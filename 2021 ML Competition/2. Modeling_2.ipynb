{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family=fm.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()) # for Windows OS user\n",
    "import math\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import klib\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys, warnings\n",
    "if not sys.warnoptions: warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import ClassifierMixin\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = pd.read_csv(os.path.abspath(\"../input\")+'/X_train.csv', encoding='cp949')\n",
    "df_x_test = pd.read_csv(os.path.abspath(\"../input\")+'/X_test.csv', encoding='cp949')\n",
    "df_y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv').age\n",
    "df_y_train_mer = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv')\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949')\n",
    "IDtrain = pd.DataFrame({'custid': df_x_train.custid.unique()})\n",
    "IDtest = pd.DataFrame({'custid': df_x_test.custid.unique()})\n",
    "\n",
    "# df = pd.concat([df_x_train, df_x_test])\n",
    "\n",
    "eda_df = pd.merge(df_x_train , df_y_train_mer, on = 'custid')\n",
    "\n",
    "ALL = pd.read_csv(os.path.abspath(\"../input\")+'/ALL피처추가060601.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.abspath(\"../input\")+'/hyun_features')\n",
    "dft = pd.read_csv(os.path.abspath(\"../input\")+'/hyun_features_te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid = IDtrain.custid.to_list()\n",
    "X_train = ALL.query('custid in @trainid')\n",
    "\n",
    "testid = IDtest.custid.to_list()\n",
    "X_test = ALL.query('custid in @testid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('custid', axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop('custid', axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns2 = X_train.dtypes[X_train.dtypes != 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-skew에만 처리를 하기 위해서 numeric_columns에서 skew와 non-skew로 구분\n",
    "skewlist2 = []\n",
    "numeric_columns_ns2 = []\n",
    "\n",
    "for i in numeric_columns2:\n",
    "    if 'SKEW' in i:\n",
    "        skewlist2.append(i)\n",
    "    else:\n",
    "        numeric_columns_ns2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-skew standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_columns2] = scaler.fit_transform(X_train[numeric_columns2])\n",
    "X_test[numeric_columns2] = scaler.transform(X_test[numeric_columns2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df, X_train[numeric_columns_ns2], X_train[skewlist2]], axis=1)\n",
    "\n",
    "X_test.index = dft.index\n",
    "data_te = pd.concat([dft, X_test[numeric_columns_ns2], X_test[skewlist2] ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_stf</th>\n",
       "      <th>9_stf</th>\n",
       "      <th>10_stf</th>\n",
       "      <th>11_stf</th>\n",
       "      <th>12_stf</th>\n",
       "      <th>13_stf</th>\n",
       "      <th>14_stf</th>\n",
       "      <th>15_stf</th>\n",
       "      <th>16_stf</th>\n",
       "      <th>17_stf</th>\n",
       "      <th>...</th>\n",
       "      <th>행사장(여성캐주얼)</th>\n",
       "      <th>행사장(여성캐쥬)</th>\n",
       "      <th>행사장(잡화)</th>\n",
       "      <th>화장품</th>\n",
       "      <th>식품팀</th>\n",
       "      <th>의류패션팀</th>\n",
       "      <th>인터넷백화점_y</th>\n",
       "      <th>잡화가용팀</th>\n",
       "      <th>방문당평균구매액</th>\n",
       "      <th>방문당평균구매상품수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>1.514697</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.451798</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>0.060923</td>\n",
       "      <td>0.316165</td>\n",
       "      <td>-0.391769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.380754</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.076312</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>0.556603</td>\n",
       "      <td>1.848414</td>\n",
       "      <td>-0.391769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.295355</td>\n",
       "      <td>-0.310157</td>\n",
       "      <td>-0.224343</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>0.068412</td>\n",
       "      <td>-0.067703</td>\n",
       "      <td>0.702682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.559885</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.118915</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.559987</td>\n",
       "      <td>1.777211</td>\n",
       "      <td>0.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>0.404504</td>\n",
       "      <td>0.134538</td>\n",
       "      <td>0.161607</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>0.736393</td>\n",
       "      <td>0.272373</td>\n",
       "      <td>-0.462554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>1.146022</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>5.361198</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>0.672847</td>\n",
       "      <td>1.224299</td>\n",
       "      <td>0.169069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.601543</td>\n",
       "      <td>-0.297154</td>\n",
       "      <td>-0.476080</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.073786</td>\n",
       "      <td>-0.329461</td>\n",
       "      <td>-0.160108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.622372</td>\n",
       "      <td>0.078366</td>\n",
       "      <td>-0.422218</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>0.550462</td>\n",
       "      <td>1.160984</td>\n",
       "      <td>0.988546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.605709</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.346326</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.496227</td>\n",
       "      <td>-0.559442</td>\n",
       "      <td>-0.312135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21586</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.576548</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.532149</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.543726</td>\n",
       "      <td>-0.750921</td>\n",
       "      <td>-1.241194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21587 rows × 5098 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1_stf  9_stf  10_stf  11_stf  12_stf  13_stf  14_stf  15_stf  16_stf  \\\n",
       "0          0      0       0       0       2       0       0       0       0   \n",
       "1          0      0       1       1       0       1       1       0       1   \n",
       "2          0      0       0       2       3       2       3       0       0   \n",
       "3          0      0       0       0       0       0       4       0       0   \n",
       "4          0      0       0       8       1       2       0       1       3   \n",
       "...      ...    ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "21582      0      0       2       1       8       8      12       3      10   \n",
       "21583      0      0       0       0       4       4       0       0       3   \n",
       "21584      0      0       0       0       1       3       4       7       3   \n",
       "21585      0      0       0       0       0       5       2       2       2   \n",
       "21586      0      0       0       0       0       1       0       0       0   \n",
       "\n",
       "       17_stf  ...  행사장(여성캐주얼)  행사장(여성캐쥬)   행사장(잡화)       화장품       식품팀  \\\n",
       "0           0  ...   -0.046443  -0.044738 -0.031135  1.514697 -0.346229   \n",
       "1           1  ...   -0.046443  -0.044738 -0.031135 -0.380754 -0.346229   \n",
       "2           5  ...   -0.046443  -0.044738 -0.031135 -0.295355 -0.310157   \n",
       "3           0  ...   -0.046443  -0.044738 -0.031135 -0.559885 -0.346229   \n",
       "4           5  ...   -0.046443  -0.044738 -0.031135  0.404504  0.134538   \n",
       "...       ...  ...         ...        ...       ...       ...       ...   \n",
       "21582      14  ...   -0.046443  -0.044738 -0.031135  1.146022 -0.346229   \n",
       "21583       2  ...   -0.046443  -0.044738 -0.031135 -0.601543 -0.297154   \n",
       "21584       2  ...   -0.046443  -0.044738 -0.031135 -0.622372  0.078366   \n",
       "21585       0  ...   -0.046443  -0.044738 -0.031135 -0.605709 -0.346229   \n",
       "21586       0  ...   -0.046443  -0.044738 -0.031135 -0.576548 -0.346229   \n",
       "\n",
       "          의류패션팀  인터넷백화점_y     잡화가용팀  방문당평균구매액  방문당평균구매상품수  \n",
       "0     -0.451798 -0.006806  0.060923  0.316165   -0.391769  \n",
       "1     -0.076312 -0.006806  0.556603  1.848414   -0.391769  \n",
       "2     -0.224343 -0.006806  0.068412 -0.067703    0.702682  \n",
       "3     -0.118915 -0.006806 -0.559987  1.777211    0.245300  \n",
       "4      0.161607 -0.006806  0.736393  0.272373   -0.462554  \n",
       "...         ...       ...       ...       ...         ...  \n",
       "21582  5.361198 -0.006806  0.672847  1.224299    0.169069  \n",
       "21583 -0.476080 -0.006806 -0.073786 -0.329461   -0.160108  \n",
       "21584 -0.422218 -0.006806  0.550462  1.160984    0.988546  \n",
       "21585 -0.346326 -0.006806 -0.496227 -0.559442   -0.312135  \n",
       "21586 -0.532149 -0.006806 -0.543726 -0.750921   -1.241194  \n",
       "\n",
       "[21587 rows x 5098 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_stf</th>\n",
       "      <th>9_stf</th>\n",
       "      <th>10_stf</th>\n",
       "      <th>11_stf</th>\n",
       "      <th>12_stf</th>\n",
       "      <th>13_stf</th>\n",
       "      <th>14_stf</th>\n",
       "      <th>15_stf</th>\n",
       "      <th>16_stf</th>\n",
       "      <th>17_stf</th>\n",
       "      <th>...</th>\n",
       "      <th>행사장(여성캐주얼)</th>\n",
       "      <th>행사장(여성캐쥬)</th>\n",
       "      <th>행사장(잡화)</th>\n",
       "      <th>화장품</th>\n",
       "      <th>식품팀</th>\n",
       "      <th>의류패션팀</th>\n",
       "      <th>인터넷백화점_y</th>\n",
       "      <th>잡화가용팀</th>\n",
       "      <th>방문당평균구매액</th>\n",
       "      <th>방문당평균구매상품수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.570299</td>\n",
       "      <td>0.266301</td>\n",
       "      <td>-0.017519</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>0.486510</td>\n",
       "      <td>1.207685</td>\n",
       "      <td>1.285845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>3.468470</td>\n",
       "      <td>-0.140063</td>\n",
       "      <td>1.420423</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>0.891128</td>\n",
       "      <td>0.473286</td>\n",
       "      <td>2.500668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.464695</td>\n",
       "      <td>-0.253084</td>\n",
       "      <td>-0.165801</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.393869</td>\n",
       "      <td>-0.714909</td>\n",
       "      <td>0.066920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.566133</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.553782</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.561271</td>\n",
       "      <td>-0.708207</td>\n",
       "      <td>-1.241194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.366174</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.490869</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.520191</td>\n",
       "      <td>-0.618107</td>\n",
       "      <td>-0.497947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.480734</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.344074</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.518479</td>\n",
       "      <td>0.674657</td>\n",
       "      <td>0.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.241199</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.553782</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.494515</td>\n",
       "      <td>0.124715</td>\n",
       "      <td>-1.241194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.574465</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.479611</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.562982</td>\n",
       "      <td>-0.422558</td>\n",
       "      <td>-1.241194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.539055</td>\n",
       "      <td>-0.272087</td>\n",
       "      <td>-0.553782</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.547149</td>\n",
       "      <td>-0.248877</td>\n",
       "      <td>3.218286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.044738</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.505729</td>\n",
       "      <td>-0.346229</td>\n",
       "      <td>-0.521465</td>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.548861</td>\n",
       "      <td>-0.587540</td>\n",
       "      <td>-0.497947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 5098 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1_stf  9_stf  10_stf  11_stf  12_stf  13_stf  14_stf  15_stf  16_stf  \\\n",
       "0          0      0       0       0       0       0       0       0       3   \n",
       "1          0      0       1      11      18      11       8       9       9   \n",
       "2          0      0       0       0       4       2      12       2       1   \n",
       "3          0      0       0       0       0       0       0       0       0   \n",
       "4          0      0       0       0       0       0       0       1       1   \n",
       "...      ...    ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "14375      0      0       0       0       3       0       0       0       0   \n",
       "14376      0      0       0       0       0       0       0       1       0   \n",
       "14377      0      0       0       0       0       0       0       0       0   \n",
       "14378      0      0       0       0       0       0       0       0       1   \n",
       "14379      0      0       0       0       0       0       0       0       1   \n",
       "\n",
       "       17_stf  ...  행사장(여성캐주얼)  행사장(여성캐쥬)   행사장(잡화)       화장품       식품팀  \\\n",
       "0          15  ...   -0.046443  -0.044738 -0.031135 -0.570299  0.266301   \n",
       "1          15  ...   -0.046443  -0.044738 -0.031135  3.468470 -0.140063   \n",
       "2           9  ...   -0.046443  -0.044738 -0.031135 -0.464695 -0.253084   \n",
       "3           0  ...   -0.046443  -0.044738 -0.031135 -0.566133 -0.346229   \n",
       "4           0  ...   -0.046443  -0.044738 -0.031135 -0.366174 -0.346229   \n",
       "...       ...  ...         ...        ...       ...       ...       ...   \n",
       "14375       0  ...   -0.046443  -0.044738 -0.031135 -0.480734 -0.346229   \n",
       "14376       0  ...   -0.046443  -0.044738 -0.031135 -0.241199 -0.346229   \n",
       "14377       1  ...   -0.046443  -0.044738 -0.031135 -0.574465 -0.346229   \n",
       "14378       2  ...   -0.046443  -0.044738 -0.031135 -0.539055 -0.272087   \n",
       "14379       1  ...   -0.046443  -0.044738 -0.031135 -0.505729 -0.346229   \n",
       "\n",
       "          의류패션팀  인터넷백화점_y     잡화가용팀  방문당평균구매액  방문당평균구매상품수  \n",
       "0     -0.017519 -0.006806  0.486510  1.207685    1.285845  \n",
       "1      1.420423 -0.006806  0.891128  0.473286    2.500668  \n",
       "2     -0.165801 -0.006806 -0.393869 -0.714909    0.066920  \n",
       "3     -0.553782 -0.006806 -0.561271 -0.708207   -1.241194  \n",
       "4     -0.490869 -0.006806 -0.520191 -0.618107   -0.497947  \n",
       "...         ...       ...       ...       ...         ...  \n",
       "14375 -0.344074 -0.006806 -0.518479  0.674657    0.245300  \n",
       "14376 -0.553782 -0.006806 -0.494515  0.124715   -1.241194  \n",
       "14377 -0.479611 -0.006806 -0.562982 -0.422558   -1.241194  \n",
       "14378 -0.553782 -0.006806 -0.547149 -0.248877    3.218286  \n",
       "14379 -0.521465 -0.006806 -0.548861 -0.587540   -0.497947  \n",
       "\n",
       "[14380 rows x 5098 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( data, data_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21587, 5098), (14380, 5098), (21587,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "data.shape, data_te.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.astype(str)\n",
    "data_te.columns = data_te.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.values\n",
    "data_te2 = data_te.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = data2[:, 1:]\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17269, 5097), (4318, 5097))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr, target, test_size=0.2 , stratify = target , random_state=0)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 8.08188\ttraining's l2: 65.3168\tvalid_1's rmse: 8.65417\tvalid_1's l2: 74.8947\n",
      "[200]\ttraining's rmse: 7.3421\ttraining's l2: 53.9065\tvalid_1's rmse: 8.38242\tvalid_1's l2: 70.265\n",
      "[300]\ttraining's rmse: 6.84944\ttraining's l2: 46.9148\tvalid_1's rmse: 8.30163\tvalid_1's l2: 68.917\n",
      "[400]\ttraining's rmse: 6.46629\ttraining's l2: 41.8129\tvalid_1's rmse: 8.28015\tvalid_1's l2: 68.5609\n",
      "[500]\ttraining's rmse: 6.1421\ttraining's l2: 37.7254\tvalid_1's rmse: 8.27539\tvalid_1's l2: 68.482\n",
      "[600]\ttraining's rmse: 5.85635\ttraining's l2: 34.2968\tvalid_1's rmse: 8.26558\tvalid_1's l2: 68.3199\n",
      "[700]\ttraining's rmse: 5.60838\ttraining's l2: 31.4539\tvalid_1's rmse: 8.26459\tvalid_1's l2: 68.3034\n",
      "Early stopping, best iteration is:\n",
      "[665]\ttraining's rmse: 5.69307\ttraining's l2: 32.411\tvalid_1's rmse: 8.2629\tvalid_1's l2: 68.2756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.02, max_depth=12, n_estimators=1000,\n",
       "              num_leaves=32, silent=-1, subsample=0.8, verbose=-1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "clf = LGBMRegressor(\n",
    "        n_jobs=-1,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=32,\n",
    "        subsample=0.8,\n",
    "        max_depth=12,\n",
    "        silent=-1,\n",
    "        verbose=-1\n",
    "        )\n",
    "\n",
    "clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric = 'RMSE', \n",
    "        verbose=100, early_stopping_rounds= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection & Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = data2[:, 1:]\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "smf = SelectFromModel(clf, threshold='2.0*mean')\n",
    "smf.fit(ftr, target)\n",
    "X_new = smf.transform(ftr)\n",
    "X_te_new = smf.transform(data_te2[:, 1:])\n",
    "feature_idx = smf.get_support()\n",
    "# feature_name = ftr.columns[feature_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [-65.858  -68.8208 -69.7267 -66.2238 -65.539 ]\n",
      "평균 검증 정확도: -67.2337\n",
      "RMSE: 8.199613557837917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X_new, target, scoring='neg_mean_squared_error', cv=5)\n",
    "print('교차 검증별 정확도:', np.round(scores, 4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores), 4))\n",
    "print('RMSE:', np.sqrt(-np.mean(scores)))\n",
    "# mean -\n",
    "# 2.0mean - 8.199613557837917\n",
    "# 3.0mean - 8.207348627039885\n",
    "# 3.5mean -       \n",
    "# 4.0mean - \n",
    "# 4.5mean - \n",
    "# 5.0mean - \n",
    "# 6.0mean - \n",
    "# 6.5mean - \n",
    "# 7.0mean - 8.225485195696558\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21587, 581), (14380, 581))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape, X_te_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper parameter Tuning_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = np.array(data)\n",
    "# X_te_new = np.array(data_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = X_new\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21587,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15110, 581), (6477, 581))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr, target, test_size=0.3, stratify = target,  random_state=1000)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.063286\n",
      "0:\tlearn: 10.2967141\ttotal: 263ms\tremaining: 4m 22s\n",
      "1:\tlearn: 10.1562030\ttotal: 340ms\tremaining: 2m 49s\n",
      "2:\tlearn: 10.0385337\ttotal: 415ms\tremaining: 2m 17s\n",
      "3:\tlearn: 9.9386690\ttotal: 486ms\tremaining: 2m 1s\n",
      "4:\tlearn: 9.8401474\ttotal: 562ms\tremaining: 1m 51s\n",
      "5:\tlearn: 9.7422273\ttotal: 642ms\tremaining: 1m 46s\n",
      "6:\tlearn: 9.6557683\ttotal: 714ms\tremaining: 1m 41s\n",
      "7:\tlearn: 9.5755614\ttotal: 791ms\tremaining: 1m 38s\n",
      "8:\tlearn: 9.5052347\ttotal: 860ms\tremaining: 1m 34s\n",
      "9:\tlearn: 9.4384202\ttotal: 933ms\tremaining: 1m 32s\n",
      "10:\tlearn: 9.3789410\ttotal: 1.02s\tremaining: 1m 32s\n",
      "11:\tlearn: 9.3243263\ttotal: 1.09s\tremaining: 1m 30s\n",
      "12:\tlearn: 9.2736793\ttotal: 1.16s\tremaining: 1m 28s\n",
      "13:\tlearn: 9.2265025\ttotal: 1.22s\tremaining: 1m 26s\n",
      "14:\tlearn: 9.1774537\ttotal: 1.29s\tremaining: 1m 24s\n",
      "15:\tlearn: 9.1358822\ttotal: 1.35s\tremaining: 1m 23s\n",
      "16:\tlearn: 9.0936508\ttotal: 1.42s\tremaining: 1m 21s\n",
      "17:\tlearn: 9.0563088\ttotal: 1.48s\tremaining: 1m 20s\n",
      "18:\tlearn: 9.0246515\ttotal: 1.55s\tremaining: 1m 20s\n",
      "19:\tlearn: 8.9872534\ttotal: 1.63s\tremaining: 1m 19s\n",
      "20:\tlearn: 8.9526035\ttotal: 1.7s\tremaining: 1m 19s\n",
      "21:\tlearn: 8.9230753\ttotal: 1.78s\tremaining: 1m 19s\n",
      "22:\tlearn: 8.8959004\ttotal: 1.85s\tremaining: 1m 18s\n",
      "23:\tlearn: 8.8705478\ttotal: 1.93s\tremaining: 1m 18s\n",
      "24:\tlearn: 8.8408630\ttotal: 2s\tremaining: 1m 18s\n",
      "25:\tlearn: 8.8180713\ttotal: 2.08s\tremaining: 1m 17s\n",
      "26:\tlearn: 8.7921681\ttotal: 2.15s\tremaining: 1m 17s\n",
      "27:\tlearn: 8.7704801\ttotal: 2.22s\tremaining: 1m 17s\n",
      "28:\tlearn: 8.7439314\ttotal: 2.29s\tremaining: 1m 16s\n",
      "29:\tlearn: 8.7207193\ttotal: 2.36s\tremaining: 1m 16s\n",
      "30:\tlearn: 8.7001746\ttotal: 2.43s\tremaining: 1m 16s\n",
      "31:\tlearn: 8.6832332\ttotal: 2.52s\tremaining: 1m 16s\n",
      "32:\tlearn: 8.6622765\ttotal: 2.67s\tremaining: 1m 18s\n",
      "33:\tlearn: 8.6460834\ttotal: 2.75s\tremaining: 1m 18s\n",
      "34:\tlearn: 8.6247394\ttotal: 2.83s\tremaining: 1m 18s\n",
      "35:\tlearn: 8.6072711\ttotal: 2.91s\tremaining: 1m 17s\n",
      "36:\tlearn: 8.5926662\ttotal: 3s\tremaining: 1m 17s\n",
      "37:\tlearn: 8.5754525\ttotal: 3.08s\tremaining: 1m 17s\n",
      "38:\tlearn: 8.5609956\ttotal: 3.16s\tremaining: 1m 17s\n",
      "39:\tlearn: 8.5464097\ttotal: 3.24s\tremaining: 1m 17s\n",
      "40:\tlearn: 8.5309123\ttotal: 3.32s\tremaining: 1m 17s\n",
      "41:\tlearn: 8.5164134\ttotal: 3.4s\tremaining: 1m 17s\n",
      "42:\tlearn: 8.5055953\ttotal: 3.48s\tremaining: 1m 17s\n",
      "43:\tlearn: 8.4905863\ttotal: 3.56s\tremaining: 1m 17s\n",
      "44:\tlearn: 8.4774530\ttotal: 3.64s\tremaining: 1m 17s\n",
      "45:\tlearn: 8.4651512\ttotal: 3.73s\tremaining: 1m 17s\n",
      "46:\tlearn: 8.4547996\ttotal: 3.81s\tremaining: 1m 17s\n",
      "47:\tlearn: 8.4450460\ttotal: 3.88s\tremaining: 1m 17s\n",
      "48:\tlearn: 8.4352234\ttotal: 3.95s\tremaining: 1m 16s\n",
      "49:\tlearn: 8.4241527\ttotal: 4.03s\tremaining: 1m 16s\n",
      "50:\tlearn: 8.4126355\ttotal: 4.11s\tremaining: 1m 16s\n",
      "51:\tlearn: 8.4015290\ttotal: 4.18s\tremaining: 1m 16s\n",
      "52:\tlearn: 8.3904327\ttotal: 4.27s\tremaining: 1m 16s\n",
      "53:\tlearn: 8.3798998\ttotal: 4.37s\tremaining: 1m 16s\n",
      "54:\tlearn: 8.3724640\ttotal: 4.45s\tremaining: 1m 16s\n",
      "55:\tlearn: 8.3620178\ttotal: 4.53s\tremaining: 1m 16s\n",
      "56:\tlearn: 8.3527933\ttotal: 4.61s\tremaining: 1m 16s\n",
      "57:\tlearn: 8.3438030\ttotal: 4.69s\tremaining: 1m 16s\n",
      "58:\tlearn: 8.3349459\ttotal: 4.76s\tremaining: 1m 15s\n",
      "59:\tlearn: 8.3257600\ttotal: 4.83s\tremaining: 1m 15s\n",
      "60:\tlearn: 8.3164527\ttotal: 4.91s\tremaining: 1m 15s\n",
      "61:\tlearn: 8.3096496\ttotal: 4.98s\tremaining: 1m 15s\n",
      "62:\tlearn: 8.3012611\ttotal: 5.08s\tremaining: 1m 15s\n",
      "63:\tlearn: 8.2923342\ttotal: 5.17s\tremaining: 1m 15s\n",
      "64:\tlearn: 8.2851777\ttotal: 5.26s\tremaining: 1m 15s\n",
      "65:\tlearn: 8.2768113\ttotal: 5.38s\tremaining: 1m 16s\n",
      "66:\tlearn: 8.2696360\ttotal: 5.46s\tremaining: 1m 16s\n",
      "67:\tlearn: 8.2640324\ttotal: 5.53s\tremaining: 1m 15s\n",
      "68:\tlearn: 8.2585014\ttotal: 5.6s\tremaining: 1m 15s\n",
      "69:\tlearn: 8.2494593\ttotal: 5.67s\tremaining: 1m 15s\n",
      "70:\tlearn: 8.2414229\ttotal: 5.75s\tremaining: 1m 15s\n",
      "71:\tlearn: 8.2348675\ttotal: 5.83s\tremaining: 1m 15s\n",
      "72:\tlearn: 8.2277634\ttotal: 5.9s\tremaining: 1m 14s\n",
      "73:\tlearn: 8.2207116\ttotal: 5.99s\tremaining: 1m 14s\n",
      "74:\tlearn: 8.2139859\ttotal: 6.05s\tremaining: 1m 14s\n",
      "75:\tlearn: 8.2088202\ttotal: 6.12s\tremaining: 1m 14s\n",
      "76:\tlearn: 8.2028068\ttotal: 6.18s\tremaining: 1m 14s\n",
      "77:\tlearn: 8.1960204\ttotal: 6.25s\tremaining: 1m 13s\n",
      "78:\tlearn: 8.1887917\ttotal: 6.32s\tremaining: 1m 13s\n",
      "79:\tlearn: 8.1836332\ttotal: 6.38s\tremaining: 1m 13s\n",
      "80:\tlearn: 8.1791096\ttotal: 6.44s\tremaining: 1m 13s\n",
      "81:\tlearn: 8.1733151\ttotal: 6.5s\tremaining: 1m 12s\n",
      "82:\tlearn: 8.1657023\ttotal: 6.57s\tremaining: 1m 12s\n",
      "83:\tlearn: 8.1604487\ttotal: 6.63s\tremaining: 1m 12s\n",
      "84:\tlearn: 8.1540795\ttotal: 6.69s\tremaining: 1m 12s\n",
      "85:\tlearn: 8.1474185\ttotal: 6.76s\tremaining: 1m 11s\n",
      "86:\tlearn: 8.1417288\ttotal: 6.82s\tremaining: 1m 11s\n",
      "87:\tlearn: 8.1372464\ttotal: 6.88s\tremaining: 1m 11s\n",
      "88:\tlearn: 8.1325579\ttotal: 6.95s\tremaining: 1m 11s\n",
      "89:\tlearn: 8.1272683\ttotal: 7.01s\tremaining: 1m 10s\n",
      "90:\tlearn: 8.1228379\ttotal: 7.08s\tremaining: 1m 10s\n",
      "91:\tlearn: 8.1181188\ttotal: 7.16s\tremaining: 1m 10s\n",
      "92:\tlearn: 8.1135392\ttotal: 7.23s\tremaining: 1m 10s\n",
      "93:\tlearn: 8.1092738\ttotal: 7.31s\tremaining: 1m 10s\n",
      "94:\tlearn: 8.1046076\ttotal: 7.38s\tremaining: 1m 10s\n",
      "95:\tlearn: 8.1005126\ttotal: 7.44s\tremaining: 1m 10s\n",
      "96:\tlearn: 8.0965974\ttotal: 7.51s\tremaining: 1m 9s\n",
      "97:\tlearn: 8.0922552\ttotal: 7.58s\tremaining: 1m 9s\n",
      "98:\tlearn: 8.0867383\ttotal: 7.66s\tremaining: 1m 9s\n",
      "99:\tlearn: 8.0816670\ttotal: 7.72s\tremaining: 1m 9s\n",
      "100:\tlearn: 8.0776376\ttotal: 7.79s\tremaining: 1m 9s\n",
      "101:\tlearn: 8.0734125\ttotal: 7.85s\tremaining: 1m 9s\n",
      "102:\tlearn: 8.0689125\ttotal: 7.91s\tremaining: 1m 8s\n",
      "103:\tlearn: 8.0638390\ttotal: 7.98s\tremaining: 1m 8s\n",
      "104:\tlearn: 8.0599404\ttotal: 8.04s\tremaining: 1m 8s\n",
      "105:\tlearn: 8.0558996\ttotal: 8.1s\tremaining: 1m 8s\n",
      "106:\tlearn: 8.0507496\ttotal: 8.17s\tremaining: 1m 8s\n",
      "107:\tlearn: 8.0477044\ttotal: 8.23s\tremaining: 1m 8s\n",
      "108:\tlearn: 8.0436362\ttotal: 8.31s\tremaining: 1m 7s\n",
      "109:\tlearn: 8.0389453\ttotal: 8.37s\tremaining: 1m 7s\n",
      "110:\tlearn: 8.0334183\ttotal: 8.44s\tremaining: 1m 7s\n",
      "111:\tlearn: 8.0278344\ttotal: 8.51s\tremaining: 1m 7s\n",
      "112:\tlearn: 8.0230589\ttotal: 8.57s\tremaining: 1m 7s\n",
      "113:\tlearn: 8.0174469\ttotal: 8.63s\tremaining: 1m 7s\n",
      "114:\tlearn: 8.0132251\ttotal: 8.7s\tremaining: 1m 6s\n",
      "115:\tlearn: 8.0085790\ttotal: 8.76s\tremaining: 1m 6s\n",
      "116:\tlearn: 8.0048373\ttotal: 8.82s\tremaining: 1m 6s\n",
      "117:\tlearn: 7.9988313\ttotal: 8.89s\tremaining: 1m 6s\n",
      "118:\tlearn: 7.9943352\ttotal: 8.96s\tremaining: 1m 6s\n",
      "119:\tlearn: 7.9891480\ttotal: 9.04s\tremaining: 1m 6s\n",
      "120:\tlearn: 7.9845672\ttotal: 9.11s\tremaining: 1m 6s\n",
      "121:\tlearn: 7.9786753\ttotal: 9.18s\tremaining: 1m 6s\n",
      "122:\tlearn: 7.9743319\ttotal: 9.26s\tremaining: 1m 6s\n",
      "123:\tlearn: 7.9701554\ttotal: 9.34s\tremaining: 1m 5s\n",
      "124:\tlearn: 7.9663993\ttotal: 9.41s\tremaining: 1m 5s\n",
      "125:\tlearn: 7.9615034\ttotal: 9.48s\tremaining: 1m 5s\n",
      "126:\tlearn: 7.9588746\ttotal: 9.54s\tremaining: 1m 5s\n",
      "127:\tlearn: 7.9559846\ttotal: 9.61s\tremaining: 1m 5s\n",
      "128:\tlearn: 7.9524276\ttotal: 9.68s\tremaining: 1m 5s\n",
      "129:\tlearn: 7.9479624\ttotal: 9.75s\tremaining: 1m 5s\n",
      "130:\tlearn: 7.9440242\ttotal: 9.82s\tremaining: 1m 5s\n",
      "131:\tlearn: 7.9384616\ttotal: 9.9s\tremaining: 1m 5s\n",
      "132:\tlearn: 7.9340896\ttotal: 9.97s\tremaining: 1m 4s\n",
      "133:\tlearn: 7.9294619\ttotal: 10s\tremaining: 1m 4s\n",
      "134:\tlearn: 7.9263606\ttotal: 10.1s\tremaining: 1m 4s\n",
      "135:\tlearn: 7.9218911\ttotal: 10.2s\tremaining: 1m 4s\n",
      "136:\tlearn: 7.9176715\ttotal: 10.3s\tremaining: 1m 4s\n",
      "137:\tlearn: 7.9134395\ttotal: 10.3s\tremaining: 1m 4s\n",
      "138:\tlearn: 7.9096194\ttotal: 10.4s\tremaining: 1m 4s\n",
      "139:\tlearn: 7.9067474\ttotal: 10.5s\tremaining: 1m 4s\n",
      "140:\tlearn: 7.9034830\ttotal: 10.6s\tremaining: 1m 4s\n",
      "141:\tlearn: 7.8988556\ttotal: 10.7s\tremaining: 1m 4s\n",
      "142:\tlearn: 7.8938429\ttotal: 10.7s\tremaining: 1m 4s\n",
      "143:\tlearn: 7.8907010\ttotal: 10.8s\tremaining: 1m 4s\n",
      "144:\tlearn: 7.8841688\ttotal: 10.9s\tremaining: 1m 4s\n",
      "145:\tlearn: 7.8798289\ttotal: 11s\tremaining: 1m 4s\n",
      "146:\tlearn: 7.8747977\ttotal: 11.1s\tremaining: 1m 4s\n",
      "147:\tlearn: 7.8708555\ttotal: 11.2s\tremaining: 1m 4s\n",
      "148:\tlearn: 7.8659893\ttotal: 11.2s\tremaining: 1m 4s\n",
      "149:\tlearn: 7.8616018\ttotal: 11.3s\tremaining: 1m 4s\n",
      "150:\tlearn: 7.8582330\ttotal: 11.4s\tremaining: 1m 4s\n",
      "151:\tlearn: 7.8547237\ttotal: 11.4s\tremaining: 1m 3s\n",
      "152:\tlearn: 7.8504218\ttotal: 11.5s\tremaining: 1m 3s\n",
      "153:\tlearn: 7.8465111\ttotal: 11.6s\tremaining: 1m 3s\n",
      "154:\tlearn: 7.8413072\ttotal: 11.7s\tremaining: 1m 3s\n",
      "155:\tlearn: 7.8363882\ttotal: 11.7s\tremaining: 1m 3s\n",
      "156:\tlearn: 7.8321908\ttotal: 11.8s\tremaining: 1m 3s\n",
      "157:\tlearn: 7.8279801\ttotal: 11.9s\tremaining: 1m 3s\n",
      "158:\tlearn: 7.8233872\ttotal: 12s\tremaining: 1m 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159:\tlearn: 7.8196229\ttotal: 12.1s\tremaining: 1m 3s\n",
      "160:\tlearn: 7.8157770\ttotal: 12.2s\tremaining: 1m 3s\n",
      "161:\tlearn: 7.8114588\ttotal: 12.2s\tremaining: 1m 3s\n",
      "162:\tlearn: 7.8064549\ttotal: 12.3s\tremaining: 1m 3s\n",
      "163:\tlearn: 7.8022473\ttotal: 12.4s\tremaining: 1m 3s\n",
      "164:\tlearn: 7.7987167\ttotal: 12.4s\tremaining: 1m 2s\n",
      "165:\tlearn: 7.7940946\ttotal: 12.5s\tremaining: 1m 2s\n",
      "166:\tlearn: 7.7899281\ttotal: 12.6s\tremaining: 1m 2s\n",
      "167:\tlearn: 7.7853964\ttotal: 12.6s\tremaining: 1m 2s\n",
      "168:\tlearn: 7.7812122\ttotal: 12.7s\tremaining: 1m 2s\n",
      "169:\tlearn: 7.7771911\ttotal: 12.8s\tremaining: 1m 2s\n",
      "170:\tlearn: 7.7718252\ttotal: 12.8s\tremaining: 1m 2s\n",
      "171:\tlearn: 7.7669960\ttotal: 12.9s\tremaining: 1m 2s\n",
      "172:\tlearn: 7.7627816\ttotal: 13s\tremaining: 1m 2s\n",
      "173:\tlearn: 7.7551655\ttotal: 13s\tremaining: 1m 1s\n",
      "174:\tlearn: 7.7510262\ttotal: 13.1s\tremaining: 1m 1s\n",
      "175:\tlearn: 7.7476177\ttotal: 13.2s\tremaining: 1m 1s\n",
      "176:\tlearn: 7.7436976\ttotal: 13.3s\tremaining: 1m 1s\n",
      "177:\tlearn: 7.7410384\ttotal: 13.3s\tremaining: 1m 1s\n",
      "178:\tlearn: 7.7370896\ttotal: 13.4s\tremaining: 1m 1s\n",
      "179:\tlearn: 7.7324858\ttotal: 13.5s\tremaining: 1m 1s\n",
      "180:\tlearn: 7.7291191\ttotal: 13.5s\tremaining: 1m 1s\n",
      "181:\tlearn: 7.7246013\ttotal: 13.6s\tremaining: 1m 1s\n",
      "182:\tlearn: 7.7198357\ttotal: 13.7s\tremaining: 1m\n",
      "183:\tlearn: 7.7141966\ttotal: 13.7s\tremaining: 1m\n",
      "184:\tlearn: 7.7088609\ttotal: 13.8s\tremaining: 1m\n",
      "185:\tlearn: 7.7043456\ttotal: 13.9s\tremaining: 1m\n",
      "186:\tlearn: 7.6993912\ttotal: 14s\tremaining: 1m\n",
      "187:\tlearn: 7.6945909\ttotal: 14s\tremaining: 1m\n",
      "188:\tlearn: 7.6907257\ttotal: 14.1s\tremaining: 1m\n",
      "189:\tlearn: 7.6876194\ttotal: 14.2s\tremaining: 1m\n",
      "190:\tlearn: 7.6821405\ttotal: 14.2s\tremaining: 1m\n",
      "191:\tlearn: 7.6778684\ttotal: 14.3s\tremaining: 1m\n",
      "192:\tlearn: 7.6742337\ttotal: 14.4s\tremaining: 1m\n",
      "193:\tlearn: 7.6684410\ttotal: 14.4s\tremaining: 1m\n",
      "194:\tlearn: 7.6625694\ttotal: 14.5s\tremaining: 59.9s\n",
      "195:\tlearn: 7.6584246\ttotal: 14.6s\tremaining: 59.8s\n",
      "196:\tlearn: 7.6532133\ttotal: 14.6s\tremaining: 59.7s\n",
      "197:\tlearn: 7.6477789\ttotal: 14.7s\tremaining: 59.6s\n",
      "198:\tlearn: 7.6429284\ttotal: 14.8s\tremaining: 59.5s\n",
      "199:\tlearn: 7.6378723\ttotal: 14.8s\tremaining: 59.4s\n",
      "200:\tlearn: 7.6336891\ttotal: 14.9s\tremaining: 59.3s\n",
      "201:\tlearn: 7.6296845\ttotal: 15s\tremaining: 59.2s\n",
      "202:\tlearn: 7.6249576\ttotal: 15.1s\tremaining: 59.1s\n",
      "203:\tlearn: 7.6186593\ttotal: 15.1s\tremaining: 59s\n",
      "204:\tlearn: 7.6146951\ttotal: 15.2s\tremaining: 58.9s\n",
      "205:\tlearn: 7.6116112\ttotal: 15.2s\tremaining: 58.8s\n",
      "206:\tlearn: 7.6067433\ttotal: 15.3s\tremaining: 58.7s\n",
      "207:\tlearn: 7.6004391\ttotal: 15.4s\tremaining: 58.6s\n",
      "208:\tlearn: 7.5968853\ttotal: 15.4s\tremaining: 58.4s\n",
      "209:\tlearn: 7.5925615\ttotal: 15.5s\tremaining: 58.3s\n",
      "210:\tlearn: 7.5876849\ttotal: 15.6s\tremaining: 58.2s\n",
      "211:\tlearn: 7.5830887\ttotal: 15.6s\tremaining: 58.1s\n",
      "212:\tlearn: 7.5786896\ttotal: 15.7s\tremaining: 58s\n",
      "213:\tlearn: 7.5752512\ttotal: 15.7s\tremaining: 57.8s\n",
      "214:\tlearn: 7.5708259\ttotal: 15.8s\tremaining: 57.7s\n",
      "215:\tlearn: 7.5670018\ttotal: 15.9s\tremaining: 57.6s\n",
      "216:\tlearn: 7.5620576\ttotal: 15.9s\tremaining: 57.5s\n",
      "217:\tlearn: 7.5578497\ttotal: 16s\tremaining: 57.4s\n",
      "218:\tlearn: 7.5549076\ttotal: 16.1s\tremaining: 57.3s\n",
      "219:\tlearn: 7.5490679\ttotal: 16.1s\tremaining: 57.1s\n",
      "220:\tlearn: 7.5442425\ttotal: 16.2s\tremaining: 57s\n",
      "221:\tlearn: 7.5394348\ttotal: 16.2s\tremaining: 56.9s\n",
      "222:\tlearn: 7.5360478\ttotal: 16.3s\tremaining: 56.8s\n",
      "223:\tlearn: 7.5306127\ttotal: 16.4s\tremaining: 56.7s\n",
      "224:\tlearn: 7.5269751\ttotal: 16.4s\tremaining: 56.6s\n",
      "225:\tlearn: 7.5229562\ttotal: 16.5s\tremaining: 56.5s\n",
      "226:\tlearn: 7.5186611\ttotal: 16.6s\tremaining: 56.4s\n",
      "227:\tlearn: 7.5141114\ttotal: 16.6s\tremaining: 56.3s\n",
      "228:\tlearn: 7.5098062\ttotal: 16.7s\tremaining: 56.2s\n",
      "229:\tlearn: 7.5043363\ttotal: 16.8s\tremaining: 56.1s\n",
      "230:\tlearn: 7.4994226\ttotal: 16.8s\tremaining: 56s\n",
      "231:\tlearn: 7.4939966\ttotal: 16.9s\tremaining: 55.9s\n",
      "232:\tlearn: 7.4907093\ttotal: 17s\tremaining: 55.8s\n",
      "233:\tlearn: 7.4855797\ttotal: 17s\tremaining: 55.8s\n",
      "234:\tlearn: 7.4821968\ttotal: 17.1s\tremaining: 55.7s\n",
      "235:\tlearn: 7.4768304\ttotal: 17.2s\tremaining: 55.6s\n",
      "236:\tlearn: 7.4721894\ttotal: 17.2s\tremaining: 55.5s\n",
      "237:\tlearn: 7.4687171\ttotal: 17.3s\tremaining: 55.4s\n",
      "238:\tlearn: 7.4636919\ttotal: 17.4s\tremaining: 55.3s\n",
      "239:\tlearn: 7.4608369\ttotal: 17.4s\tremaining: 55.2s\n",
      "240:\tlearn: 7.4569159\ttotal: 17.5s\tremaining: 55.1s\n",
      "241:\tlearn: 7.4527018\ttotal: 17.6s\tremaining: 55.1s\n",
      "242:\tlearn: 7.4484751\ttotal: 17.6s\tremaining: 55s\n",
      "243:\tlearn: 7.4433800\ttotal: 17.7s\tremaining: 54.9s\n",
      "244:\tlearn: 7.4382303\ttotal: 17.8s\tremaining: 54.8s\n",
      "245:\tlearn: 7.4336500\ttotal: 17.9s\tremaining: 54.7s\n",
      "246:\tlearn: 7.4288458\ttotal: 17.9s\tremaining: 54.6s\n",
      "247:\tlearn: 7.4238074\ttotal: 18s\tremaining: 54.5s\n",
      "248:\tlearn: 7.4203382\ttotal: 18.1s\tremaining: 54.4s\n",
      "249:\tlearn: 7.4163151\ttotal: 18.1s\tremaining: 54.4s\n",
      "250:\tlearn: 7.4120626\ttotal: 18.2s\tremaining: 54.3s\n",
      "251:\tlearn: 7.4094285\ttotal: 18.2s\tremaining: 54.2s\n",
      "252:\tlearn: 7.4066769\ttotal: 18.3s\tremaining: 54.1s\n",
      "253:\tlearn: 7.4035998\ttotal: 18.4s\tremaining: 54s\n",
      "254:\tlearn: 7.3990809\ttotal: 18.5s\tremaining: 54s\n",
      "255:\tlearn: 7.3946876\ttotal: 18.5s\tremaining: 53.9s\n",
      "256:\tlearn: 7.3903762\ttotal: 18.6s\tremaining: 53.8s\n",
      "257:\tlearn: 7.3857884\ttotal: 18.7s\tremaining: 53.7s\n",
      "258:\tlearn: 7.3808156\ttotal: 18.8s\tremaining: 53.7s\n",
      "259:\tlearn: 7.3784115\ttotal: 18.8s\tremaining: 53.6s\n",
      "260:\tlearn: 7.3741622\ttotal: 18.9s\tremaining: 53.5s\n",
      "261:\tlearn: 7.3694630\ttotal: 18.9s\tremaining: 53.4s\n",
      "262:\tlearn: 7.3661310\ttotal: 19s\tremaining: 53.3s\n",
      "263:\tlearn: 7.3612052\ttotal: 19.1s\tremaining: 53.2s\n",
      "264:\tlearn: 7.3557916\ttotal: 19.1s\tremaining: 53.1s\n",
      "265:\tlearn: 7.3532237\ttotal: 19.2s\tremaining: 53s\n",
      "266:\tlearn: 7.3493011\ttotal: 19.3s\tremaining: 52.9s\n",
      "267:\tlearn: 7.3449057\ttotal: 19.3s\tremaining: 52.8s\n",
      "268:\tlearn: 7.3433334\ttotal: 19.4s\tremaining: 52.7s\n",
      "269:\tlearn: 7.3405736\ttotal: 19.5s\tremaining: 52.6s\n",
      "270:\tlearn: 7.3361866\ttotal: 19.5s\tremaining: 52.5s\n",
      "271:\tlearn: 7.3305031\ttotal: 19.6s\tremaining: 52.4s\n",
      "272:\tlearn: 7.3269120\ttotal: 19.6s\tremaining: 52.3s\n",
      "273:\tlearn: 7.3234098\ttotal: 19.7s\tremaining: 52.2s\n",
      "274:\tlearn: 7.3181845\ttotal: 19.8s\tremaining: 52.1s\n",
      "275:\tlearn: 7.3139160\ttotal: 19.8s\tremaining: 52.1s\n",
      "276:\tlearn: 7.3108572\ttotal: 19.9s\tremaining: 52s\n",
      "277:\tlearn: 7.3066815\ttotal: 20s\tremaining: 51.9s\n",
      "278:\tlearn: 7.3029689\ttotal: 20s\tremaining: 51.8s\n",
      "279:\tlearn: 7.2995502\ttotal: 20.1s\tremaining: 51.7s\n",
      "280:\tlearn: 7.2970200\ttotal: 20.2s\tremaining: 51.6s\n",
      "281:\tlearn: 7.2940989\ttotal: 20.2s\tremaining: 51.5s\n",
      "282:\tlearn: 7.2904074\ttotal: 20.3s\tremaining: 51.5s\n",
      "283:\tlearn: 7.2858332\ttotal: 20.4s\tremaining: 51.4s\n",
      "284:\tlearn: 7.2812511\ttotal: 20.4s\tremaining: 51.3s\n",
      "285:\tlearn: 7.2773393\ttotal: 20.5s\tremaining: 51.2s\n",
      "286:\tlearn: 7.2734451\ttotal: 20.6s\tremaining: 51.1s\n",
      "287:\tlearn: 7.2692412\ttotal: 20.7s\tremaining: 51.1s\n",
      "288:\tlearn: 7.2675978\ttotal: 20.7s\tremaining: 51s\n",
      "289:\tlearn: 7.2639737\ttotal: 20.8s\tremaining: 50.9s\n",
      "290:\tlearn: 7.2598006\ttotal: 20.9s\tremaining: 50.9s\n",
      "291:\tlearn: 7.2548891\ttotal: 20.9s\tremaining: 50.8s\n",
      "292:\tlearn: 7.2500681\ttotal: 21s\tremaining: 50.7s\n",
      "293:\tlearn: 7.2465728\ttotal: 21.1s\tremaining: 50.6s\n",
      "294:\tlearn: 7.2438161\ttotal: 21.1s\tremaining: 50.5s\n",
      "295:\tlearn: 7.2392531\ttotal: 21.2s\tremaining: 50.4s\n",
      "296:\tlearn: 7.2376451\ttotal: 21.3s\tremaining: 50.3s\n",
      "297:\tlearn: 7.2332440\ttotal: 21.3s\tremaining: 50.3s\n",
      "298:\tlearn: 7.2307567\ttotal: 21.4s\tremaining: 50.2s\n",
      "299:\tlearn: 7.2279569\ttotal: 21.5s\tremaining: 50.1s\n",
      "300:\tlearn: 7.2246321\ttotal: 21.5s\tremaining: 50s\n",
      "301:\tlearn: 7.2204173\ttotal: 21.6s\tremaining: 49.9s\n",
      "302:\tlearn: 7.2163342\ttotal: 21.6s\tremaining: 49.8s\n",
      "303:\tlearn: 7.2123647\ttotal: 21.7s\tremaining: 49.7s\n",
      "304:\tlearn: 7.2092015\ttotal: 21.8s\tremaining: 49.6s\n",
      "305:\tlearn: 7.2050129\ttotal: 21.9s\tremaining: 49.6s\n",
      "306:\tlearn: 7.2016641\ttotal: 21.9s\tremaining: 49.5s\n",
      "307:\tlearn: 7.1970846\ttotal: 22s\tremaining: 49.4s\n",
      "308:\tlearn: 7.1952472\ttotal: 22s\tremaining: 49.3s\n",
      "309:\tlearn: 7.1915271\ttotal: 22.1s\tremaining: 49.2s\n",
      "310:\tlearn: 7.1876314\ttotal: 22.2s\tremaining: 49.1s\n",
      "311:\tlearn: 7.1839210\ttotal: 22.2s\tremaining: 49s\n",
      "312:\tlearn: 7.1801737\ttotal: 22.3s\tremaining: 48.9s\n",
      "313:\tlearn: 7.1787519\ttotal: 22.3s\tremaining: 48.8s\n",
      "314:\tlearn: 7.1753459\ttotal: 22.4s\tremaining: 48.7s\n",
      "315:\tlearn: 7.1712783\ttotal: 22.5s\tremaining: 48.6s\n",
      "316:\tlearn: 7.1690637\ttotal: 22.5s\tremaining: 48.5s\n",
      "317:\tlearn: 7.1657100\ttotal: 22.6s\tremaining: 48.5s\n",
      "318:\tlearn: 7.1620503\ttotal: 22.7s\tremaining: 48.4s\n",
      "319:\tlearn: 7.1587767\ttotal: 22.7s\tremaining: 48.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320:\tlearn: 7.1542523\ttotal: 22.8s\tremaining: 48.2s\n",
      "321:\tlearn: 7.1491706\ttotal: 22.8s\tremaining: 48.1s\n",
      "322:\tlearn: 7.1463301\ttotal: 22.9s\tremaining: 48s\n",
      "323:\tlearn: 7.1423775\ttotal: 23s\tremaining: 47.9s\n",
      "324:\tlearn: 7.1385353\ttotal: 23s\tremaining: 47.8s\n",
      "325:\tlearn: 7.1346226\ttotal: 23.1s\tremaining: 47.7s\n",
      "326:\tlearn: 7.1310698\ttotal: 23.1s\tremaining: 47.6s\n",
      "327:\tlearn: 7.1276832\ttotal: 23.2s\tremaining: 47.5s\n",
      "328:\tlearn: 7.1231868\ttotal: 23.3s\tremaining: 47.5s\n",
      "329:\tlearn: 7.1183426\ttotal: 23.3s\tremaining: 47.4s\n",
      "330:\tlearn: 7.1142393\ttotal: 23.4s\tremaining: 47.3s\n",
      "331:\tlearn: 7.1119108\ttotal: 23.5s\tremaining: 47.3s\n",
      "332:\tlearn: 7.1067349\ttotal: 23.6s\tremaining: 47.3s\n",
      "333:\tlearn: 7.1021134\ttotal: 23.7s\tremaining: 47.3s\n",
      "334:\tlearn: 7.0986629\ttotal: 23.8s\tremaining: 47.3s\n",
      "335:\tlearn: 7.0952618\ttotal: 23.9s\tremaining: 47.3s\n",
      "336:\tlearn: 7.0906471\ttotal: 24.1s\tremaining: 47.3s\n",
      "337:\tlearn: 7.0874385\ttotal: 24.2s\tremaining: 47.3s\n",
      "338:\tlearn: 7.0847352\ttotal: 24.3s\tremaining: 47.3s\n",
      "339:\tlearn: 7.0826055\ttotal: 24.4s\tremaining: 47.3s\n",
      "340:\tlearn: 7.0791733\ttotal: 24.5s\tremaining: 47.3s\n",
      "341:\tlearn: 7.0764825\ttotal: 24.6s\tremaining: 47.3s\n",
      "342:\tlearn: 7.0734079\ttotal: 24.7s\tremaining: 47.3s\n",
      "343:\tlearn: 7.0697935\ttotal: 24.8s\tremaining: 47.3s\n",
      "344:\tlearn: 7.0671578\ttotal: 24.9s\tremaining: 47.3s\n",
      "345:\tlearn: 7.0649593\ttotal: 25s\tremaining: 47.3s\n",
      "346:\tlearn: 7.0616365\ttotal: 25.1s\tremaining: 47.3s\n",
      "347:\tlearn: 7.0580692\ttotal: 25.3s\tremaining: 47.3s\n",
      "348:\tlearn: 7.0549114\ttotal: 25.4s\tremaining: 47.3s\n",
      "349:\tlearn: 7.0517684\ttotal: 25.5s\tremaining: 47.3s\n",
      "350:\tlearn: 7.0488063\ttotal: 25.6s\tremaining: 47.3s\n",
      "351:\tlearn: 7.0459275\ttotal: 25.7s\tremaining: 47.3s\n",
      "352:\tlearn: 7.0442973\ttotal: 25.8s\tremaining: 47.3s\n",
      "353:\tlearn: 7.0396930\ttotal: 25.9s\tremaining: 47.3s\n",
      "354:\tlearn: 7.0354890\ttotal: 26s\tremaining: 47.3s\n",
      "355:\tlearn: 7.0318675\ttotal: 26.1s\tremaining: 47.3s\n",
      "356:\tlearn: 7.0313873\ttotal: 26.3s\tremaining: 47.3s\n",
      "357:\tlearn: 7.0278248\ttotal: 26.4s\tremaining: 47.3s\n",
      "358:\tlearn: 7.0249259\ttotal: 26.5s\tremaining: 47.3s\n",
      "359:\tlearn: 7.0198921\ttotal: 26.6s\tremaining: 47.3s\n",
      "360:\tlearn: 7.0165550\ttotal: 26.7s\tremaining: 47.3s\n",
      "361:\tlearn: 7.0121936\ttotal: 26.8s\tremaining: 47.3s\n",
      "362:\tlearn: 7.0082120\ttotal: 26.9s\tremaining: 47.3s\n",
      "363:\tlearn: 7.0041177\ttotal: 27.1s\tremaining: 47.3s\n",
      "364:\tlearn: 7.0013008\ttotal: 27.2s\tremaining: 47.3s\n",
      "365:\tlearn: 7.0004933\ttotal: 27.3s\tremaining: 47.3s\n",
      "366:\tlearn: 6.9972123\ttotal: 27.4s\tremaining: 47.3s\n",
      "367:\tlearn: 6.9950619\ttotal: 27.5s\tremaining: 47.3s\n",
      "368:\tlearn: 6.9914288\ttotal: 27.6s\tremaining: 47.2s\n",
      "369:\tlearn: 6.9877863\ttotal: 27.7s\tremaining: 47.2s\n",
      "370:\tlearn: 6.9846973\ttotal: 27.8s\tremaining: 47.2s\n",
      "371:\tlearn: 6.9806736\ttotal: 28s\tremaining: 47.2s\n",
      "372:\tlearn: 6.9774947\ttotal: 28.1s\tremaining: 47.2s\n",
      "373:\tlearn: 6.9738102\ttotal: 28.2s\tremaining: 47.2s\n",
      "374:\tlearn: 6.9699861\ttotal: 28.3s\tremaining: 47.1s\n",
      "375:\tlearn: 6.9674109\ttotal: 28.4s\tremaining: 47.1s\n",
      "376:\tlearn: 6.9638682\ttotal: 28.5s\tremaining: 47.1s\n",
      "377:\tlearn: 6.9605632\ttotal: 28.6s\tremaining: 47.1s\n",
      "378:\tlearn: 6.9569184\ttotal: 28.7s\tremaining: 47s\n",
      "379:\tlearn: 6.9547354\ttotal: 28.8s\tremaining: 47s\n",
      "380:\tlearn: 6.9503930\ttotal: 28.9s\tremaining: 46.9s\n",
      "381:\tlearn: 6.9469616\ttotal: 28.9s\tremaining: 46.8s\n",
      "382:\tlearn: 6.9433343\ttotal: 29s\tremaining: 46.7s\n",
      "383:\tlearn: 6.9397030\ttotal: 29.1s\tremaining: 46.6s\n",
      "384:\tlearn: 6.9369964\ttotal: 29.1s\tremaining: 46.5s\n",
      "385:\tlearn: 6.9329458\ttotal: 29.2s\tremaining: 46.4s\n",
      "386:\tlearn: 6.9290780\ttotal: 29.2s\tremaining: 46.3s\n",
      "387:\tlearn: 6.9253708\ttotal: 29.3s\tremaining: 46.2s\n",
      "388:\tlearn: 6.9229270\ttotal: 29.4s\tremaining: 46.1s\n",
      "389:\tlearn: 6.9203989\ttotal: 29.4s\tremaining: 46s\n",
      "390:\tlearn: 6.9168874\ttotal: 29.5s\tremaining: 45.9s\n",
      "391:\tlearn: 6.9129519\ttotal: 29.6s\tremaining: 45.8s\n",
      "392:\tlearn: 6.9103307\ttotal: 29.6s\tremaining: 45.7s\n",
      "393:\tlearn: 6.9069934\ttotal: 29.7s\tremaining: 45.6s\n",
      "394:\tlearn: 6.9044794\ttotal: 29.7s\tremaining: 45.5s\n",
      "395:\tlearn: 6.9017296\ttotal: 29.8s\tremaining: 45.4s\n",
      "396:\tlearn: 6.8981392\ttotal: 29.9s\tremaining: 45.3s\n",
      "397:\tlearn: 6.8945616\ttotal: 29.9s\tremaining: 45.3s\n",
      "398:\tlearn: 6.8909862\ttotal: 30s\tremaining: 45.2s\n",
      "399:\tlearn: 6.8866809\ttotal: 30s\tremaining: 45.1s\n",
      "400:\tlearn: 6.8839022\ttotal: 30.1s\tremaining: 45s\n",
      "401:\tlearn: 6.8813540\ttotal: 30.2s\tremaining: 44.9s\n",
      "402:\tlearn: 6.8786198\ttotal: 30.2s\tremaining: 44.8s\n",
      "403:\tlearn: 6.8743515\ttotal: 30.3s\tremaining: 44.7s\n",
      "404:\tlearn: 6.8707461\ttotal: 30.4s\tremaining: 44.6s\n",
      "405:\tlearn: 6.8688348\ttotal: 30.4s\tremaining: 44.5s\n",
      "406:\tlearn: 6.8664073\ttotal: 30.5s\tremaining: 44.4s\n",
      "407:\tlearn: 6.8622768\ttotal: 30.5s\tremaining: 44.3s\n",
      "408:\tlearn: 6.8581114\ttotal: 30.6s\tremaining: 44.2s\n",
      "409:\tlearn: 6.8550681\ttotal: 30.7s\tremaining: 44.1s\n",
      "410:\tlearn: 6.8511804\ttotal: 30.7s\tremaining: 44.1s\n",
      "411:\tlearn: 6.8493244\ttotal: 30.8s\tremaining: 44s\n",
      "412:\tlearn: 6.8453312\ttotal: 30.9s\tremaining: 43.9s\n",
      "413:\tlearn: 6.8425288\ttotal: 30.9s\tremaining: 43.8s\n",
      "414:\tlearn: 6.8377957\ttotal: 31s\tremaining: 43.7s\n",
      "415:\tlearn: 6.8347593\ttotal: 31.1s\tremaining: 43.7s\n",
      "416:\tlearn: 6.8330642\ttotal: 31.2s\tremaining: 43.6s\n",
      "417:\tlearn: 6.8305687\ttotal: 31.2s\tremaining: 43.5s\n",
      "418:\tlearn: 6.8264289\ttotal: 31.3s\tremaining: 43.4s\n",
      "419:\tlearn: 6.8231853\ttotal: 31.4s\tremaining: 43.3s\n",
      "420:\tlearn: 6.8207274\ttotal: 31.4s\tremaining: 43.2s\n",
      "421:\tlearn: 6.8173718\ttotal: 31.5s\tremaining: 43.1s\n",
      "422:\tlearn: 6.8145856\ttotal: 31.6s\tremaining: 43.1s\n",
      "423:\tlearn: 6.8117595\ttotal: 31.6s\tremaining: 43s\n",
      "424:\tlearn: 6.8087253\ttotal: 31.7s\tremaining: 42.9s\n",
      "425:\tlearn: 6.8056952\ttotal: 31.8s\tremaining: 42.8s\n",
      "426:\tlearn: 6.8019912\ttotal: 31.8s\tremaining: 42.7s\n",
      "427:\tlearn: 6.7993798\ttotal: 31.9s\tremaining: 42.6s\n",
      "428:\tlearn: 6.7969756\ttotal: 32s\tremaining: 42.5s\n",
      "429:\tlearn: 6.7946030\ttotal: 32s\tremaining: 42.5s\n",
      "430:\tlearn: 6.7918542\ttotal: 32.1s\tremaining: 42.4s\n",
      "431:\tlearn: 6.7883147\ttotal: 32.2s\tremaining: 42.3s\n",
      "432:\tlearn: 6.7850120\ttotal: 32.3s\tremaining: 42.3s\n",
      "433:\tlearn: 6.7828337\ttotal: 32.3s\tremaining: 42.2s\n",
      "434:\tlearn: 6.7794629\ttotal: 32.4s\tremaining: 42.1s\n",
      "435:\tlearn: 6.7765544\ttotal: 32.5s\tremaining: 42s\n",
      "436:\tlearn: 6.7731927\ttotal: 32.6s\tremaining: 41.9s\n",
      "437:\tlearn: 6.7720816\ttotal: 32.6s\tremaining: 41.9s\n",
      "438:\tlearn: 6.7693420\ttotal: 32.7s\tremaining: 41.8s\n",
      "439:\tlearn: 6.7666508\ttotal: 32.8s\tremaining: 41.7s\n",
      "440:\tlearn: 6.7637078\ttotal: 32.8s\tremaining: 41.6s\n",
      "441:\tlearn: 6.7605711\ttotal: 32.9s\tremaining: 41.5s\n",
      "442:\tlearn: 6.7572190\ttotal: 33s\tremaining: 41.5s\n",
      "443:\tlearn: 6.7546765\ttotal: 33.1s\tremaining: 41.5s\n",
      "444:\tlearn: 6.7517675\ttotal: 33.2s\tremaining: 41.4s\n",
      "445:\tlearn: 6.7484846\ttotal: 33.3s\tremaining: 41.3s\n",
      "446:\tlearn: 6.7452889\ttotal: 33.4s\tremaining: 41.3s\n",
      "447:\tlearn: 6.7441892\ttotal: 33.4s\tremaining: 41.2s\n",
      "448:\tlearn: 6.7413874\ttotal: 33.5s\tremaining: 41.1s\n",
      "449:\tlearn: 6.7379109\ttotal: 33.6s\tremaining: 41.1s\n",
      "450:\tlearn: 6.7350298\ttotal: 33.7s\tremaining: 41s\n",
      "451:\tlearn: 6.7321358\ttotal: 33.8s\tremaining: 40.9s\n",
      "452:\tlearn: 6.7295862\ttotal: 33.8s\tremaining: 40.9s\n",
      "453:\tlearn: 6.7267688\ttotal: 33.9s\tremaining: 40.8s\n",
      "454:\tlearn: 6.7239752\ttotal: 34s\tremaining: 40.7s\n",
      "455:\tlearn: 6.7194515\ttotal: 34.1s\tremaining: 40.6s\n",
      "456:\tlearn: 6.7171588\ttotal: 34.1s\tremaining: 40.6s\n",
      "457:\tlearn: 6.7146033\ttotal: 34.2s\tremaining: 40.5s\n",
      "458:\tlearn: 6.7123734\ttotal: 34.3s\tremaining: 40.4s\n",
      "459:\tlearn: 6.7117945\ttotal: 34.4s\tremaining: 40.4s\n",
      "460:\tlearn: 6.7081304\ttotal: 34.5s\tremaining: 40.3s\n",
      "461:\tlearn: 6.7071529\ttotal: 34.5s\tremaining: 40.2s\n",
      "462:\tlearn: 6.7039863\ttotal: 34.6s\tremaining: 40.1s\n",
      "463:\tlearn: 6.7005387\ttotal: 34.7s\tremaining: 40.1s\n",
      "464:\tlearn: 6.6975838\ttotal: 34.8s\tremaining: 40s\n",
      "465:\tlearn: 6.6941292\ttotal: 34.8s\tremaining: 39.9s\n",
      "466:\tlearn: 6.6920757\ttotal: 34.9s\tremaining: 39.8s\n",
      "467:\tlearn: 6.6890634\ttotal: 35s\tremaining: 39.8s\n",
      "468:\tlearn: 6.6869028\ttotal: 35.1s\tremaining: 39.7s\n",
      "469:\tlearn: 6.6838158\ttotal: 35.2s\tremaining: 39.7s\n",
      "470:\tlearn: 6.6802425\ttotal: 35.3s\tremaining: 39.6s\n",
      "471:\tlearn: 6.6761307\ttotal: 35.4s\tremaining: 39.5s\n",
      "472:\tlearn: 6.6728996\ttotal: 35.4s\tremaining: 39.5s\n",
      "473:\tlearn: 6.6702243\ttotal: 35.5s\tremaining: 39.4s\n",
      "474:\tlearn: 6.6663321\ttotal: 35.6s\tremaining: 39.4s\n",
      "475:\tlearn: 6.6645526\ttotal: 35.7s\tremaining: 39.3s\n",
      "476:\tlearn: 6.6606648\ttotal: 35.8s\tremaining: 39.3s\n",
      "477:\tlearn: 6.6573698\ttotal: 35.9s\tremaining: 39.2s\n",
      "478:\tlearn: 6.6548141\ttotal: 36s\tremaining: 39.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479:\tlearn: 6.6516809\ttotal: 36.1s\tremaining: 39.1s\n",
      "480:\tlearn: 6.6475658\ttotal: 36.2s\tremaining: 39s\n",
      "481:\tlearn: 6.6448957\ttotal: 36.2s\tremaining: 38.9s\n",
      "482:\tlearn: 6.6417959\ttotal: 36.3s\tremaining: 38.9s\n",
      "483:\tlearn: 6.6389116\ttotal: 36.4s\tremaining: 38.8s\n",
      "484:\tlearn: 6.6344862\ttotal: 36.5s\tremaining: 38.8s\n",
      "485:\tlearn: 6.6312786\ttotal: 36.6s\tremaining: 38.7s\n",
      "486:\tlearn: 6.6281563\ttotal: 36.7s\tremaining: 38.6s\n",
      "487:\tlearn: 6.6253159\ttotal: 36.7s\tremaining: 38.6s\n",
      "488:\tlearn: 6.6226224\ttotal: 36.8s\tremaining: 38.5s\n",
      "489:\tlearn: 6.6201802\ttotal: 36.9s\tremaining: 38.4s\n",
      "490:\tlearn: 6.6168062\ttotal: 37s\tremaining: 38.3s\n",
      "491:\tlearn: 6.6133317\ttotal: 37s\tremaining: 38.2s\n",
      "492:\tlearn: 6.6097341\ttotal: 37.1s\tremaining: 38.2s\n",
      "493:\tlearn: 6.6052643\ttotal: 37.2s\tremaining: 38.1s\n",
      "494:\tlearn: 6.6030386\ttotal: 37.3s\tremaining: 38s\n",
      "495:\tlearn: 6.6005186\ttotal: 37.3s\tremaining: 37.9s\n",
      "496:\tlearn: 6.5974447\ttotal: 37.4s\tremaining: 37.9s\n",
      "497:\tlearn: 6.5945537\ttotal: 37.5s\tremaining: 37.8s\n",
      "498:\tlearn: 6.5912515\ttotal: 37.6s\tremaining: 37.7s\n",
      "499:\tlearn: 6.5890427\ttotal: 37.6s\tremaining: 37.6s\n",
      "500:\tlearn: 6.5858343\ttotal: 37.7s\tremaining: 37.5s\n",
      "501:\tlearn: 6.5843007\ttotal: 37.8s\tremaining: 37.5s\n",
      "502:\tlearn: 6.5818308\ttotal: 37.8s\tremaining: 37.4s\n",
      "503:\tlearn: 6.5792411\ttotal: 37.9s\tremaining: 37.3s\n",
      "504:\tlearn: 6.5761177\ttotal: 38s\tremaining: 37.2s\n",
      "505:\tlearn: 6.5729820\ttotal: 38.1s\tremaining: 37.2s\n",
      "506:\tlearn: 6.5696349\ttotal: 38.1s\tremaining: 37.1s\n",
      "507:\tlearn: 6.5668287\ttotal: 38.2s\tremaining: 37s\n",
      "508:\tlearn: 6.5636673\ttotal: 38.3s\tremaining: 36.9s\n",
      "509:\tlearn: 6.5596804\ttotal: 38.4s\tremaining: 36.9s\n",
      "510:\tlearn: 6.5578209\ttotal: 38.4s\tremaining: 36.8s\n",
      "511:\tlearn: 6.5544080\ttotal: 38.5s\tremaining: 36.7s\n",
      "512:\tlearn: 6.5522399\ttotal: 38.6s\tremaining: 36.6s\n",
      "513:\tlearn: 6.5502536\ttotal: 38.6s\tremaining: 36.5s\n",
      "514:\tlearn: 6.5474212\ttotal: 38.7s\tremaining: 36.5s\n",
      "515:\tlearn: 6.5445356\ttotal: 38.8s\tremaining: 36.4s\n",
      "516:\tlearn: 6.5419310\ttotal: 38.9s\tremaining: 36.4s\n",
      "517:\tlearn: 6.5386411\ttotal: 39s\tremaining: 36.3s\n",
      "518:\tlearn: 6.5352022\ttotal: 39.1s\tremaining: 36.2s\n",
      "519:\tlearn: 6.5326812\ttotal: 39.1s\tremaining: 36.1s\n",
      "520:\tlearn: 6.5294543\ttotal: 39.2s\tremaining: 36s\n",
      "521:\tlearn: 6.5265584\ttotal: 39.3s\tremaining: 36s\n",
      "522:\tlearn: 6.5232049\ttotal: 39.3s\tremaining: 35.9s\n",
      "523:\tlearn: 6.5205381\ttotal: 39.4s\tremaining: 35.8s\n",
      "524:\tlearn: 6.5167998\ttotal: 39.5s\tremaining: 35.7s\n",
      "525:\tlearn: 6.5135661\ttotal: 39.6s\tremaining: 35.6s\n",
      "526:\tlearn: 6.5098253\ttotal: 39.6s\tremaining: 35.6s\n",
      "527:\tlearn: 6.5073208\ttotal: 39.7s\tremaining: 35.5s\n",
      "528:\tlearn: 6.5035236\ttotal: 39.8s\tremaining: 35.5s\n",
      "529:\tlearn: 6.5000918\ttotal: 39.9s\tremaining: 35.4s\n",
      "530:\tlearn: 6.4960368\ttotal: 40s\tremaining: 35.3s\n",
      "531:\tlearn: 6.4931587\ttotal: 40.1s\tremaining: 35.3s\n",
      "532:\tlearn: 6.4906445\ttotal: 40.2s\tremaining: 35.2s\n",
      "533:\tlearn: 6.4874749\ttotal: 40.2s\tremaining: 35.1s\n",
      "534:\tlearn: 6.4838976\ttotal: 40.3s\tremaining: 35.1s\n",
      "535:\tlearn: 6.4812817\ttotal: 40.4s\tremaining: 35s\n",
      "536:\tlearn: 6.4805480\ttotal: 40.5s\tremaining: 34.9s\n",
      "537:\tlearn: 6.4775540\ttotal: 40.6s\tremaining: 34.9s\n",
      "538:\tlearn: 6.4755255\ttotal: 40.7s\tremaining: 34.8s\n",
      "539:\tlearn: 6.4724648\ttotal: 40.8s\tremaining: 34.7s\n",
      "540:\tlearn: 6.4703679\ttotal: 40.9s\tremaining: 34.7s\n",
      "541:\tlearn: 6.4695471\ttotal: 40.9s\tremaining: 34.6s\n",
      "542:\tlearn: 6.4692483\ttotal: 41s\tremaining: 34.5s\n",
      "543:\tlearn: 6.4656589\ttotal: 41.1s\tremaining: 34.4s\n",
      "544:\tlearn: 6.4625551\ttotal: 41.2s\tremaining: 34.4s\n",
      "545:\tlearn: 6.4605828\ttotal: 41.2s\tremaining: 34.3s\n",
      "546:\tlearn: 6.4567499\ttotal: 41.4s\tremaining: 34.3s\n",
      "547:\tlearn: 6.4540838\ttotal: 41.4s\tremaining: 34.2s\n",
      "548:\tlearn: 6.4510634\ttotal: 41.5s\tremaining: 34.1s\n",
      "549:\tlearn: 6.4483152\ttotal: 41.6s\tremaining: 34s\n",
      "550:\tlearn: 6.4454595\ttotal: 41.7s\tremaining: 34s\n",
      "551:\tlearn: 6.4418853\ttotal: 41.8s\tremaining: 33.9s\n",
      "552:\tlearn: 6.4398180\ttotal: 41.9s\tremaining: 33.8s\n",
      "553:\tlearn: 6.4371549\ttotal: 41.9s\tremaining: 33.8s\n",
      "554:\tlearn: 6.4340264\ttotal: 42s\tremaining: 33.7s\n",
      "555:\tlearn: 6.4308422\ttotal: 42.1s\tremaining: 33.6s\n",
      "556:\tlearn: 6.4282485\ttotal: 42.2s\tremaining: 33.6s\n",
      "557:\tlearn: 6.4253838\ttotal: 42.3s\tremaining: 33.5s\n",
      "558:\tlearn: 6.4224249\ttotal: 42.4s\tremaining: 33.4s\n",
      "559:\tlearn: 6.4196233\ttotal: 42.4s\tremaining: 33.3s\n",
      "560:\tlearn: 6.4168029\ttotal: 42.5s\tremaining: 33.3s\n",
      "561:\tlearn: 6.4141582\ttotal: 42.6s\tremaining: 33.2s\n",
      "562:\tlearn: 6.4105451\ttotal: 42.7s\tremaining: 33.1s\n",
      "563:\tlearn: 6.4079961\ttotal: 42.8s\tremaining: 33.1s\n",
      "564:\tlearn: 6.4067791\ttotal: 42.9s\tremaining: 33s\n",
      "565:\tlearn: 6.4053656\ttotal: 42.9s\tremaining: 32.9s\n",
      "566:\tlearn: 6.4008933\ttotal: 43s\tremaining: 32.9s\n",
      "567:\tlearn: 6.3979816\ttotal: 43.1s\tremaining: 32.8s\n",
      "568:\tlearn: 6.3943756\ttotal: 43.2s\tremaining: 32.7s\n",
      "569:\tlearn: 6.3916623\ttotal: 43.3s\tremaining: 32.6s\n",
      "570:\tlearn: 6.3904915\ttotal: 43.4s\tremaining: 32.6s\n",
      "571:\tlearn: 6.3866671\ttotal: 43.4s\tremaining: 32.5s\n",
      "572:\tlearn: 6.3840065\ttotal: 43.5s\tremaining: 32.4s\n",
      "573:\tlearn: 6.3801379\ttotal: 43.6s\tremaining: 32.4s\n",
      "574:\tlearn: 6.3768947\ttotal: 43.7s\tremaining: 32.3s\n",
      "575:\tlearn: 6.3748708\ttotal: 43.7s\tremaining: 32.2s\n",
      "576:\tlearn: 6.3745122\ttotal: 43.8s\tremaining: 32.1s\n",
      "577:\tlearn: 6.3717901\ttotal: 43.9s\tremaining: 32s\n",
      "578:\tlearn: 6.3712882\ttotal: 44s\tremaining: 32s\n",
      "579:\tlearn: 6.3675582\ttotal: 44s\tremaining: 31.9s\n",
      "580:\tlearn: 6.3641591\ttotal: 44.1s\tremaining: 31.8s\n",
      "581:\tlearn: 6.3607392\ttotal: 44.2s\tremaining: 31.7s\n",
      "582:\tlearn: 6.3579929\ttotal: 44.3s\tremaining: 31.7s\n",
      "583:\tlearn: 6.3560890\ttotal: 44.3s\tremaining: 31.6s\n",
      "584:\tlearn: 6.3537104\ttotal: 44.4s\tremaining: 31.5s\n",
      "585:\tlearn: 6.3492628\ttotal: 44.5s\tremaining: 31.4s\n",
      "586:\tlearn: 6.3464403\ttotal: 44.6s\tremaining: 31.4s\n",
      "587:\tlearn: 6.3429426\ttotal: 44.6s\tremaining: 31.3s\n",
      "588:\tlearn: 6.3398818\ttotal: 44.7s\tremaining: 31.2s\n",
      "589:\tlearn: 6.3372713\ttotal: 44.8s\tremaining: 31.1s\n",
      "590:\tlearn: 6.3334186\ttotal: 44.9s\tremaining: 31.1s\n",
      "591:\tlearn: 6.3314141\ttotal: 45s\tremaining: 31s\n",
      "592:\tlearn: 6.3293208\ttotal: 45s\tremaining: 30.9s\n",
      "593:\tlearn: 6.3267397\ttotal: 45.1s\tremaining: 30.8s\n",
      "594:\tlearn: 6.3243717\ttotal: 45.2s\tremaining: 30.8s\n",
      "595:\tlearn: 6.3215028\ttotal: 45.3s\tremaining: 30.7s\n",
      "596:\tlearn: 6.3189547\ttotal: 45.4s\tremaining: 30.6s\n",
      "597:\tlearn: 6.3171019\ttotal: 45.4s\tremaining: 30.5s\n",
      "598:\tlearn: 6.3132687\ttotal: 45.5s\tremaining: 30.5s\n",
      "599:\tlearn: 6.3110060\ttotal: 45.6s\tremaining: 30.4s\n",
      "600:\tlearn: 6.3075951\ttotal: 45.7s\tremaining: 30.3s\n",
      "601:\tlearn: 6.3042791\ttotal: 45.7s\tremaining: 30.2s\n",
      "602:\tlearn: 6.3019121\ttotal: 45.8s\tremaining: 30.2s\n",
      "603:\tlearn: 6.2988649\ttotal: 45.9s\tremaining: 30.1s\n",
      "604:\tlearn: 6.2970942\ttotal: 46s\tremaining: 30s\n",
      "605:\tlearn: 6.2946077\ttotal: 46s\tremaining: 29.9s\n",
      "606:\tlearn: 6.2909058\ttotal: 46.1s\tremaining: 29.8s\n",
      "607:\tlearn: 6.2876888\ttotal: 46.2s\tremaining: 29.8s\n",
      "608:\tlearn: 6.2835666\ttotal: 46.2s\tremaining: 29.7s\n",
      "609:\tlearn: 6.2812746\ttotal: 46.3s\tremaining: 29.6s\n",
      "610:\tlearn: 6.2801096\ttotal: 46.4s\tremaining: 29.5s\n",
      "611:\tlearn: 6.2765357\ttotal: 46.5s\tremaining: 29.5s\n",
      "612:\tlearn: 6.2736935\ttotal: 46.5s\tremaining: 29.4s\n",
      "613:\tlearn: 6.2713890\ttotal: 46.6s\tremaining: 29.3s\n",
      "614:\tlearn: 6.2683646\ttotal: 46.7s\tremaining: 29.2s\n",
      "615:\tlearn: 6.2659370\ttotal: 46.8s\tremaining: 29.2s\n",
      "616:\tlearn: 6.2638876\ttotal: 46.8s\tremaining: 29.1s\n",
      "617:\tlearn: 6.2615328\ttotal: 46.9s\tremaining: 29s\n",
      "618:\tlearn: 6.2593009\ttotal: 47s\tremaining: 28.9s\n",
      "619:\tlearn: 6.2568806\ttotal: 47.1s\tremaining: 28.8s\n",
      "620:\tlearn: 6.2544169\ttotal: 47.1s\tremaining: 28.8s\n",
      "621:\tlearn: 6.2530145\ttotal: 47.2s\tremaining: 28.7s\n",
      "622:\tlearn: 6.2504896\ttotal: 47.3s\tremaining: 28.6s\n",
      "623:\tlearn: 6.2475890\ttotal: 47.4s\tremaining: 28.5s\n",
      "624:\tlearn: 6.2451465\ttotal: 47.4s\tremaining: 28.5s\n",
      "625:\tlearn: 6.2434488\ttotal: 47.5s\tremaining: 28.4s\n",
      "626:\tlearn: 6.2405730\ttotal: 47.6s\tremaining: 28.3s\n",
      "627:\tlearn: 6.2380184\ttotal: 47.7s\tremaining: 28.3s\n",
      "628:\tlearn: 6.2346685\ttotal: 47.8s\tremaining: 28.2s\n",
      "629:\tlearn: 6.2320463\ttotal: 47.9s\tremaining: 28.1s\n",
      "630:\tlearn: 6.2291418\ttotal: 47.9s\tremaining: 28s\n",
      "631:\tlearn: 6.2268498\ttotal: 48s\tremaining: 28s\n",
      "632:\tlearn: 6.2230591\ttotal: 48.1s\tremaining: 27.9s\n",
      "633:\tlearn: 6.2210016\ttotal: 48.2s\tremaining: 27.8s\n",
      "634:\tlearn: 6.2179407\ttotal: 48.3s\tremaining: 27.7s\n",
      "635:\tlearn: 6.2150339\ttotal: 48.3s\tremaining: 27.7s\n",
      "636:\tlearn: 6.2130610\ttotal: 48.4s\tremaining: 27.6s\n",
      "637:\tlearn: 6.2115034\ttotal: 48.5s\tremaining: 27.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638:\tlearn: 6.2113450\ttotal: 48.6s\tremaining: 27.4s\n",
      "639:\tlearn: 6.2084765\ttotal: 48.7s\tremaining: 27.4s\n",
      "640:\tlearn: 6.2059248\ttotal: 48.7s\tremaining: 27.3s\n",
      "641:\tlearn: 6.2034632\ttotal: 48.8s\tremaining: 27.2s\n",
      "642:\tlearn: 6.1991501\ttotal: 48.9s\tremaining: 27.2s\n",
      "643:\tlearn: 6.1972107\ttotal: 49s\tremaining: 27.1s\n",
      "644:\tlearn: 6.1948107\ttotal: 49.1s\tremaining: 27s\n",
      "645:\tlearn: 6.1923554\ttotal: 49.2s\tremaining: 26.9s\n",
      "646:\tlearn: 6.1900123\ttotal: 49.2s\tremaining: 26.9s\n",
      "647:\tlearn: 6.1861770\ttotal: 49.3s\tremaining: 26.8s\n",
      "648:\tlearn: 6.1831728\ttotal: 49.4s\tremaining: 26.7s\n",
      "649:\tlearn: 6.1807528\ttotal: 49.5s\tremaining: 26.7s\n",
      "650:\tlearn: 6.1784525\ttotal: 49.6s\tremaining: 26.6s\n",
      "651:\tlearn: 6.1756294\ttotal: 49.7s\tremaining: 26.5s\n",
      "652:\tlearn: 6.1735468\ttotal: 49.8s\tremaining: 26.4s\n",
      "653:\tlearn: 6.1700558\ttotal: 49.8s\tremaining: 26.4s\n",
      "654:\tlearn: 6.1676225\ttotal: 49.9s\tremaining: 26.3s\n",
      "655:\tlearn: 6.1641378\ttotal: 50s\tremaining: 26.2s\n",
      "656:\tlearn: 6.1610659\ttotal: 50.1s\tremaining: 26.1s\n",
      "657:\tlearn: 6.1587727\ttotal: 50.2s\tremaining: 26.1s\n",
      "658:\tlearn: 6.1571608\ttotal: 50.2s\tremaining: 26s\n",
      "659:\tlearn: 6.1541431\ttotal: 50.3s\tremaining: 25.9s\n",
      "660:\tlearn: 6.1516265\ttotal: 50.4s\tremaining: 25.8s\n",
      "661:\tlearn: 6.1490187\ttotal: 50.5s\tremaining: 25.8s\n",
      "662:\tlearn: 6.1455374\ttotal: 50.6s\tremaining: 25.7s\n",
      "663:\tlearn: 6.1425041\ttotal: 50.7s\tremaining: 25.6s\n",
      "664:\tlearn: 6.1392822\ttotal: 50.7s\tremaining: 25.6s\n",
      "665:\tlearn: 6.1370834\ttotal: 50.8s\tremaining: 25.5s\n",
      "666:\tlearn: 6.1358524\ttotal: 50.9s\tremaining: 25.4s\n",
      "667:\tlearn: 6.1324859\ttotal: 51s\tremaining: 25.3s\n",
      "668:\tlearn: 6.1294643\ttotal: 51.1s\tremaining: 25.3s\n",
      "669:\tlearn: 6.1271436\ttotal: 51.1s\tremaining: 25.2s\n",
      "670:\tlearn: 6.1238218\ttotal: 51.2s\tremaining: 25.1s\n",
      "671:\tlearn: 6.1211609\ttotal: 51.3s\tremaining: 25s\n",
      "672:\tlearn: 6.1181640\ttotal: 51.4s\tremaining: 25s\n",
      "673:\tlearn: 6.1149831\ttotal: 51.5s\tremaining: 24.9s\n",
      "674:\tlearn: 6.1119540\ttotal: 51.6s\tremaining: 24.8s\n",
      "675:\tlearn: 6.1086772\ttotal: 51.7s\tremaining: 24.8s\n",
      "676:\tlearn: 6.1059682\ttotal: 51.8s\tremaining: 24.7s\n",
      "677:\tlearn: 6.1027450\ttotal: 51.8s\tremaining: 24.6s\n",
      "678:\tlearn: 6.1007117\ttotal: 51.9s\tremaining: 24.5s\n",
      "679:\tlearn: 6.0989962\ttotal: 52s\tremaining: 24.5s\n",
      "680:\tlearn: 6.0969607\ttotal: 52.1s\tremaining: 24.4s\n",
      "681:\tlearn: 6.0945294\ttotal: 52.2s\tremaining: 24.3s\n",
      "682:\tlearn: 6.0919929\ttotal: 52.3s\tremaining: 24.3s\n",
      "683:\tlearn: 6.0886230\ttotal: 52.3s\tremaining: 24.2s\n",
      "684:\tlearn: 6.0859780\ttotal: 52.4s\tremaining: 24.1s\n",
      "685:\tlearn: 6.0827011\ttotal: 52.5s\tremaining: 24s\n",
      "686:\tlearn: 6.0801320\ttotal: 52.6s\tremaining: 23.9s\n",
      "687:\tlearn: 6.0774642\ttotal: 52.6s\tremaining: 23.9s\n",
      "688:\tlearn: 6.0739015\ttotal: 52.7s\tremaining: 23.8s\n",
      "689:\tlearn: 6.0714499\ttotal: 52.8s\tremaining: 23.7s\n",
      "690:\tlearn: 6.0685847\ttotal: 52.9s\tremaining: 23.6s\n",
      "691:\tlearn: 6.0659408\ttotal: 52.9s\tremaining: 23.6s\n",
      "692:\tlearn: 6.0614465\ttotal: 53s\tremaining: 23.5s\n",
      "693:\tlearn: 6.0582014\ttotal: 53.1s\tremaining: 23.4s\n",
      "694:\tlearn: 6.0566284\ttotal: 53.2s\tremaining: 23.3s\n",
      "695:\tlearn: 6.0540208\ttotal: 53.2s\tremaining: 23.3s\n",
      "696:\tlearn: 6.0513485\ttotal: 53.3s\tremaining: 23.2s\n",
      "697:\tlearn: 6.0485922\ttotal: 53.4s\tremaining: 23.1s\n",
      "698:\tlearn: 6.0467240\ttotal: 53.5s\tremaining: 23s\n",
      "699:\tlearn: 6.0438594\ttotal: 53.5s\tremaining: 22.9s\n",
      "700:\tlearn: 6.0418363\ttotal: 53.6s\tremaining: 22.9s\n",
      "701:\tlearn: 6.0378194\ttotal: 53.7s\tremaining: 22.8s\n",
      "702:\tlearn: 6.0353583\ttotal: 53.8s\tremaining: 22.7s\n",
      "703:\tlearn: 6.0325895\ttotal: 53.8s\tremaining: 22.6s\n",
      "704:\tlearn: 6.0310085\ttotal: 53.9s\tremaining: 22.6s\n",
      "705:\tlearn: 6.0281569\ttotal: 54s\tremaining: 22.5s\n",
      "706:\tlearn: 6.0263090\ttotal: 54.1s\tremaining: 22.4s\n",
      "707:\tlearn: 6.0249830\ttotal: 54.1s\tremaining: 22.3s\n",
      "708:\tlearn: 6.0221322\ttotal: 54.2s\tremaining: 22.3s\n",
      "709:\tlearn: 6.0190020\ttotal: 54.3s\tremaining: 22.2s\n",
      "710:\tlearn: 6.0171607\ttotal: 54.4s\tremaining: 22.1s\n",
      "711:\tlearn: 6.0132529\ttotal: 54.5s\tremaining: 22s\n",
      "712:\tlearn: 6.0112506\ttotal: 54.5s\tremaining: 22s\n",
      "713:\tlearn: 6.0084336\ttotal: 54.6s\tremaining: 21.9s\n",
      "714:\tlearn: 6.0051795\ttotal: 54.7s\tremaining: 21.8s\n",
      "715:\tlearn: 6.0032127\ttotal: 54.8s\tremaining: 21.7s\n",
      "716:\tlearn: 6.0004715\ttotal: 54.9s\tremaining: 21.7s\n",
      "717:\tlearn: 5.9974540\ttotal: 54.9s\tremaining: 21.6s\n",
      "718:\tlearn: 5.9948620\ttotal: 55s\tremaining: 21.5s\n",
      "719:\tlearn: 5.9932365\ttotal: 55.1s\tremaining: 21.4s\n",
      "720:\tlearn: 5.9904607\ttotal: 55.2s\tremaining: 21.4s\n",
      "721:\tlearn: 5.9887001\ttotal: 55.3s\tremaining: 21.3s\n",
      "722:\tlearn: 5.9865421\ttotal: 55.3s\tremaining: 21.2s\n",
      "723:\tlearn: 5.9838357\ttotal: 55.4s\tremaining: 21.1s\n",
      "724:\tlearn: 5.9816820\ttotal: 55.5s\tremaining: 21s\n",
      "725:\tlearn: 5.9789799\ttotal: 55.6s\tremaining: 21s\n",
      "726:\tlearn: 5.9775915\ttotal: 55.7s\tremaining: 20.9s\n",
      "727:\tlearn: 5.9757059\ttotal: 55.7s\tremaining: 20.8s\n",
      "728:\tlearn: 5.9726016\ttotal: 55.8s\tremaining: 20.7s\n",
      "729:\tlearn: 5.9706056\ttotal: 55.9s\tremaining: 20.7s\n",
      "730:\tlearn: 5.9673626\ttotal: 56s\tremaining: 20.6s\n",
      "731:\tlearn: 5.9648965\ttotal: 56s\tremaining: 20.5s\n",
      "732:\tlearn: 5.9627112\ttotal: 56.1s\tremaining: 20.4s\n",
      "733:\tlearn: 5.9605963\ttotal: 56.2s\tremaining: 20.4s\n",
      "734:\tlearn: 5.9574050\ttotal: 56.3s\tremaining: 20.3s\n",
      "735:\tlearn: 5.9548930\ttotal: 56.4s\tremaining: 20.2s\n",
      "736:\tlearn: 5.9522026\ttotal: 56.4s\tremaining: 20.1s\n",
      "737:\tlearn: 5.9494236\ttotal: 56.5s\tremaining: 20.1s\n",
      "738:\tlearn: 5.9463364\ttotal: 56.6s\tremaining: 20s\n",
      "739:\tlearn: 5.9440638\ttotal: 56.7s\tremaining: 19.9s\n",
      "740:\tlearn: 5.9421932\ttotal: 56.8s\tremaining: 19.8s\n",
      "741:\tlearn: 5.9413050\ttotal: 56.8s\tremaining: 19.8s\n",
      "742:\tlearn: 5.9410959\ttotal: 56.9s\tremaining: 19.7s\n",
      "743:\tlearn: 5.9391023\ttotal: 57s\tremaining: 19.6s\n",
      "744:\tlearn: 5.9366499\ttotal: 57.1s\tremaining: 19.5s\n",
      "745:\tlearn: 5.9347461\ttotal: 57.2s\tremaining: 19.5s\n",
      "746:\tlearn: 5.9311635\ttotal: 57.2s\tremaining: 19.4s\n",
      "747:\tlearn: 5.9293660\ttotal: 57.3s\tremaining: 19.3s\n",
      "748:\tlearn: 5.9280859\ttotal: 57.4s\tremaining: 19.2s\n",
      "749:\tlearn: 5.9256418\ttotal: 57.5s\tremaining: 19.2s\n",
      "750:\tlearn: 5.9229694\ttotal: 57.6s\tremaining: 19.1s\n",
      "751:\tlearn: 5.9210682\ttotal: 57.6s\tremaining: 19s\n",
      "752:\tlearn: 5.9179233\ttotal: 57.7s\tremaining: 18.9s\n",
      "753:\tlearn: 5.9151055\ttotal: 57.8s\tremaining: 18.9s\n",
      "754:\tlearn: 5.9124760\ttotal: 57.9s\tremaining: 18.8s\n",
      "755:\tlearn: 5.9109568\ttotal: 58s\tremaining: 18.7s\n",
      "756:\tlearn: 5.9089074\ttotal: 58.1s\tremaining: 18.6s\n",
      "757:\tlearn: 5.9054323\ttotal: 58.2s\tremaining: 18.6s\n",
      "758:\tlearn: 5.9037254\ttotal: 58.3s\tremaining: 18.5s\n",
      "759:\tlearn: 5.9017190\ttotal: 58.4s\tremaining: 18.4s\n",
      "760:\tlearn: 5.8998702\ttotal: 58.4s\tremaining: 18.4s\n",
      "761:\tlearn: 5.8973068\ttotal: 58.5s\tremaining: 18.3s\n",
      "762:\tlearn: 5.8951701\ttotal: 58.6s\tremaining: 18.2s\n",
      "763:\tlearn: 5.8924752\ttotal: 58.6s\tremaining: 18.1s\n",
      "764:\tlearn: 5.8907102\ttotal: 58.7s\tremaining: 18s\n",
      "765:\tlearn: 5.8885062\ttotal: 58.8s\tremaining: 18s\n",
      "766:\tlearn: 5.8881306\ttotal: 58.8s\tremaining: 17.9s\n",
      "767:\tlearn: 5.8854153\ttotal: 58.9s\tremaining: 17.8s\n",
      "768:\tlearn: 5.8836231\ttotal: 59s\tremaining: 17.7s\n",
      "769:\tlearn: 5.8818533\ttotal: 59s\tremaining: 17.6s\n",
      "770:\tlearn: 5.8787079\ttotal: 59.1s\tremaining: 17.6s\n",
      "771:\tlearn: 5.8757235\ttotal: 59.2s\tremaining: 17.5s\n",
      "772:\tlearn: 5.8728455\ttotal: 59.2s\tremaining: 17.4s\n",
      "773:\tlearn: 5.8707798\ttotal: 59.3s\tremaining: 17.3s\n",
      "774:\tlearn: 5.8684292\ttotal: 59.4s\tremaining: 17.2s\n",
      "775:\tlearn: 5.8659695\ttotal: 59.4s\tremaining: 17.2s\n",
      "776:\tlearn: 5.8646953\ttotal: 59.5s\tremaining: 17.1s\n",
      "777:\tlearn: 5.8621369\ttotal: 59.6s\tremaining: 17s\n",
      "778:\tlearn: 5.8600864\ttotal: 59.7s\tremaining: 16.9s\n",
      "779:\tlearn: 5.8572827\ttotal: 59.7s\tremaining: 16.8s\n",
      "780:\tlearn: 5.8548851\ttotal: 59.8s\tremaining: 16.8s\n",
      "781:\tlearn: 5.8529492\ttotal: 59.9s\tremaining: 16.7s\n",
      "782:\tlearn: 5.8506509\ttotal: 59.9s\tremaining: 16.6s\n",
      "783:\tlearn: 5.8487218\ttotal: 60s\tremaining: 16.5s\n",
      "784:\tlearn: 5.8469641\ttotal: 1m\tremaining: 16.4s\n",
      "785:\tlearn: 5.8450738\ttotal: 1m\tremaining: 16.4s\n",
      "786:\tlearn: 5.8426121\ttotal: 1m\tremaining: 16.3s\n",
      "787:\tlearn: 5.8406535\ttotal: 1m\tremaining: 16.2s\n",
      "788:\tlearn: 5.8375847\ttotal: 1m\tremaining: 16.1s\n",
      "789:\tlearn: 5.8349525\ttotal: 1m\tremaining: 16.1s\n",
      "790:\tlearn: 5.8324509\ttotal: 1m\tremaining: 16s\n",
      "791:\tlearn: 5.8304514\ttotal: 1m\tremaining: 15.9s\n",
      "792:\tlearn: 5.8285703\ttotal: 1m\tremaining: 15.8s\n",
      "793:\tlearn: 5.8259202\ttotal: 1m\tremaining: 15.8s\n",
      "794:\tlearn: 5.8233175\ttotal: 1m\tremaining: 15.7s\n",
      "795:\tlearn: 5.8215094\ttotal: 1m\tremaining: 15.6s\n",
      "796:\tlearn: 5.8189225\ttotal: 1m\tremaining: 15.5s\n",
      "797:\tlearn: 5.8166106\ttotal: 1m 1s\tremaining: 15.4s\n",
      "798:\tlearn: 5.8146076\ttotal: 1m 1s\tremaining: 15.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799:\tlearn: 5.8121913\ttotal: 1m 1s\tremaining: 15.3s\n",
      "800:\tlearn: 5.8098410\ttotal: 1m 1s\tremaining: 15.2s\n",
      "801:\tlearn: 5.8072153\ttotal: 1m 1s\tremaining: 15.1s\n",
      "802:\tlearn: 5.8044351\ttotal: 1m 1s\tremaining: 15.1s\n",
      "803:\tlearn: 5.8013377\ttotal: 1m 1s\tremaining: 15s\n",
      "804:\tlearn: 5.8005849\ttotal: 1m 1s\tremaining: 14.9s\n",
      "805:\tlearn: 5.7981549\ttotal: 1m 1s\tremaining: 14.8s\n",
      "806:\tlearn: 5.7954295\ttotal: 1m 1s\tremaining: 14.7s\n",
      "807:\tlearn: 5.7932843\ttotal: 1m 1s\tremaining: 14.7s\n",
      "808:\tlearn: 5.7910972\ttotal: 1m 1s\tremaining: 14.6s\n",
      "809:\tlearn: 5.7885026\ttotal: 1m 1s\tremaining: 14.5s\n",
      "810:\tlearn: 5.7860838\ttotal: 1m 1s\tremaining: 14.4s\n",
      "811:\tlearn: 5.7839538\ttotal: 1m 1s\tremaining: 14.4s\n",
      "812:\tlearn: 5.7799160\ttotal: 1m 2s\tremaining: 14.3s\n",
      "813:\tlearn: 5.7778329\ttotal: 1m 2s\tremaining: 14.2s\n",
      "814:\tlearn: 5.7754887\ttotal: 1m 2s\tremaining: 14.1s\n",
      "815:\tlearn: 5.7728781\ttotal: 1m 2s\tremaining: 14s\n",
      "816:\tlearn: 5.7698904\ttotal: 1m 2s\tremaining: 14s\n",
      "817:\tlearn: 5.7675910\ttotal: 1m 2s\tremaining: 13.9s\n",
      "818:\tlearn: 5.7653866\ttotal: 1m 2s\tremaining: 13.8s\n",
      "819:\tlearn: 5.7628047\ttotal: 1m 2s\tremaining: 13.7s\n",
      "820:\tlearn: 5.7605831\ttotal: 1m 2s\tremaining: 13.6s\n",
      "821:\tlearn: 5.7579155\ttotal: 1m 2s\tremaining: 13.6s\n",
      "822:\tlearn: 5.7559520\ttotal: 1m 2s\tremaining: 13.5s\n",
      "823:\tlearn: 5.7537208\ttotal: 1m 2s\tremaining: 13.4s\n",
      "824:\tlearn: 5.7521249\ttotal: 1m 2s\tremaining: 13.3s\n",
      "825:\tlearn: 5.7498745\ttotal: 1m 2s\tremaining: 13.3s\n",
      "826:\tlearn: 5.7484068\ttotal: 1m 3s\tremaining: 13.2s\n",
      "827:\tlearn: 5.7459610\ttotal: 1m 3s\tremaining: 13.1s\n",
      "828:\tlearn: 5.7438168\ttotal: 1m 3s\tremaining: 13s\n",
      "829:\tlearn: 5.7416938\ttotal: 1m 3s\tremaining: 12.9s\n",
      "830:\tlearn: 5.7389793\ttotal: 1m 3s\tremaining: 12.9s\n",
      "831:\tlearn: 5.7376001\ttotal: 1m 3s\tremaining: 12.8s\n",
      "832:\tlearn: 5.7354277\ttotal: 1m 3s\tremaining: 12.7s\n",
      "833:\tlearn: 5.7324769\ttotal: 1m 3s\tremaining: 12.6s\n",
      "834:\tlearn: 5.7308157\ttotal: 1m 3s\tremaining: 12.6s\n",
      "835:\tlearn: 5.7280305\ttotal: 1m 3s\tremaining: 12.5s\n",
      "836:\tlearn: 5.7260622\ttotal: 1m 3s\tremaining: 12.4s\n",
      "837:\tlearn: 5.7238968\ttotal: 1m 3s\tremaining: 12.3s\n",
      "838:\tlearn: 5.7221584\ttotal: 1m 3s\tremaining: 12.2s\n",
      "839:\tlearn: 5.7196415\ttotal: 1m 3s\tremaining: 12.2s\n",
      "840:\tlearn: 5.7174678\ttotal: 1m 3s\tremaining: 12.1s\n",
      "841:\tlearn: 5.7152033\ttotal: 1m 4s\tremaining: 12s\n",
      "842:\tlearn: 5.7118280\ttotal: 1m 4s\tremaining: 11.9s\n",
      "843:\tlearn: 5.7104751\ttotal: 1m 4s\tremaining: 11.9s\n",
      "844:\tlearn: 5.7083789\ttotal: 1m 4s\tremaining: 11.8s\n",
      "845:\tlearn: 5.7048756\ttotal: 1m 4s\tremaining: 11.7s\n",
      "846:\tlearn: 5.7029284\ttotal: 1m 4s\tremaining: 11.6s\n",
      "847:\tlearn: 5.7006349\ttotal: 1m 4s\tremaining: 11.6s\n",
      "848:\tlearn: 5.6978789\ttotal: 1m 4s\tremaining: 11.5s\n",
      "849:\tlearn: 5.6962285\ttotal: 1m 4s\tremaining: 11.4s\n",
      "850:\tlearn: 5.6937274\ttotal: 1m 4s\tremaining: 11.3s\n",
      "851:\tlearn: 5.6913789\ttotal: 1m 4s\tremaining: 11.2s\n",
      "852:\tlearn: 5.6899853\ttotal: 1m 4s\tremaining: 11.2s\n",
      "853:\tlearn: 5.6872575\ttotal: 1m 4s\tremaining: 11.1s\n",
      "854:\tlearn: 5.6851310\ttotal: 1m 4s\tremaining: 11s\n",
      "855:\tlearn: 5.6827609\ttotal: 1m 5s\tremaining: 10.9s\n",
      "856:\tlearn: 5.6798771\ttotal: 1m 5s\tremaining: 10.9s\n",
      "857:\tlearn: 5.6770525\ttotal: 1m 5s\tremaining: 10.8s\n",
      "858:\tlearn: 5.6760910\ttotal: 1m 5s\tremaining: 10.7s\n",
      "859:\tlearn: 5.6735612\ttotal: 1m 5s\tremaining: 10.6s\n",
      "860:\tlearn: 5.6728325\ttotal: 1m 5s\tremaining: 10.6s\n",
      "861:\tlearn: 5.6699845\ttotal: 1m 5s\tremaining: 10.5s\n",
      "862:\tlearn: 5.6673044\ttotal: 1m 5s\tremaining: 10.4s\n",
      "863:\tlearn: 5.6650060\ttotal: 1m 5s\tremaining: 10.3s\n",
      "864:\tlearn: 5.6609208\ttotal: 1m 5s\tremaining: 10.2s\n",
      "865:\tlearn: 5.6586392\ttotal: 1m 5s\tremaining: 10.2s\n",
      "866:\tlearn: 5.6556592\ttotal: 1m 5s\tremaining: 10.1s\n",
      "867:\tlearn: 5.6547236\ttotal: 1m 5s\tremaining: 10s\n",
      "868:\tlearn: 5.6520883\ttotal: 1m 5s\tremaining: 9.93s\n",
      "869:\tlearn: 5.6498134\ttotal: 1m 5s\tremaining: 9.86s\n",
      "870:\tlearn: 5.6480697\ttotal: 1m 6s\tremaining: 9.78s\n",
      "871:\tlearn: 5.6468685\ttotal: 1m 6s\tremaining: 9.7s\n",
      "872:\tlearn: 5.6438257\ttotal: 1m 6s\tremaining: 9.63s\n",
      "873:\tlearn: 5.6421519\ttotal: 1m 6s\tremaining: 9.55s\n",
      "874:\tlearn: 5.6399556\ttotal: 1m 6s\tremaining: 9.47s\n",
      "875:\tlearn: 5.6359699\ttotal: 1m 6s\tremaining: 9.4s\n",
      "876:\tlearn: 5.6345448\ttotal: 1m 6s\tremaining: 9.32s\n",
      "877:\tlearn: 5.6322807\ttotal: 1m 6s\tremaining: 9.24s\n",
      "878:\tlearn: 5.6300832\ttotal: 1m 6s\tremaining: 9.16s\n",
      "879:\tlearn: 5.6299180\ttotal: 1m 6s\tremaining: 9.09s\n",
      "880:\tlearn: 5.6275870\ttotal: 1m 6s\tremaining: 9.01s\n",
      "881:\tlearn: 5.6254734\ttotal: 1m 6s\tremaining: 8.94s\n",
      "882:\tlearn: 5.6219385\ttotal: 1m 6s\tremaining: 8.86s\n",
      "883:\tlearn: 5.6206330\ttotal: 1m 6s\tremaining: 8.78s\n",
      "884:\tlearn: 5.6182348\ttotal: 1m 7s\tremaining: 8.71s\n",
      "885:\tlearn: 5.6157819\ttotal: 1m 7s\tremaining: 8.63s\n",
      "886:\tlearn: 5.6138360\ttotal: 1m 7s\tremaining: 8.55s\n",
      "887:\tlearn: 5.6109762\ttotal: 1m 7s\tremaining: 8.48s\n",
      "888:\tlearn: 5.6079114\ttotal: 1m 7s\tremaining: 8.4s\n",
      "889:\tlearn: 5.6050882\ttotal: 1m 7s\tremaining: 8.32s\n",
      "890:\tlearn: 5.6024923\ttotal: 1m 7s\tremaining: 8.25s\n",
      "891:\tlearn: 5.5999915\ttotal: 1m 7s\tremaining: 8.17s\n",
      "892:\tlearn: 5.5975420\ttotal: 1m 7s\tremaining: 8.09s\n",
      "893:\tlearn: 5.5942990\ttotal: 1m 7s\tremaining: 8.02s\n",
      "894:\tlearn: 5.5919249\ttotal: 1m 7s\tremaining: 7.94s\n",
      "895:\tlearn: 5.5903362\ttotal: 1m 7s\tremaining: 7.86s\n",
      "896:\tlearn: 5.5889400\ttotal: 1m 7s\tremaining: 7.79s\n",
      "897:\tlearn: 5.5864730\ttotal: 1m 7s\tremaining: 7.71s\n",
      "898:\tlearn: 5.5842683\ttotal: 1m 7s\tremaining: 7.63s\n",
      "899:\tlearn: 5.5817244\ttotal: 1m 8s\tremaining: 7.55s\n",
      "900:\tlearn: 5.5797423\ttotal: 1m 8s\tremaining: 7.48s\n",
      "901:\tlearn: 5.5778593\ttotal: 1m 8s\tremaining: 7.4s\n",
      "902:\tlearn: 5.5753893\ttotal: 1m 8s\tremaining: 7.33s\n",
      "903:\tlearn: 5.5732101\ttotal: 1m 8s\tremaining: 7.25s\n",
      "904:\tlearn: 5.5708174\ttotal: 1m 8s\tremaining: 7.17s\n",
      "905:\tlearn: 5.5680910\ttotal: 1m 8s\tremaining: 7.1s\n",
      "906:\tlearn: 5.5658313\ttotal: 1m 8s\tremaining: 7.02s\n",
      "907:\tlearn: 5.5631279\ttotal: 1m 8s\tremaining: 6.95s\n",
      "908:\tlearn: 5.5606437\ttotal: 1m 8s\tremaining: 6.87s\n",
      "909:\tlearn: 5.5581161\ttotal: 1m 8s\tremaining: 6.79s\n",
      "910:\tlearn: 5.5555085\ttotal: 1m 8s\tremaining: 6.72s\n",
      "911:\tlearn: 5.5536769\ttotal: 1m 8s\tremaining: 6.64s\n",
      "912:\tlearn: 5.5525551\ttotal: 1m 8s\tremaining: 6.57s\n",
      "913:\tlearn: 5.5507080\ttotal: 1m 8s\tremaining: 6.49s\n",
      "914:\tlearn: 5.5479818\ttotal: 1m 9s\tremaining: 6.41s\n",
      "915:\tlearn: 5.5469193\ttotal: 1m 9s\tremaining: 6.34s\n",
      "916:\tlearn: 5.5453728\ttotal: 1m 9s\tremaining: 6.26s\n",
      "917:\tlearn: 5.5425399\ttotal: 1m 9s\tremaining: 6.18s\n",
      "918:\tlearn: 5.5401848\ttotal: 1m 9s\tremaining: 6.11s\n",
      "919:\tlearn: 5.5375345\ttotal: 1m 9s\tremaining: 6.03s\n",
      "920:\tlearn: 5.5374257\ttotal: 1m 9s\tremaining: 5.96s\n",
      "921:\tlearn: 5.5337948\ttotal: 1m 9s\tremaining: 5.88s\n",
      "922:\tlearn: 5.5306993\ttotal: 1m 9s\tremaining: 5.8s\n",
      "923:\tlearn: 5.5284601\ttotal: 1m 9s\tremaining: 5.73s\n",
      "924:\tlearn: 5.5257419\ttotal: 1m 9s\tremaining: 5.65s\n",
      "925:\tlearn: 5.5249884\ttotal: 1m 9s\tremaining: 5.58s\n",
      "926:\tlearn: 5.5230793\ttotal: 1m 9s\tremaining: 5.5s\n",
      "927:\tlearn: 5.5204111\ttotal: 1m 9s\tremaining: 5.42s\n",
      "928:\tlearn: 5.5179018\ttotal: 1m 9s\tremaining: 5.35s\n",
      "929:\tlearn: 5.5165160\ttotal: 1m 10s\tremaining: 5.27s\n",
      "930:\tlearn: 5.5142475\ttotal: 1m 10s\tremaining: 5.2s\n",
      "931:\tlearn: 5.5123217\ttotal: 1m 10s\tremaining: 5.12s\n",
      "932:\tlearn: 5.5103407\ttotal: 1m 10s\tremaining: 5.05s\n",
      "933:\tlearn: 5.5077924\ttotal: 1m 10s\tremaining: 4.97s\n",
      "934:\tlearn: 5.5052773\ttotal: 1m 10s\tremaining: 4.89s\n",
      "935:\tlearn: 5.5031759\ttotal: 1m 10s\tremaining: 4.82s\n",
      "936:\tlearn: 5.4998727\ttotal: 1m 10s\tremaining: 4.74s\n",
      "937:\tlearn: 5.4971913\ttotal: 1m 10s\tremaining: 4.67s\n",
      "938:\tlearn: 5.4947369\ttotal: 1m 10s\tremaining: 4.59s\n",
      "939:\tlearn: 5.4929780\ttotal: 1m 10s\tremaining: 4.52s\n",
      "940:\tlearn: 5.4901909\ttotal: 1m 10s\tremaining: 4.44s\n",
      "941:\tlearn: 5.4884856\ttotal: 1m 10s\tremaining: 4.37s\n",
      "942:\tlearn: 5.4857560\ttotal: 1m 10s\tremaining: 4.29s\n",
      "943:\tlearn: 5.4826626\ttotal: 1m 11s\tremaining: 4.21s\n",
      "944:\tlearn: 5.4811014\ttotal: 1m 11s\tremaining: 4.14s\n",
      "945:\tlearn: 5.4791665\ttotal: 1m 11s\tremaining: 4.06s\n",
      "946:\tlearn: 5.4772535\ttotal: 1m 11s\tremaining: 3.99s\n",
      "947:\tlearn: 5.4756385\ttotal: 1m 11s\tremaining: 3.91s\n",
      "948:\tlearn: 5.4732217\ttotal: 1m 11s\tremaining: 3.84s\n",
      "949:\tlearn: 5.4706936\ttotal: 1m 11s\tremaining: 3.76s\n",
      "950:\tlearn: 5.4684604\ttotal: 1m 11s\tremaining: 3.69s\n",
      "951:\tlearn: 5.4656088\ttotal: 1m 11s\tremaining: 3.61s\n",
      "952:\tlearn: 5.4632818\ttotal: 1m 11s\tremaining: 3.53s\n",
      "953:\tlearn: 5.4616015\ttotal: 1m 11s\tremaining: 3.46s\n",
      "954:\tlearn: 5.4589596\ttotal: 1m 11s\tremaining: 3.38s\n",
      "955:\tlearn: 5.4559751\ttotal: 1m 11s\tremaining: 3.31s\n",
      "956:\tlearn: 5.4535231\ttotal: 1m 11s\tremaining: 3.23s\n",
      "957:\tlearn: 5.4507165\ttotal: 1m 12s\tremaining: 3.16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958:\tlearn: 5.4489368\ttotal: 1m 12s\tremaining: 3.08s\n",
      "959:\tlearn: 5.4487334\ttotal: 1m 12s\tremaining: 3.01s\n",
      "960:\tlearn: 5.4478060\ttotal: 1m 12s\tremaining: 2.93s\n",
      "961:\tlearn: 5.4464685\ttotal: 1m 12s\tremaining: 2.85s\n",
      "962:\tlearn: 5.4437075\ttotal: 1m 12s\tremaining: 2.78s\n",
      "963:\tlearn: 5.4416717\ttotal: 1m 12s\tremaining: 2.71s\n",
      "964:\tlearn: 5.4389695\ttotal: 1m 12s\tremaining: 2.63s\n",
      "965:\tlearn: 5.4373379\ttotal: 1m 12s\tremaining: 2.55s\n",
      "966:\tlearn: 5.4347530\ttotal: 1m 12s\tremaining: 2.48s\n",
      "967:\tlearn: 5.4321529\ttotal: 1m 12s\tremaining: 2.4s\n",
      "968:\tlearn: 5.4306282\ttotal: 1m 12s\tremaining: 2.33s\n",
      "969:\tlearn: 5.4283440\ttotal: 1m 12s\tremaining: 2.25s\n",
      "970:\tlearn: 5.4255050\ttotal: 1m 12s\tremaining: 2.18s\n",
      "971:\tlearn: 5.4236846\ttotal: 1m 13s\tremaining: 2.1s\n",
      "972:\tlearn: 5.4217671\ttotal: 1m 13s\tremaining: 2.03s\n",
      "973:\tlearn: 5.4196239\ttotal: 1m 13s\tremaining: 1.95s\n",
      "974:\tlearn: 5.4178898\ttotal: 1m 13s\tremaining: 1.88s\n",
      "975:\tlearn: 5.4159155\ttotal: 1m 13s\tremaining: 1.8s\n",
      "976:\tlearn: 5.4132720\ttotal: 1m 13s\tremaining: 1.73s\n",
      "977:\tlearn: 5.4130800\ttotal: 1m 13s\tremaining: 1.65s\n",
      "978:\tlearn: 5.4106398\ttotal: 1m 13s\tremaining: 1.58s\n",
      "979:\tlearn: 5.4085270\ttotal: 1m 13s\tremaining: 1.5s\n",
      "980:\tlearn: 5.4062812\ttotal: 1m 13s\tremaining: 1.43s\n",
      "981:\tlearn: 5.4043620\ttotal: 1m 13s\tremaining: 1.35s\n",
      "982:\tlearn: 5.4020702\ttotal: 1m 13s\tremaining: 1.28s\n",
      "983:\tlearn: 5.4016624\ttotal: 1m 13s\tremaining: 1.2s\n",
      "984:\tlearn: 5.4003891\ttotal: 1m 13s\tremaining: 1.13s\n",
      "985:\tlearn: 5.3978570\ttotal: 1m 14s\tremaining: 1.05s\n",
      "986:\tlearn: 5.3956751\ttotal: 1m 14s\tremaining: 976ms\n",
      "987:\tlearn: 5.3932199\ttotal: 1m 14s\tremaining: 901ms\n",
      "988:\tlearn: 5.3907657\ttotal: 1m 14s\tremaining: 826ms\n",
      "989:\tlearn: 5.3890526\ttotal: 1m 14s\tremaining: 751ms\n",
      "990:\tlearn: 5.3869465\ttotal: 1m 14s\tremaining: 676ms\n",
      "991:\tlearn: 5.3858279\ttotal: 1m 14s\tremaining: 600ms\n",
      "992:\tlearn: 5.3835645\ttotal: 1m 14s\tremaining: 525ms\n",
      "993:\tlearn: 5.3813047\ttotal: 1m 14s\tremaining: 450ms\n",
      "994:\tlearn: 5.3802221\ttotal: 1m 14s\tremaining: 375ms\n",
      "995:\tlearn: 5.3788829\ttotal: 1m 14s\tremaining: 300ms\n",
      "996:\tlearn: 5.3765302\ttotal: 1m 14s\tremaining: 225ms\n",
      "997:\tlearn: 5.3747666\ttotal: 1m 14s\tremaining: 150ms\n",
      "998:\tlearn: 5.3728178\ttotal: 1m 14s\tremaining: 75ms\n",
      "999:\tlearn: 5.3698989\ttotal: 1m 15s\tremaining: 0us\n",
      "LGBMRegressor 로그 변환된 RMSE: 8.318\n",
      "CatBoostRegressor 로그 변환된 RMSE: 8.227\n",
      "XGBRegressor 로그 변환된 RMSE: 8.778\n",
      "Ridge 로그 변환된 RMSE: 8.469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.317722126952988, 8.226987560575429, 8.77767236248439, 8.469065002823504]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rmse(model):\n",
    "    pred = model.predict(valid_x)\n",
    "    mse = mean_squared_error(valid_y , pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('{0} 로그 변환된 RMSE: {1}'.format(model.__class__.__name__,np.round(rmse, 3)))\n",
    "    return rmse\n",
    "\n",
    "def get_rmses(models):\n",
    "    rmses = [ ]\n",
    "    for model in models:\n",
    "        rmse = get_rmse(model)\n",
    "        rmses.append(rmse)\n",
    "    return rmses\n",
    "\n",
    "\n",
    "\n",
    "lgbm = LGBMRegressor(random_state = 1000  )\n",
    "lgbm = lgbm.fit(train_x , train_y)\n",
    "\n",
    "cat = CatBoostRegressor(random_state=1000 )\n",
    "cat = cat.fit(train_x , train_y)\n",
    "\n",
    "xgb = XGBRegressor(random_state = 1000 )\n",
    "xgb.fit(train_x , train_y )\n",
    "\n",
    "reg_ridge = Ridge(random_state = 1000)\n",
    "reg_ridge.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "models = [lgbm, cat, xgb, reg_ridge ]\n",
    "get_rmses(models)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LGBMRegressor 로그 변환된 RMSE: 8.318\n",
    "# CatBoostRegressor 로그 변환된 RMSE: 8.227\n",
    "# XGBRegressor 로그 변환된 RMSE: 8.778\n",
    "# Ridge 로그 변환된 RMSE: 8.469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_params = {\n",
    "    'max_depth':(8, 16),\n",
    "    'num_leaves':(24, 64),\n",
    "    'min_child_samples':(10, 200),\n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1),\n",
    "    'colsample_bytree':(0.5, 1),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha':(0.01, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_rmse_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree, max_bin, reg_lambda, reg_alpha):\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\":2000, \n",
    "        \"learning_rate\":0.02,\n",
    "        'max_depth':int(round(max_depth)),\n",
    "        'num_leaves':int(round(num_leaves)),\n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample':max(min(subsample, 1), 0),\n",
    "        'colsample_bytree':max(min(colsample_bytree, 1), 0),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0)\n",
    "    }\n",
    "    \n",
    "    lgb_model = LGBMRegressor(**params)\n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'RMSE', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    valid_pred = lgb_model.predict(valid_x)\n",
    "    RMSE = np.sqrt(mean_squared_error(valid_y, valid_pred))\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.07906\ttraining's l2: 65.2712\tvalid_1's rmse: 8.59034\tvalid_1's l2: 73.794\n",
      "[200]\ttraining's rmse: 7.35293\ttraining's l2: 54.0656\tvalid_1's rmse: 8.32396\tvalid_1's l2: 69.2883\n",
      "[300]\ttraining's rmse: 6.88104\ttraining's l2: 47.3488\tvalid_1's rmse: 8.24524\tvalid_1's l2: 67.9841\n",
      "[400]\ttraining's rmse: 6.49982\ttraining's l2: 42.2477\tvalid_1's rmse: 8.21169\tvalid_1's l2: 67.4318\n",
      "[500]\ttraining's rmse: 6.17983\ttraining's l2: 38.1904\tvalid_1's rmse: 8.19794\tvalid_1's l2: 67.2062\n",
      "[600]\ttraining's rmse: 5.89184\ttraining's l2: 34.7137\tvalid_1's rmse: 8.18785\tvalid_1's l2: 67.0409\n",
      "[700]\ttraining's rmse: 5.6305\ttraining's l2: 31.7025\tvalid_1's rmse: 8.1837\tvalid_1's l2: 66.973\n",
      "[800]\ttraining's rmse: 5.38687\ttraining's l2: 29.0183\tvalid_1's rmse: 8.18465\tvalid_1's l2: 66.9885\n",
      "Early stopping, best iteration is:\n",
      "[782]\ttraining's rmse: 5.42981\ttraining's l2: 29.4828\tvalid_1's rmse: 8.18212\tvalid_1's l2: 66.9471\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 8.182   \u001b[0m | \u001b[0m 0.8268  \u001b[0m | \u001b[0m 66.35   \u001b[0m | \u001b[0m 15.6    \u001b[0m | \u001b[0m 101.6   \u001b[0m | \u001b[0m 43.75   \u001b[0m | \u001b[0m 32.49   \u001b[0m | \u001b[0m 2.045   \u001b[0m | \u001b[0m 3.973   \u001b[0m | \u001b[0m 0.6166  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.74208\ttraining's l2: 59.9397\tvalid_1's rmse: 8.55006\tvalid_1's l2: 73.1035\n",
      "[200]\ttraining's rmse: 6.80691\ttraining's l2: 46.334\tvalid_1's rmse: 8.30364\tvalid_1's l2: 68.9505\n",
      "[300]\ttraining's rmse: 6.17449\ttraining's l2: 38.1243\tvalid_1's rmse: 8.23362\tvalid_1's l2: 67.7925\n",
      "[400]\ttraining's rmse: 5.67842\ttraining's l2: 32.2444\tvalid_1's rmse: 8.20914\tvalid_1's l2: 67.39\n",
      "[500]\ttraining's rmse: 5.25422\ttraining's l2: 27.6069\tvalid_1's rmse: 8.19908\tvalid_1's l2: 67.2249\n",
      "[600]\ttraining's rmse: 4.87228\ttraining's l2: 23.7391\tvalid_1's rmse: 8.19911\tvalid_1's l2: 67.2253\n",
      "Early stopping, best iteration is:\n",
      "[578]\ttraining's rmse: 4.95367\ttraining's l2: 24.5389\tvalid_1's rmse: 8.19762\tvalid_1's l2: 67.201\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 8.198   \u001b[0m | \u001b[95m 0.9209  \u001b[0m | \u001b[95m 111.5   \u001b[0m | \u001b[95m 13.94   \u001b[0m | \u001b[95m 84.51   \u001b[0m | \u001b[95m 9.931   \u001b[0m | \u001b[95m 53.74   \u001b[0m | \u001b[95m 3.488   \u001b[0m | \u001b[95m 8.853   \u001b[0m | \u001b[95m 0.9763  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.94029\ttraining's l2: 63.0482\tvalid_1's rmse: 8.5722\tvalid_1's l2: 73.4826\n",
      "[200]\ttraining's rmse: 7.23454\ttraining's l2: 52.3386\tvalid_1's rmse: 8.33021\tvalid_1's l2: 69.3925\n",
      "[300]\ttraining's rmse: 6.82319\ttraining's l2: 46.5559\tvalid_1's rmse: 8.26773\tvalid_1's l2: 68.3553\n",
      "[400]\ttraining's rmse: 6.51933\ttraining's l2: 42.5016\tvalid_1's rmse: 8.2476\tvalid_1's l2: 68.0228\n",
      "[500]\ttraining's rmse: 6.27691\ttraining's l2: 39.3996\tvalid_1's rmse: 8.23245\tvalid_1's l2: 67.7732\n",
      "[600]\ttraining's rmse: 6.07653\ttraining's l2: 36.9242\tvalid_1's rmse: 8.22471\tvalid_1's l2: 67.6458\n",
      "[700]\ttraining's rmse: 5.87931\ttraining's l2: 34.5663\tvalid_1's rmse: 8.22448\tvalid_1's l2: 67.6421\n",
      "[800]\ttraining's rmse: 5.69306\ttraining's l2: 32.4109\tvalid_1's rmse: 8.22466\tvalid_1's l2: 67.645\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's rmse: 5.78674\ttraining's l2: 33.4864\tvalid_1's rmse: 8.22209\tvalid_1's l2: 67.6027\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 8.222   \u001b[0m | \u001b[95m 0.9656  \u001b[0m | \u001b[95m 213.6   \u001b[0m | \u001b[95m 8.232   \u001b[0m | \u001b[95m 196.6   \u001b[0m | \u001b[95m 17.64   \u001b[0m | \u001b[95m 52.27   \u001b[0m | \u001b[95m 18.1    \u001b[0m | \u001b[95m 0.352   \u001b[0m | \u001b[95m 0.9275  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.25761\ttraining's l2: 68.1882\tvalid_1's rmse: 8.64276\tvalid_1's l2: 74.6973\n",
      "[200]\ttraining's rmse: 7.63208\ttraining's l2: 58.2487\tvalid_1's rmse: 8.3676\tvalid_1's l2: 70.0168\n",
      "[300]\ttraining's rmse: 7.24515\ttraining's l2: 52.4923\tvalid_1's rmse: 8.2827\tvalid_1's l2: 68.6031\n",
      "[400]\ttraining's rmse: 6.93867\ttraining's l2: 48.1452\tvalid_1's rmse: 8.24828\tvalid_1's l2: 68.0341\n",
      "[500]\ttraining's rmse: 6.67961\ttraining's l2: 44.6172\tvalid_1's rmse: 8.23408\tvalid_1's l2: 67.8001\n",
      "[600]\ttraining's rmse: 6.44859\ttraining's l2: 41.5844\tvalid_1's rmse: 8.22316\tvalid_1's l2: 67.6203\n",
      "[700]\ttraining's rmse: 6.23984\ttraining's l2: 38.9357\tvalid_1's rmse: 8.21983\tvalid_1's l2: 67.5655\n",
      "Early stopping, best iteration is:\n",
      "[697]\ttraining's rmse: 6.24577\ttraining's l2: 39.0096\tvalid_1's rmse: 8.2192\tvalid_1's l2: 67.5553\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 8.219   \u001b[0m | \u001b[0m 0.8286  \u001b[0m | \u001b[0m 385.2   \u001b[0m | \u001b[0m 12.43   \u001b[0m | \u001b[0m 178.2   \u001b[0m | \u001b[0m 45.31   \u001b[0m | \u001b[0m 24.42   \u001b[0m | \u001b[0m 3.737   \u001b[0m | \u001b[0m 2.447   \u001b[0m | \u001b[0m 0.5667  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.2355\ttraining's l2: 67.8234\tvalid_1's rmse: 8.64993\tvalid_1's l2: 74.8213\n",
      "[200]\ttraining's rmse: 7.58041\ttraining's l2: 57.4626\tvalid_1's rmse: 8.36919\tvalid_1's l2: 70.0434\n",
      "[300]\ttraining's rmse: 7.17259\ttraining's l2: 51.446\tvalid_1's rmse: 8.29101\tvalid_1's l2: 68.7408\n",
      "[400]\ttraining's rmse: 6.84467\ttraining's l2: 46.8495\tvalid_1's rmse: 8.24667\tvalid_1's l2: 68.0076\n",
      "[500]\ttraining's rmse: 6.56698\ttraining's l2: 43.1253\tvalid_1's rmse: 8.23003\tvalid_1's l2: 67.7333\n",
      "[600]\ttraining's rmse: 6.32045\ttraining's l2: 39.9481\tvalid_1's rmse: 8.21897\tvalid_1's l2: 67.5515\n",
      "[700]\ttraining's rmse: 6.0941\ttraining's l2: 37.1381\tvalid_1's rmse: 8.21416\tvalid_1's l2: 67.4724\n",
      "[800]\ttraining's rmse: 5.88815\ttraining's l2: 34.6703\tvalid_1's rmse: 8.20997\tvalid_1's l2: 67.4036\n",
      "[900]\ttraining's rmse: 5.69569\ttraining's l2: 32.4409\tvalid_1's rmse: 8.20747\tvalid_1's l2: 67.3625\n",
      "[1000]\ttraining's rmse: 5.50982\ttraining's l2: 30.3582\tvalid_1's rmse: 8.20507\tvalid_1's l2: 67.3231\n",
      "[1100]\ttraining's rmse: 5.32996\ttraining's l2: 28.4085\tvalid_1's rmse: 8.20442\tvalid_1's l2: 67.3125\n",
      "[1200]\ttraining's rmse: 5.16606\ttraining's l2: 26.6882\tvalid_1's rmse: 8.20577\tvalid_1's l2: 67.3347\n",
      "Early stopping, best iteration is:\n",
      "[1119]\ttraining's rmse: 5.29793\ttraining's l2: 28.068\tvalid_1's rmse: 8.20354\tvalid_1's l2: 67.2981\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 8.204   \u001b[0m | \u001b[0m 0.849   \u001b[0m | \u001b[0m 205.1   \u001b[0m | \u001b[0m 15.06   \u001b[0m | \u001b[0m 44.39   \u001b[0m | \u001b[0m 22.19   \u001b[0m | \u001b[0m 24.73   \u001b[0m | \u001b[0m 34.57   \u001b[0m | \u001b[0m 4.697   \u001b[0m | \u001b[0m 0.5641  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.88801\ttraining's l2: 62.2207\tvalid_1's rmse: 8.55951\tvalid_1's l2: 73.2651\n",
      "[200]\ttraining's rmse: 7.0515\ttraining's l2: 49.7236\tvalid_1's rmse: 8.30815\tvalid_1's l2: 69.0253\n",
      "[300]\ttraining's rmse: 6.5031\ttraining's l2: 42.2904\tvalid_1's rmse: 8.23994\tvalid_1's l2: 67.8967\n",
      "[400]\ttraining's rmse: 6.0876\ttraining's l2: 37.0588\tvalid_1's rmse: 8.21673\tvalid_1's l2: 67.5146\n",
      "[500]\ttraining's rmse: 5.73719\ttraining's l2: 32.9153\tvalid_1's rmse: 8.20365\tvalid_1's l2: 67.2998\n",
      "[600]\ttraining's rmse: 5.43602\ttraining's l2: 29.5503\tvalid_1's rmse: 8.20125\tvalid_1's l2: 67.2605\n",
      "[700]\ttraining's rmse: 5.1661\ttraining's l2: 26.6885\tvalid_1's rmse: 8.19987\tvalid_1's l2: 67.2379\n",
      "Early stopping, best iteration is:\n",
      "[660]\ttraining's rmse: 5.27662\ttraining's l2: 27.8427\tvalid_1's rmse: 8.19601\tvalid_1's l2: 67.1746\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 8.196   \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 298.9   \u001b[0m | \u001b[0m 12.75   \u001b[0m | \u001b[0m 193.3   \u001b[0m | \u001b[0m 3.974   \u001b[0m | \u001b[0m 59.19   \u001b[0m | \u001b[0m 11.59   \u001b[0m | \u001b[0m 4.796   \u001b[0m | \u001b[0m 0.5093  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.15909\ttraining's l2: 66.5707\tvalid_1's rmse: 8.60748\tvalid_1's l2: 74.0887\n",
      "[200]\ttraining's rmse: 7.48268\ttraining's l2: 55.9905\tvalid_1's rmse: 8.33976\tvalid_1's l2: 69.5516\n",
      "[300]\ttraining's rmse: 7.05751\ttraining's l2: 49.8084\tvalid_1's rmse: 8.25778\tvalid_1's l2: 68.191\n",
      "[400]\ttraining's rmse: 6.71319\ttraining's l2: 45.067\tvalid_1's rmse: 8.22487\tvalid_1's l2: 67.6486\n",
      "[500]\ttraining's rmse: 6.41187\ttraining's l2: 41.1121\tvalid_1's rmse: 8.20929\tvalid_1's l2: 67.3924\n",
      "[600]\ttraining's rmse: 6.14408\ttraining's l2: 37.7498\tvalid_1's rmse: 8.20207\tvalid_1's l2: 67.274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttraining's rmse: 5.89944\ttraining's l2: 34.8035\tvalid_1's rmse: 8.19587\tvalid_1's l2: 67.1723\n",
      "[800]\ttraining's rmse: 5.67307\ttraining's l2: 32.1838\tvalid_1's rmse: 8.19504\tvalid_1's l2: 67.1587\n",
      "Early stopping, best iteration is:\n",
      "[780]\ttraining's rmse: 5.71737\ttraining's l2: 32.6883\tvalid_1's rmse: 8.19454\tvalid_1's l2: 67.1504\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 8.195   \u001b[0m | \u001b[0m 0.6744  \u001b[0m | \u001b[0m 384.4   \u001b[0m | \u001b[0m 15.72   \u001b[0m | \u001b[0m 183.3   \u001b[0m | \u001b[0m 44.39   \u001b[0m | \u001b[0m 29.63   \u001b[0m | \u001b[0m 5.094   \u001b[0m | \u001b[0m 4.801   \u001b[0m | \u001b[0m 0.8988  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.0218\ttraining's l2: 64.3494\tvalid_1's rmse: 8.60019\tvalid_1's l2: 73.9632\n",
      "[200]\ttraining's rmse: 7.25613\ttraining's l2: 52.6514\tvalid_1's rmse: 8.33148\tvalid_1's l2: 69.4136\n",
      "[300]\ttraining's rmse: 6.75011\ttraining's l2: 45.564\tvalid_1's rmse: 8.25439\tvalid_1's l2: 68.135\n",
      "[400]\ttraining's rmse: 6.3339\ttraining's l2: 40.1183\tvalid_1's rmse: 8.22237\tvalid_1's l2: 67.6073\n",
      "[500]\ttraining's rmse: 5.98383\ttraining's l2: 35.8062\tvalid_1's rmse: 8.20496\tvalid_1's l2: 67.3213\n",
      "[600]\ttraining's rmse: 5.67633\ttraining's l2: 32.2207\tvalid_1's rmse: 8.20054\tvalid_1's l2: 67.2488\n",
      "[700]\ttraining's rmse: 5.39808\ttraining's l2: 29.1392\tvalid_1's rmse: 8.19304\tvalid_1's l2: 67.1259\n",
      "[800]\ttraining's rmse: 5.14592\ttraining's l2: 26.4805\tvalid_1's rmse: 8.19002\tvalid_1's l2: 67.0764\n",
      "[900]\ttraining's rmse: 4.91023\ttraining's l2: 24.1104\tvalid_1's rmse: 8.18726\tvalid_1's l2: 67.0312\n",
      "Early stopping, best iteration is:\n",
      "[871]\ttraining's rmse: 4.97649\ttraining's l2: 24.7654\tvalid_1's rmse: 8.18585\tvalid_1's l2: 67.0082\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 8.186   \u001b[0m | \u001b[0m 0.7675  \u001b[0m | \u001b[0m 132.0   \u001b[0m | \u001b[0m 14.3    \u001b[0m | \u001b[0m 40.39   \u001b[0m | \u001b[0m 44.76   \u001b[0m | \u001b[0m 35.85   \u001b[0m | \u001b[0m 33.16   \u001b[0m | \u001b[0m 4.179   \u001b[0m | \u001b[0m 0.9905  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.68667\ttraining's l2: 59.0849\tvalid_1's rmse: 8.52673\tvalid_1's l2: 72.7052\n",
      "[200]\ttraining's rmse: 6.79335\ttraining's l2: 46.1496\tvalid_1's rmse: 8.28501\tvalid_1's l2: 68.6413\n",
      "[300]\ttraining's rmse: 6.3093\ttraining's l2: 39.8073\tvalid_1's rmse: 8.22848\tvalid_1's l2: 67.7079\n",
      "[400]\ttraining's rmse: 5.93563\ttraining's l2: 35.2317\tvalid_1's rmse: 8.20094\tvalid_1's l2: 67.2554\n",
      "[500]\ttraining's rmse: 5.6179\ttraining's l2: 31.5608\tvalid_1's rmse: 8.19053\tvalid_1's l2: 67.0848\n",
      "[600]\ttraining's rmse: 5.33736\ttraining's l2: 28.4874\tvalid_1's rmse: 8.18422\tvalid_1's l2: 66.9814\n",
      "[700]\ttraining's rmse: 5.07562\ttraining's l2: 25.7619\tvalid_1's rmse: 8.18362\tvalid_1's l2: 66.9716\n",
      "Early stopping, best iteration is:\n",
      "[670]\ttraining's rmse: 5.14646\ttraining's l2: 26.4861\tvalid_1's rmse: 8.18184\tvalid_1's l2: 66.9425\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 8.182   \u001b[0m | \u001b[0m 0.5909  \u001b[0m | \u001b[0m 151.4   \u001b[0m | \u001b[0m 8.126   \u001b[0m | \u001b[0m 67.71   \u001b[0m | \u001b[0m 12.18   \u001b[0m | \u001b[0m 57.97   \u001b[0m | \u001b[0m 5.113   \u001b[0m | \u001b[0m 2.963   \u001b[0m | \u001b[0m 0.5074  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.16175\ttraining's l2: 66.6141\tvalid_1's rmse: 8.62544\tvalid_1's l2: 74.3982\n",
      "[200]\ttraining's rmse: 7.47952\ttraining's l2: 55.9432\tvalid_1's rmse: 8.35347\tvalid_1's l2: 69.7805\n",
      "[300]\ttraining's rmse: 7.05086\ttraining's l2: 49.7146\tvalid_1's rmse: 8.26867\tvalid_1's l2: 68.3709\n",
      "[400]\ttraining's rmse: 6.7021\ttraining's l2: 44.9181\tvalid_1's rmse: 8.23191\tvalid_1's l2: 67.7643\n",
      "[500]\ttraining's rmse: 6.40747\ttraining's l2: 41.0557\tvalid_1's rmse: 8.21412\tvalid_1's l2: 67.4717\n",
      "[600]\ttraining's rmse: 6.1452\ttraining's l2: 37.7635\tvalid_1's rmse: 8.20938\tvalid_1's l2: 67.3939\n",
      "[700]\ttraining's rmse: 5.9061\ttraining's l2: 34.882\tvalid_1's rmse: 8.20103\tvalid_1's l2: 67.2568\n",
      "[800]\ttraining's rmse: 5.68658\ttraining's l2: 32.3372\tvalid_1's rmse: 8.20333\tvalid_1's l2: 67.2946\n",
      "Early stopping, best iteration is:\n",
      "[718]\ttraining's rmse: 5.86504\ttraining's l2: 34.3987\tvalid_1's rmse: 8.20014\tvalid_1's l2: 67.2422\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 8.2     \u001b[0m | \u001b[0m 0.9254  \u001b[0m | \u001b[0m 416.7   \u001b[0m | \u001b[0m 10.77   \u001b[0m | \u001b[0m 126.9   \u001b[0m | \u001b[0m 26.11   \u001b[0m | \u001b[0m 29.61   \u001b[0m | \u001b[0m 48.7    \u001b[0m | \u001b[0m 7.307   \u001b[0m | \u001b[0m 0.5611  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.13255\ttraining's l2: 66.1384\tvalid_1's rmse: 8.60501\tvalid_1's l2: 74.0462\n",
      "[200]\ttraining's rmse: 7.43426\ttraining's l2: 55.2682\tvalid_1's rmse: 8.32781\tvalid_1's l2: 69.3524\n",
      "[300]\ttraining's rmse: 6.98464\ttraining's l2: 48.7852\tvalid_1's rmse: 8.23899\tvalid_1's l2: 67.8809\n",
      "[400]\ttraining's rmse: 6.62224\ttraining's l2: 43.8541\tvalid_1's rmse: 8.20474\tvalid_1's l2: 67.3177\n",
      "[500]\ttraining's rmse: 6.31127\ttraining's l2: 39.8321\tvalid_1's rmse: 8.19427\tvalid_1's l2: 67.1461\n",
      "[600]\ttraining's rmse: 6.03413\ttraining's l2: 36.4108\tvalid_1's rmse: 8.18416\tvalid_1's l2: 66.9805\n",
      "[700]\ttraining's rmse: 5.78501\ttraining's l2: 33.4663\tvalid_1's rmse: 8.17867\tvalid_1's l2: 66.8906\n",
      "[800]\ttraining's rmse: 5.55289\ttraining's l2: 30.8346\tvalid_1's rmse: 8.1757\tvalid_1's l2: 66.8421\n",
      "[900]\ttraining's rmse: 5.33353\ttraining's l2: 28.4465\tvalid_1's rmse: 8.173\tvalid_1's l2: 66.798\n",
      "[1000]\ttraining's rmse: 5.12902\ttraining's l2: 26.3069\tvalid_1's rmse: 8.17596\tvalid_1's l2: 66.8464\n",
      "Early stopping, best iteration is:\n",
      "[903]\ttraining's rmse: 5.32716\ttraining's l2: 28.3786\tvalid_1's rmse: 8.17289\tvalid_1's l2: 66.7962\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 8.173   \u001b[0m | \u001b[0m 0.5141  \u001b[0m | \u001b[0m 254.3   \u001b[0m | \u001b[0m 15.33   \u001b[0m | \u001b[0m 103.2   \u001b[0m | \u001b[0m 46.9    \u001b[0m | \u001b[0m 32.34   \u001b[0m | \u001b[0m 12.22   \u001b[0m | \u001b[0m 9.777   \u001b[0m | \u001b[0m 0.6989  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.07679\ttraining's l2: 65.2346\tvalid_1's rmse: 8.59126\tvalid_1's l2: 73.8098\n",
      "[200]\ttraining's rmse: 7.35632\ttraining's l2: 54.1154\tvalid_1's rmse: 8.32303\tvalid_1's l2: 69.2728\n",
      "[300]\ttraining's rmse: 6.8824\ttraining's l2: 47.3674\tvalid_1's rmse: 8.23803\tvalid_1's l2: 67.8652\n",
      "[400]\ttraining's rmse: 6.49834\ttraining's l2: 42.2285\tvalid_1's rmse: 8.20424\tvalid_1's l2: 67.3096\n",
      "[500]\ttraining's rmse: 6.16647\ttraining's l2: 38.0254\tvalid_1's rmse: 8.1906\tvalid_1's l2: 67.0859\n",
      "[600]\ttraining's rmse: 5.86861\ttraining's l2: 34.4406\tvalid_1's rmse: 8.18568\tvalid_1's l2: 67.0053\n",
      "[700]\ttraining's rmse: 5.59688\ttraining's l2: 31.3251\tvalid_1's rmse: 8.18308\tvalid_1's l2: 66.9628\n",
      "Early stopping, best iteration is:\n",
      "[670]\ttraining's rmse: 5.67518\ttraining's l2: 32.2077\tvalid_1's rmse: 8.18162\tvalid_1's l2: 66.9389\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 8.182   \u001b[0m | \u001b[0m 0.5715  \u001b[0m | \u001b[0m 420.3   \u001b[0m | \u001b[0m 15.04   \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 3.524   \u001b[0m | \u001b[0m 35.44   \u001b[0m | \u001b[0m 22.55   \u001b[0m | \u001b[0m 3.946   \u001b[0m | \u001b[0m 0.9637  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.96879\ttraining's l2: 63.5016\tvalid_1's rmse: 8.58972\tvalid_1's l2: 73.7832\n",
      "[200]\ttraining's rmse: 7.1735\ttraining's l2: 51.4591\tvalid_1's rmse: 8.33199\tvalid_1's l2: 69.4221\n",
      "[300]\ttraining's rmse: 6.6434\ttraining's l2: 44.1347\tvalid_1's rmse: 8.2483\tvalid_1's l2: 68.0345\n",
      "[400]\ttraining's rmse: 6.21069\ttraining's l2: 38.5727\tvalid_1's rmse: 8.21946\tvalid_1's l2: 67.5596\n",
      "[500]\ttraining's rmse: 5.84136\ttraining's l2: 34.1215\tvalid_1's rmse: 8.20332\tvalid_1's l2: 67.2945\n",
      "[600]\ttraining's rmse: 5.51701\ttraining's l2: 30.4374\tvalid_1's rmse: 8.1934\tvalid_1's l2: 67.1319\n",
      "[700]\ttraining's rmse: 5.22887\ttraining's l2: 27.341\tvalid_1's rmse: 8.18854\tvalid_1's l2: 67.0522\n",
      "Early stopping, best iteration is:\n",
      "[668]\ttraining's rmse: 5.31999\ttraining's l2: 28.3023\tvalid_1's rmse: 8.18722\tvalid_1's l2: 67.0305\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 8.187   \u001b[0m | \u001b[0m 0.5793  \u001b[0m | \u001b[0m 255.2   \u001b[0m | \u001b[0m 13.55   \u001b[0m | \u001b[0m 12.51   \u001b[0m | \u001b[0m 29.43   \u001b[0m | \u001b[0m 39.82   \u001b[0m | \u001b[0m 33.96   \u001b[0m | \u001b[0m 5.653   \u001b[0m | \u001b[0m 0.8581  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.73393\ttraining's l2: 59.8137\tvalid_1's rmse: 8.54017\tvalid_1's l2: 72.9345\n",
      "[200]\ttraining's rmse: 6.79816\ttraining's l2: 46.215\tvalid_1's rmse: 8.29629\tvalid_1's l2: 68.8285\n",
      "[300]\ttraining's rmse: 6.15704\ttraining's l2: 37.9091\tvalid_1's rmse: 8.23015\tvalid_1's l2: 67.7353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 5.63818\ttraining's l2: 31.789\tvalid_1's rmse: 8.20878\tvalid_1's l2: 67.3841\n",
      "[500]\ttraining's rmse: 5.20698\ttraining's l2: 27.1126\tvalid_1's rmse: 8.2005\tvalid_1's l2: 67.2481\n",
      "[600]\ttraining's rmse: 4.8266\ttraining's l2: 23.296\tvalid_1's rmse: 8.19269\tvalid_1's l2: 67.1201\n",
      "[700]\ttraining's rmse: 4.48442\ttraining's l2: 20.11\tvalid_1's rmse: 8.19547\tvalid_1's l2: 67.1657\n",
      "Early stopping, best iteration is:\n",
      "[664]\ttraining's rmse: 4.60342\ttraining's l2: 21.1915\tvalid_1's rmse: 8.19151\tvalid_1's l2: 67.1008\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 8.192   \u001b[0m | \u001b[0m 0.8278  \u001b[0m | \u001b[0m 110.7   \u001b[0m | \u001b[0m 15.82   \u001b[0m | \u001b[0m 82.63   \u001b[0m | \u001b[0m 9.746   \u001b[0m | \u001b[0m 54.33   \u001b[0m | \u001b[0m 9.338   \u001b[0m | \u001b[0m 4.784   \u001b[0m | \u001b[0m 0.9855  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.8068\ttraining's l2: 60.9462\tvalid_1's rmse: 8.55667\tvalid_1's l2: 73.2165\n",
      "[200]\ttraining's rmse: 6.91888\ttraining's l2: 47.8709\tvalid_1's rmse: 8.30707\tvalid_1's l2: 69.0074\n",
      "[300]\ttraining's rmse: 6.31746\ttraining's l2: 39.9104\tvalid_1's rmse: 8.2399\tvalid_1's l2: 67.896\n",
      "[400]\ttraining's rmse: 5.82352\ttraining's l2: 33.9134\tvalid_1's rmse: 8.21476\tvalid_1's l2: 67.4822\n",
      "[500]\ttraining's rmse: 5.39966\ttraining's l2: 29.1563\tvalid_1's rmse: 8.20422\tvalid_1's l2: 67.3092\n",
      "[600]\ttraining's rmse: 5.02616\ttraining's l2: 25.2623\tvalid_1's rmse: 8.20281\tvalid_1's l2: 67.2861\n",
      "[700]\ttraining's rmse: 4.69151\ttraining's l2: 22.0103\tvalid_1's rmse: 8.20133\tvalid_1's l2: 67.2618\n",
      "Early stopping, best iteration is:\n",
      "[679]\ttraining's rmse: 4.75967\ttraining's l2: 22.6544\tvalid_1's rmse: 8.19823\tvalid_1's l2: 67.211\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 8.198   \u001b[0m | \u001b[0m 0.6659  \u001b[0m | \u001b[0m 318.9   \u001b[0m | \u001b[0m 14.7    \u001b[0m | \u001b[0m 89.29   \u001b[0m | \u001b[0m 7.679   \u001b[0m | \u001b[0m 54.4    \u001b[0m | \u001b[0m 41.98   \u001b[0m | \u001b[0m 4.397   \u001b[0m | \u001b[0m 0.6464  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.68209\ttraining's l2: 59.0145\tvalid_1's rmse: 8.56026\tvalid_1's l2: 73.2781\n",
      "[200]\ttraining's rmse: 6.73078\ttraining's l2: 45.3034\tvalid_1's rmse: 8.31639\tvalid_1's l2: 69.1624\n",
      "[300]\ttraining's rmse: 6.09777\ttraining's l2: 37.1829\tvalid_1's rmse: 8.25479\tvalid_1's l2: 68.1416\n",
      "[400]\ttraining's rmse: 5.60484\ttraining's l2: 31.4142\tvalid_1's rmse: 8.22803\tvalid_1's l2: 67.7005\n",
      "[500]\ttraining's rmse: 5.17703\ttraining's l2: 26.8016\tvalid_1's rmse: 8.21839\tvalid_1's l2: 67.5419\n",
      "[600]\ttraining's rmse: 4.80843\ttraining's l2: 23.121\tvalid_1's rmse: 8.21565\tvalid_1's l2: 67.497\n",
      "[700]\ttraining's rmse: 4.47001\ttraining's l2: 19.981\tvalid_1's rmse: 8.2178\tvalid_1's l2: 67.5322\n",
      "Early stopping, best iteration is:\n",
      "[628]\ttraining's rmse: 4.71008\ttraining's l2: 22.1849\tvalid_1's rmse: 8.21437\tvalid_1's l2: 67.4759\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 8.214   \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 9.587   \u001b[0m | \u001b[0m 45.26   \u001b[0m | \u001b[0m 38.36   \u001b[0m | \u001b[0m 58.79   \u001b[0m | \u001b[0m 48.62   \u001b[0m | \u001b[0m 2.709   \u001b[0m | \u001b[0m 0.9832  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.09966\ttraining's l2: 65.6045\tvalid_1's rmse: 8.61371\tvalid_1's l2: 74.196\n",
      "[200]\ttraining's rmse: 7.37953\ttraining's l2: 54.4575\tvalid_1's rmse: 8.34271\tvalid_1's l2: 69.6008\n",
      "[300]\ttraining's rmse: 6.92057\ttraining's l2: 47.8943\tvalid_1's rmse: 8.26841\tvalid_1's l2: 68.3666\n",
      "[400]\ttraining's rmse: 6.55404\ttraining's l2: 42.9554\tvalid_1's rmse: 8.23706\tvalid_1's l2: 67.8491\n",
      "[500]\ttraining's rmse: 6.2409\ttraining's l2: 38.9488\tvalid_1's rmse: 8.22541\tvalid_1's l2: 67.6573\n",
      "[600]\ttraining's rmse: 5.96583\ttraining's l2: 35.5912\tvalid_1's rmse: 8.21611\tvalid_1's l2: 67.5044\n",
      "[700]\ttraining's rmse: 5.71257\ttraining's l2: 32.6335\tvalid_1's rmse: 8.20979\tvalid_1's l2: 67.4006\n",
      "[800]\ttraining's rmse: 5.47725\ttraining's l2: 30.0002\tvalid_1's rmse: 8.20728\tvalid_1's l2: 67.3594\n",
      "[900]\ttraining's rmse: 5.26222\ttraining's l2: 27.691\tvalid_1's rmse: 8.20571\tvalid_1's l2: 67.3337\n",
      "Early stopping, best iteration is:\n",
      "[898]\ttraining's rmse: 5.2666\ttraining's l2: 27.7371\tvalid_1's rmse: 8.20555\tvalid_1's l2: 67.3311\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 8.206   \u001b[0m | \u001b[0m 0.9319  \u001b[0m | \u001b[0m 265.1   \u001b[0m | \u001b[0m 8.635   \u001b[0m | \u001b[0m 55.92   \u001b[0m | \u001b[0m 4.254   \u001b[0m | \u001b[0m 32.04   \u001b[0m | \u001b[0m 37.83   \u001b[0m | \u001b[0m 6.108   \u001b[0m | \u001b[0m 0.9044  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.82799\ttraining's l2: 61.2775\tvalid_1's rmse: 8.5648\tvalid_1's l2: 73.3558\n",
      "[200]\ttraining's rmse: 6.94334\ttraining's l2: 48.21\tvalid_1's rmse: 8.31139\tvalid_1's l2: 69.0792\n",
      "[300]\ttraining's rmse: 6.35173\ttraining's l2: 40.3445\tvalid_1's rmse: 8.24361\tvalid_1's l2: 67.9571\n",
      "[400]\ttraining's rmse: 5.88087\ttraining's l2: 34.5846\tvalid_1's rmse: 8.22137\tvalid_1's l2: 67.591\n",
      "[500]\ttraining's rmse: 5.48532\ttraining's l2: 30.0888\tvalid_1's rmse: 8.20973\tvalid_1's l2: 67.3997\n",
      "[600]\ttraining's rmse: 5.13323\ttraining's l2: 26.3501\tvalid_1's rmse: 8.20596\tvalid_1's l2: 67.3378\n",
      "[700]\ttraining's rmse: 4.81416\ttraining's l2: 23.1762\tvalid_1's rmse: 8.20305\tvalid_1's l2: 67.29\n",
      "[800]\ttraining's rmse: 4.52381\ttraining's l2: 20.4648\tvalid_1's rmse: 8.2022\tvalid_1's l2: 67.2761\n",
      "Early stopping, best iteration is:\n",
      "[787]\ttraining's rmse: 4.5592\ttraining's l2: 20.7863\tvalid_1's rmse: 8.20076\tvalid_1's l2: 67.2524\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 8.201   \u001b[0m | \u001b[0m 0.8401  \u001b[0m | \u001b[0m 218.0   \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 18.53   \u001b[0m | \u001b[0m 44.08   \u001b[0m | \u001b[0m 48.28   \u001b[0m | \u001b[0m 31.39   \u001b[0m | \u001b[0m 5.161   \u001b[0m | \u001b[0m 0.8321  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.69351\ttraining's l2: 59.1901\tvalid_1's rmse: 8.55399\tvalid_1's l2: 73.1707\n",
      "[200]\ttraining's rmse: 6.73917\ttraining's l2: 45.4165\tvalid_1's rmse: 8.30545\tvalid_1's l2: 68.9805\n",
      "[300]\ttraining's rmse: 6.10646\ttraining's l2: 37.2889\tvalid_1's rmse: 8.2416\tvalid_1's l2: 67.9239\n",
      "[400]\ttraining's rmse: 5.60546\ttraining's l2: 31.4211\tvalid_1's rmse: 8.21524\tvalid_1's l2: 67.4901\n",
      "[500]\ttraining's rmse: 5.17736\ttraining's l2: 26.8051\tvalid_1's rmse: 8.20602\tvalid_1's l2: 67.3388\n",
      "[600]\ttraining's rmse: 4.81422\ttraining's l2: 23.1767\tvalid_1's rmse: 8.1997\tvalid_1's l2: 67.2351\n",
      "[700]\ttraining's rmse: 4.47797\ttraining's l2: 20.0522\tvalid_1's rmse: 8.1994\tvalid_1's l2: 67.2302\n",
      "Early stopping, best iteration is:\n",
      "[672]\ttraining's rmse: 4.56768\ttraining's l2: 20.8637\tvalid_1's rmse: 8.19748\tvalid_1's l2: 67.1987\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 8.197   \u001b[0m | \u001b[0m 0.7178  \u001b[0m | \u001b[0m 174.7   \u001b[0m | \u001b[0m 10.29   \u001b[0m | \u001b[0m 36.12   \u001b[0m | \u001b[0m 11.2    \u001b[0m | \u001b[0m 59.42   \u001b[0m | \u001b[0m 23.53   \u001b[0m | \u001b[0m 9.78    \u001b[0m | \u001b[0m 0.5628  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.19396\ttraining's l2: 67.141\tvalid_1's rmse: 8.63105\tvalid_1's l2: 74.4951\n",
      "[200]\ttraining's rmse: 7.53961\ttraining's l2: 56.8457\tvalid_1's rmse: 8.36364\tvalid_1's l2: 69.9505\n",
      "[300]\ttraining's rmse: 7.13313\ttraining's l2: 50.8815\tvalid_1's rmse: 8.2776\tvalid_1's l2: 68.5186\n",
      "[400]\ttraining's rmse: 6.79946\ttraining's l2: 46.2327\tvalid_1's rmse: 8.23898\tvalid_1's l2: 67.8808\n",
      "[500]\ttraining's rmse: 6.51194\ttraining's l2: 42.4054\tvalid_1's rmse: 8.221\tvalid_1's l2: 67.5848\n",
      "[600]\ttraining's rmse: 6.25441\ttraining's l2: 39.1177\tvalid_1's rmse: 8.21379\tvalid_1's l2: 67.4663\n",
      "[700]\ttraining's rmse: 6.01987\ttraining's l2: 36.2388\tvalid_1's rmse: 8.2078\tvalid_1's l2: 67.368\n",
      "[800]\ttraining's rmse: 5.80187\ttraining's l2: 33.6617\tvalid_1's rmse: 8.20916\tvalid_1's l2: 67.3904\n",
      "Early stopping, best iteration is:\n",
      "[717]\ttraining's rmse: 5.98122\ttraining's l2: 35.775\tvalid_1's rmse: 8.20675\tvalid_1's l2: 67.3508\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 8.207   \u001b[0m | \u001b[0m 0.8023  \u001b[0m | \u001b[0m 372.3   \u001b[0m | \u001b[0m 13.22   \u001b[0m | \u001b[0m 189.7   \u001b[0m | \u001b[0m 29.8    \u001b[0m | \u001b[0m 29.28   \u001b[0m | \u001b[0m 46.45   \u001b[0m | \u001b[0m 6.261   \u001b[0m | \u001b[0m 0.5583  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.91089\ttraining's l2: 62.5823\tvalid_1's rmse: 8.56819\tvalid_1's l2: 73.4139\n",
      "[200]\ttraining's rmse: 7.09224\ttraining's l2: 50.2999\tvalid_1's rmse: 8.31634\tvalid_1's l2: 69.1615\n",
      "[300]\ttraining's rmse: 6.54437\ttraining's l2: 42.8288\tvalid_1's rmse: 8.24175\tvalid_1's l2: 67.9264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 6.1061\ttraining's l2: 37.2844\tvalid_1's rmse: 8.21495\tvalid_1's l2: 67.4854\n",
      "[500]\ttraining's rmse: 5.72946\ttraining's l2: 32.8267\tvalid_1's rmse: 8.20387\tvalid_1's l2: 67.3035\n",
      "[600]\ttraining's rmse: 5.39465\ttraining's l2: 29.1022\tvalid_1's rmse: 8.19933\tvalid_1's l2: 67.229\n",
      "[700]\ttraining's rmse: 5.09083\ttraining's l2: 25.9166\tvalid_1's rmse: 8.19551\tvalid_1's l2: 67.1664\n",
      "[800]\ttraining's rmse: 4.82004\ttraining's l2: 23.2328\tvalid_1's rmse: 8.19473\tvalid_1's l2: 67.1536\n",
      "Early stopping, best iteration is:\n",
      "[748]\ttraining's rmse: 4.9596\ttraining's l2: 24.5976\tvalid_1's rmse: 8.19355\tvalid_1's l2: 67.1343\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 8.194   \u001b[0m | \u001b[0m 0.6121  \u001b[0m | \u001b[0m 56.01   \u001b[0m | \u001b[0m 13.32   \u001b[0m | \u001b[0m 86.02   \u001b[0m | \u001b[0m 2.535   \u001b[0m | \u001b[0m 43.43   \u001b[0m | \u001b[0m 12.8    \u001b[0m | \u001b[0m 3.448   \u001b[0m | \u001b[0m 0.5243  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.88026\ttraining's l2: 62.0984\tvalid_1's rmse: 8.56472\tvalid_1's l2: 73.3544\n",
      "[200]\ttraining's rmse: 7.04845\ttraining's l2: 49.6807\tvalid_1's rmse: 8.31061\tvalid_1's l2: 69.0663\n",
      "[300]\ttraining's rmse: 6.48612\ttraining's l2: 42.0697\tvalid_1's rmse: 8.23818\tvalid_1's l2: 67.8676\n",
      "[400]\ttraining's rmse: 6.03344\ttraining's l2: 36.4024\tvalid_1's rmse: 8.21514\tvalid_1's l2: 67.4885\n",
      "[500]\ttraining's rmse: 5.64379\ttraining's l2: 31.8524\tvalid_1's rmse: 8.20943\tvalid_1's l2: 67.3947\n",
      "[600]\ttraining's rmse: 5.29551\ttraining's l2: 28.0425\tvalid_1's rmse: 8.20074\tvalid_1's l2: 67.2521\n",
      "Early stopping, best iteration is:\n",
      "[586]\ttraining's rmse: 5.34281\ttraining's l2: 28.5457\tvalid_1's rmse: 8.20011\tvalid_1's l2: 67.2418\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 8.2     \u001b[0m | \u001b[0m 0.6732  \u001b[0m | \u001b[0m 294.8   \u001b[0m | \u001b[0m 15.04   \u001b[0m | \u001b[0m 117.9   \u001b[0m | \u001b[0m 26.82   \u001b[0m | \u001b[0m 46.07   \u001b[0m | \u001b[0m 13.76   \u001b[0m | \u001b[0m 3.302   \u001b[0m | \u001b[0m 0.5363  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.98744\ttraining's l2: 63.7992\tvalid_1's rmse: 8.58518\tvalid_1's l2: 73.7054\n",
      "[200]\ttraining's rmse: 7.19662\ttraining's l2: 51.7914\tvalid_1's rmse: 8.32677\tvalid_1's l2: 69.3351\n",
      "[300]\ttraining's rmse: 6.66989\ttraining's l2: 44.4874\tvalid_1's rmse: 8.25144\tvalid_1's l2: 68.0862\n",
      "[400]\ttraining's rmse: 6.24232\ttraining's l2: 38.9666\tvalid_1's rmse: 8.2278\tvalid_1's l2: 67.6966\n",
      "[500]\ttraining's rmse: 5.87968\ttraining's l2: 34.5707\tvalid_1's rmse: 8.21311\tvalid_1's l2: 67.4552\n",
      "[600]\ttraining's rmse: 5.56284\ttraining's l2: 30.9452\tvalid_1's rmse: 8.20625\tvalid_1's l2: 67.3425\n",
      "[700]\ttraining's rmse: 5.27076\ttraining's l2: 27.7809\tvalid_1's rmse: 8.20724\tvalid_1's l2: 67.3589\n",
      "Early stopping, best iteration is:\n",
      "[624]\ttraining's rmse: 5.49035\ttraining's l2: 30.144\tvalid_1's rmse: 8.20541\tvalid_1's l2: 67.3288\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 8.205   \u001b[0m | \u001b[0m 0.819   \u001b[0m | \u001b[0m 33.68   \u001b[0m | \u001b[0m 14.31   \u001b[0m | \u001b[0m 81.77   \u001b[0m | \u001b[0m 30.16   \u001b[0m | \u001b[0m 39.27   \u001b[0m | \u001b[0m 19.79   \u001b[0m | \u001b[0m 7.493   \u001b[0m | \u001b[0m 0.6173  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.87378\ttraining's l2: 61.9964\tvalid_1's rmse: 8.57461\tvalid_1's l2: 73.5239\n",
      "[200]\ttraining's rmse: 7.02195\ttraining's l2: 49.3077\tvalid_1's rmse: 8.30971\tvalid_1's l2: 69.0513\n",
      "[300]\ttraining's rmse: 6.44475\ttraining's l2: 41.5348\tvalid_1's rmse: 8.24269\tvalid_1's l2: 67.9419\n",
      "[400]\ttraining's rmse: 5.97306\ttraining's l2: 35.6775\tvalid_1's rmse: 8.20886\tvalid_1's l2: 67.3853\n",
      "[500]\ttraining's rmse: 5.57524\ttraining's l2: 31.0834\tvalid_1's rmse: 8.19899\tvalid_1's l2: 67.2234\n",
      "[600]\ttraining's rmse: 5.2225\ttraining's l2: 27.2745\tvalid_1's rmse: 8.1933\tvalid_1's l2: 67.1301\n",
      "[700]\ttraining's rmse: 4.91169\ttraining's l2: 24.1247\tvalid_1's rmse: 8.19153\tvalid_1's l2: 67.1012\n",
      "[800]\ttraining's rmse: 4.63027\ttraining's l2: 21.4394\tvalid_1's rmse: 8.19101\tvalid_1's l2: 67.0926\n",
      "Early stopping, best iteration is:\n",
      "[753]\ttraining's rmse: 4.76043\ttraining's l2: 22.6617\tvalid_1's rmse: 8.19024\tvalid_1's l2: 67.0801\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 8.19    \u001b[0m | \u001b[0m 0.7314  \u001b[0m | \u001b[0m 322.5   \u001b[0m | \u001b[0m 14.67   \u001b[0m | \u001b[0m 29.11   \u001b[0m | \u001b[0m 46.03   \u001b[0m | \u001b[0m 47.01   \u001b[0m | \u001b[0m 44.83   \u001b[0m | \u001b[0m 5.787   \u001b[0m | \u001b[0m 0.6073  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.83767\ttraining's l2: 61.4291\tvalid_1's rmse: 8.56483\tvalid_1's l2: 73.3564\n",
      "[200]\ttraining's rmse: 6.95472\ttraining's l2: 48.3682\tvalid_1's rmse: 8.31246\tvalid_1's l2: 69.097\n",
      "[300]\ttraining's rmse: 6.35543\ttraining's l2: 40.3915\tvalid_1's rmse: 8.24034\tvalid_1's l2: 67.9032\n",
      "[400]\ttraining's rmse: 5.87086\ttraining's l2: 34.4671\tvalid_1's rmse: 8.21688\tvalid_1's l2: 67.5171\n",
      "[500]\ttraining's rmse: 5.46166\ttraining's l2: 29.8298\tvalid_1's rmse: 8.20751\tvalid_1's l2: 67.3631\n",
      "[600]\ttraining's rmse: 5.10748\ttraining's l2: 26.0863\tvalid_1's rmse: 8.20404\tvalid_1's l2: 67.3063\n",
      "Early stopping, best iteration is:\n",
      "[591]\ttraining's rmse: 5.13723\ttraining's l2: 26.3911\tvalid_1's rmse: 8.20382\tvalid_1's l2: 67.3027\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 8.204   \u001b[0m | \u001b[0m 0.9712  \u001b[0m | \u001b[0m 489.0   \u001b[0m | \u001b[0m 15.25   \u001b[0m | \u001b[0m 49.44   \u001b[0m | \u001b[0m 26.52   \u001b[0m | \u001b[0m 47.24   \u001b[0m | \u001b[0m 39.95   \u001b[0m | \u001b[0m 2.888   \u001b[0m | \u001b[0m 0.8058  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.19159\ttraining's l2: 67.1022\tvalid_1's rmse: 8.63143\tvalid_1's l2: 74.5015\n",
      "[200]\ttraining's rmse: 7.52369\ttraining's l2: 56.606\tvalid_1's rmse: 8.34993\tvalid_1's l2: 69.7213\n",
      "[300]\ttraining's rmse: 7.10941\ttraining's l2: 50.5438\tvalid_1's rmse: 8.26546\tvalid_1's l2: 68.3179\n",
      "[400]\ttraining's rmse: 6.77045\ttraining's l2: 45.839\tvalid_1's rmse: 8.23223\tvalid_1's l2: 67.7697\n",
      "[500]\ttraining's rmse: 6.48346\ttraining's l2: 42.0352\tvalid_1's rmse: 8.21553\tvalid_1's l2: 67.495\n",
      "[600]\ttraining's rmse: 6.22841\ttraining's l2: 38.7931\tvalid_1's rmse: 8.20206\tvalid_1's l2: 67.2739\n",
      "[700]\ttraining's rmse: 5.99566\ttraining's l2: 35.9479\tvalid_1's rmse: 8.19345\tvalid_1's l2: 67.1326\n",
      "[800]\ttraining's rmse: 5.77795\ttraining's l2: 33.3847\tvalid_1's rmse: 8.19187\tvalid_1's l2: 67.1068\n",
      "[900]\ttraining's rmse: 5.57653\ttraining's l2: 31.0977\tvalid_1's rmse: 8.19483\tvalid_1's l2: 67.1553\n",
      "Early stopping, best iteration is:\n",
      "[808]\ttraining's rmse: 5.76061\ttraining's l2: 33.1846\tvalid_1's rmse: 8.19131\tvalid_1's l2: 67.0976\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 8.191   \u001b[0m | \u001b[0m 0.7876  \u001b[0m | \u001b[0m 240.7   \u001b[0m | \u001b[0m 13.27   \u001b[0m | \u001b[0m 133.4   \u001b[0m | \u001b[0m 33.93   \u001b[0m | \u001b[0m 28.29   \u001b[0m | \u001b[0m 39.58   \u001b[0m | \u001b[0m 1.11    \u001b[0m | \u001b[0m 0.7515  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.01392\ttraining's l2: 64.2229\tvalid_1's rmse: 8.58241\tvalid_1's l2: 73.6577\n",
      "[200]\ttraining's rmse: 7.25066\ttraining's l2: 52.572\tvalid_1's rmse: 8.30931\tvalid_1's l2: 69.0447\n",
      "[300]\ttraining's rmse: 6.74906\ttraining's l2: 45.5499\tvalid_1's rmse: 8.23144\tvalid_1's l2: 67.7567\n",
      "[400]\ttraining's rmse: 6.34809\ttraining's l2: 40.2983\tvalid_1's rmse: 8.19642\tvalid_1's l2: 67.1813\n",
      "[500]\ttraining's rmse: 6.00351\ttraining's l2: 36.0422\tvalid_1's rmse: 8.18518\tvalid_1's l2: 66.9972\n",
      "[600]\ttraining's rmse: 5.69708\ttraining's l2: 32.4567\tvalid_1's rmse: 8.1805\tvalid_1's l2: 66.9206\n",
      "[700]\ttraining's rmse: 5.42142\ttraining's l2: 29.3918\tvalid_1's rmse: 8.17487\tvalid_1's l2: 66.8285\n",
      "[800]\ttraining's rmse: 5.16277\ttraining's l2: 26.6542\tvalid_1's rmse: 8.17306\tvalid_1's l2: 66.7989\n",
      "Early stopping, best iteration is:\n",
      "[772]\ttraining's rmse: 5.23101\ttraining's l2: 27.3635\tvalid_1's rmse: 8.17248\tvalid_1's l2: 66.7895\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 8.172   \u001b[0m | \u001b[0m 0.5948  \u001b[0m | \u001b[0m 65.55   \u001b[0m | \u001b[0m 13.15   \u001b[0m | \u001b[0m 102.1   \u001b[0m | \u001b[0m 8.454   \u001b[0m | \u001b[0m 37.71   \u001b[0m | \u001b[0m 8.496   \u001b[0m | \u001b[0m 8.393   \u001b[0m | \u001b[0m 0.7137  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.95932\ttraining's l2: 63.3507\tvalid_1's rmse: 8.57253\tvalid_1's l2: 73.4883\n",
      "[200]\ttraining's rmse: 7.16565\ttraining's l2: 51.3465\tvalid_1's rmse: 8.30856\tvalid_1's l2: 69.0321\n",
      "[300]\ttraining's rmse: 6.63975\ttraining's l2: 44.0863\tvalid_1's rmse: 8.23533\tvalid_1's l2: 67.8206\n",
      "[400]\ttraining's rmse: 6.21612\ttraining's l2: 38.6402\tvalid_1's rmse: 8.20602\tvalid_1's l2: 67.3387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 5.84683\ttraining's l2: 34.1855\tvalid_1's rmse: 8.19437\tvalid_1's l2: 67.1477\n",
      "[600]\ttraining's rmse: 5.52279\ttraining's l2: 30.5012\tvalid_1's rmse: 8.18921\tvalid_1's l2: 67.0631\n",
      "[700]\ttraining's rmse: 5.22589\ttraining's l2: 27.31\tvalid_1's rmse: 8.18622\tvalid_1's l2: 67.0142\n",
      "[800]\ttraining's rmse: 4.9596\ttraining's l2: 24.5976\tvalid_1's rmse: 8.18875\tvalid_1's l2: 67.0556\n",
      "Early stopping, best iteration is:\n",
      "[713]\ttraining's rmse: 5.19134\ttraining's l2: 26.95\tvalid_1's rmse: 8.18594\tvalid_1's l2: 67.0096\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 8.186   \u001b[0m | \u001b[0m 0.5543  \u001b[0m | \u001b[0m 266.6   \u001b[0m | \u001b[0m 12.65   \u001b[0m | \u001b[0m 147.4   \u001b[0m | \u001b[0m 13.2    \u001b[0m | \u001b[0m 45.91   \u001b[0m | \u001b[0m 23.86   \u001b[0m | \u001b[0m 8.469   \u001b[0m | \u001b[0m 0.9726  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.93758\ttraining's l2: 63.0052\tvalid_1's rmse: 8.58069\tvalid_1's l2: 73.6282\n",
      "[200]\ttraining's rmse: 7.12689\ttraining's l2: 50.7926\tvalid_1's rmse: 8.31648\tvalid_1's l2: 69.1639\n",
      "[300]\ttraining's rmse: 6.60159\ttraining's l2: 43.581\tvalid_1's rmse: 8.24292\tvalid_1's l2: 67.9457\n",
      "[400]\ttraining's rmse: 6.18374\ttraining's l2: 38.2386\tvalid_1's rmse: 8.21485\tvalid_1's l2: 67.4838\n",
      "[500]\ttraining's rmse: 5.82106\ttraining's l2: 33.8848\tvalid_1's rmse: 8.20105\tvalid_1's l2: 67.2573\n",
      "[600]\ttraining's rmse: 5.5074\ttraining's l2: 30.3315\tvalid_1's rmse: 8.19363\tvalid_1's l2: 67.1356\n",
      "[700]\ttraining's rmse: 5.22824\ttraining's l2: 27.3345\tvalid_1's rmse: 8.18887\tvalid_1's l2: 67.0575\n",
      "[800]\ttraining's rmse: 4.9717\ttraining's l2: 24.7178\tvalid_1's rmse: 8.18913\tvalid_1's l2: 67.0618\n",
      "[900]\ttraining's rmse: 4.73429\ttraining's l2: 22.4135\tvalid_1's rmse: 8.18906\tvalid_1's l2: 67.0607\n",
      "Early stopping, best iteration is:\n",
      "[822]\ttraining's rmse: 4.91849\ttraining's l2: 24.1916\tvalid_1's rmse: 8.1861\tvalid_1's l2: 67.0123\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 8.186   \u001b[0m | \u001b[0m 0.6567  \u001b[0m | \u001b[0m 433.3   \u001b[0m | \u001b[0m 9.49    \u001b[0m | \u001b[0m 18.65   \u001b[0m | \u001b[0m 34.59   \u001b[0m | \u001b[0m 40.31   \u001b[0m | \u001b[0m 9.121   \u001b[0m | \u001b[0m 5.538   \u001b[0m | \u001b[0m 0.5815  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.16906\ttraining's l2: 66.7335\tvalid_1's rmse: 8.62735\tvalid_1's l2: 74.4312\n",
      "[200]\ttraining's rmse: 7.49307\ttraining's l2: 56.1462\tvalid_1's rmse: 8.34968\tvalid_1's l2: 69.7171\n",
      "[300]\ttraining's rmse: 7.07287\ttraining's l2: 50.0255\tvalid_1's rmse: 8.26148\tvalid_1's l2: 68.2521\n",
      "[400]\ttraining's rmse: 6.73551\ttraining's l2: 45.3671\tvalid_1's rmse: 8.22552\tvalid_1's l2: 67.6592\n",
      "[500]\ttraining's rmse: 6.44641\ttraining's l2: 41.5563\tvalid_1's rmse: 8.2042\tvalid_1's l2: 67.309\n",
      "[600]\ttraining's rmse: 6.19093\ttraining's l2: 38.3276\tvalid_1's rmse: 8.19647\tvalid_1's l2: 67.1821\n",
      "[700]\ttraining's rmse: 5.95399\ttraining's l2: 35.45\tvalid_1's rmse: 8.19028\tvalid_1's l2: 67.0807\n",
      "[800]\ttraining's rmse: 5.73855\ttraining's l2: 32.931\tvalid_1's rmse: 8.18581\tvalid_1's l2: 67.0075\n",
      "[900]\ttraining's rmse: 5.53536\ttraining's l2: 30.6402\tvalid_1's rmse: 8.18485\tvalid_1's l2: 66.9917\n",
      "[1000]\ttraining's rmse: 5.34182\ttraining's l2: 28.535\tvalid_1's rmse: 8.18782\tvalid_1's l2: 67.0404\n",
      "Early stopping, best iteration is:\n",
      "[912]\ttraining's rmse: 5.51136\ttraining's l2: 30.3751\tvalid_1's rmse: 8.18388\tvalid_1's l2: 66.9758\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 8.184   \u001b[0m | \u001b[0m 0.6299  \u001b[0m | \u001b[0m 460.8   \u001b[0m | \u001b[0m 9.51    \u001b[0m | \u001b[0m 107.5   \u001b[0m | \u001b[0m 27.24   \u001b[0m | \u001b[0m 29.0    \u001b[0m | \u001b[0m 36.78   \u001b[0m | \u001b[0m 0.7092  \u001b[0m | \u001b[0m 0.9752  \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(f=lgb_rmse_eval, pbounds=bayesian_params, random_state=1000)\n",
    "lgbBO.maximize(init_points=5, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 8.182122940865398,\n",
       "  'params': {'colsample_bytree': 0.8267947927323047,\n",
       "   'max_bin': 66.35340213095881,\n",
       "   'max_depth': 15.602262914792195,\n",
       "   'min_child_samples': 101.61636627131966,\n",
       "   'min_child_weight': 43.75125222391973,\n",
       "   'num_leaves': 32.4933072369088,\n",
       "   'reg_alpha': 2.045074142206765,\n",
       "   'reg_lambda': 3.9725474189957124,\n",
       "   'subsample': 0.61656609867419}},\n",
       " {'target': 8.197623319281618,\n",
       "  'params': {'colsample_bytree': 0.9208703621265308,\n",
       "   'max_bin': 111.47034874950597,\n",
       "   'max_depth': 13.93975626865927,\n",
       "   'min_child_samples': 84.50928428367985,\n",
       "   'min_child_weight': 9.930569477666833,\n",
       "   'num_leaves': 53.7415765836856,\n",
       "   'reg_alpha': 3.488408227688028,\n",
       "   'reg_lambda': 8.853486706603126,\n",
       "   'subsample': 0.9763221996107709}},\n",
       " {'target': 8.22208704283251,\n",
       "  'params': {'colsample_bytree': 0.9655717173387555,\n",
       "   'max_bin': 213.56116699200484,\n",
       "   'max_depth': 8.23185327509497,\n",
       "   'min_child_samples': 196.58522207365755,\n",
       "   'min_child_weight': 17.64224649812914,\n",
       "   'num_leaves': 52.26748775555215,\n",
       "   'reg_alpha': 18.100234609702014,\n",
       "   'reg_lambda': 0.35202387361566295,\n",
       "   'subsample': 0.9275291266202039}},\n",
       " {'target': 8.219204451219671,\n",
       "  'params': {'colsample_bytree': 0.8286267540702462,\n",
       "   'max_bin': 385.1846671311669,\n",
       "   'max_depth': 12.432697904035154,\n",
       "   'min_child_samples': 178.16765795601393,\n",
       "   'min_child_weight': 45.305683154470756,\n",
       "   'num_leaves': 24.416868022358166,\n",
       "   'reg_alpha': 3.737091239759974,\n",
       "   'reg_lambda': 2.447047468388093,\n",
       "   'subsample': 0.5666523762257424}},\n",
       " {'target': 8.203543721101621,\n",
       "  'params': {'colsample_bytree': 0.8489625502048597,\n",
       "   'max_bin': 205.1203929277082,\n",
       "   'max_depth': 15.064977531233142,\n",
       "   'min_child_samples': 44.39142695200357,\n",
       "   'min_child_weight': 22.19245941780866,\n",
       "   'num_leaves': 24.725728110186907,\n",
       "   'reg_alpha': 34.57497870582523,\n",
       "   'reg_lambda': 4.697436829706333,\n",
       "   'subsample': 0.5641110948268239}},\n",
       " {'target': 8.196010825482142,\n",
       "  'params': {'colsample_bytree': 0.6121906896087911,\n",
       "   'max_bin': 298.94998588649196,\n",
       "   'max_depth': 12.750846691073221,\n",
       "   'min_child_samples': 193.34531228046052,\n",
       "   'min_child_weight': 3.9736362810764536,\n",
       "   'num_leaves': 59.18788355168304,\n",
       "   'reg_alpha': 11.593649687316866,\n",
       "   'reg_lambda': 4.795613590281146,\n",
       "   'subsample': 0.5092708566003894}},\n",
       " {'target': 8.194536759035888,\n",
       "  'params': {'colsample_bytree': 0.674421523099342,\n",
       "   'max_bin': 384.4353816498156,\n",
       "   'max_depth': 15.720652569168081,\n",
       "   'min_child_samples': 183.28037305280367,\n",
       "   'min_child_weight': 44.39083123786284,\n",
       "   'num_leaves': 29.629357576646402,\n",
       "   'reg_alpha': 5.093738239695467,\n",
       "   'reg_lambda': 4.801212817757225,\n",
       "   'subsample': 0.898751931683061}},\n",
       " {'target': 8.185851778514591,\n",
       "  'params': {'colsample_bytree': 0.7675419859658956,\n",
       "   'max_bin': 132.0199627366569,\n",
       "   'max_depth': 14.298915241781739,\n",
       "   'min_child_samples': 40.3924686618707,\n",
       "   'min_child_weight': 44.75925548935725,\n",
       "   'num_leaves': 35.85435623811703,\n",
       "   'reg_alpha': 33.161736698845125,\n",
       "   'reg_lambda': 4.179346930104301,\n",
       "   'subsample': 0.9904558712794339}},\n",
       " {'target': 8.181840547348232,\n",
       "  'params': {'colsample_bytree': 0.5909121889605802,\n",
       "   'max_bin': 151.4451283058841,\n",
       "   'max_depth': 8.12570510974261,\n",
       "   'min_child_samples': 67.70982537785662,\n",
       "   'min_child_weight': 12.179556446382666,\n",
       "   'num_leaves': 57.97492807929662,\n",
       "   'reg_alpha': 5.11327135472758,\n",
       "   'reg_lambda': 2.9634057731939567,\n",
       "   'subsample': 0.5073924938486567}},\n",
       " {'target': 8.20013517309769,\n",
       "  'params': {'colsample_bytree': 0.9254172005439811,\n",
       "   'max_bin': 416.7208648802382,\n",
       "   'max_depth': 10.76574953773526,\n",
       "   'min_child_samples': 126.91007769267303,\n",
       "   'min_child_weight': 26.11112160742515,\n",
       "   'num_leaves': 29.613949340778454,\n",
       "   'reg_alpha': 48.70271304115722,\n",
       "   'reg_lambda': 7.307286495379972,\n",
       "   'subsample': 0.5610568992324143}},\n",
       " {'target': 8.172892840706846,\n",
       "  'params': {'colsample_bytree': 0.5141043094390911,\n",
       "   'max_bin': 254.3407418874025,\n",
       "   'max_depth': 15.332770159742921,\n",
       "   'min_child_samples': 103.21393354412879,\n",
       "   'min_child_weight': 46.90043392010393,\n",
       "   'num_leaves': 32.33623155988221,\n",
       "   'reg_alpha': 12.21846097676822,\n",
       "   'reg_lambda': 9.777330191074164,\n",
       "   'subsample': 0.6988643735876281}},\n",
       " {'target': 8.181618598585732,\n",
       "  'params': {'colsample_bytree': 0.5714645329357839,\n",
       "   'max_bin': 420.3449035602966,\n",
       "   'max_depth': 15.043879875899249,\n",
       "   'min_child_samples': 124.99880880459827,\n",
       "   'min_child_weight': 3.5244762071364786,\n",
       "   'num_leaves': 35.44420386327446,\n",
       "   'reg_alpha': 22.54827686645599,\n",
       "   'reg_lambda': 3.945893499815971,\n",
       "   'subsample': 0.9636697925128256}},\n",
       " {'target': 8.187217277548443,\n",
       "  'params': {'colsample_bytree': 0.579276254301057,\n",
       "   'max_bin': 255.18517768650602,\n",
       "   'max_depth': 13.550001654403957,\n",
       "   'min_child_samples': 12.505066102402521,\n",
       "   'min_child_weight': 29.42773011515404,\n",
       "   'num_leaves': 39.820389083540235,\n",
       "   'reg_alpha': 33.960034049410424,\n",
       "   'reg_lambda': 5.65260345331489,\n",
       "   'subsample': 0.8581227529538189}},\n",
       " {'target': 8.191510637999292,\n",
       "  'params': {'colsample_bytree': 0.8277971309851977,\n",
       "   'max_bin': 110.69879762220646,\n",
       "   'max_depth': 15.823214177538233,\n",
       "   'min_child_samples': 82.63273418295236,\n",
       "   'min_child_weight': 9.746284355709184,\n",
       "   'num_leaves': 54.331086480648416,\n",
       "   'reg_alpha': 9.337516326590167,\n",
       "   'reg_lambda': 4.784135361327789,\n",
       "   'subsample': 0.9854905351128942}},\n",
       " {'target': 8.198231394860912,\n",
       "  'params': {'colsample_bytree': 0.66587818349067,\n",
       "   'max_bin': 318.85670293585764,\n",
       "   'max_depth': 14.696083656856331,\n",
       "   'min_child_samples': 89.28919948696489,\n",
       "   'min_child_weight': 7.6786440348103335,\n",
       "   'num_leaves': 54.40354378771569,\n",
       "   'reg_alpha': 41.984699177480934,\n",
       "   'reg_lambda': 4.397204203719935,\n",
       "   'subsample': 0.6464426489126807}},\n",
       " {'target': 8.214368607895045,\n",
       "  'params': {'colsample_bytree': 0.8911768943126078,\n",
       "   'max_bin': 226.82335694733166,\n",
       "   'max_depth': 9.58652048927745,\n",
       "   'min_child_samples': 45.26117358341472,\n",
       "   'min_child_weight': 38.35804601447657,\n",
       "   'num_leaves': 58.79479371344334,\n",
       "   'reg_alpha': 48.616770778588304,\n",
       "   'reg_lambda': 2.7092744689647326,\n",
       "   'subsample': 0.9831742043197643}},\n",
       " {'target': 8.205552464129399,\n",
       "  'params': {'colsample_bytree': 0.9318807646090632,\n",
       "   'max_bin': 265.05132830154224,\n",
       "   'max_depth': 8.634833232254739,\n",
       "   'min_child_samples': 55.92302516802116,\n",
       "   'min_child_weight': 4.254390351086849,\n",
       "   'num_leaves': 32.03886139159377,\n",
       "   'reg_alpha': 37.83364228095505,\n",
       "   'reg_lambda': 6.107782167557087,\n",
       "   'subsample': 0.9043824557585871}},\n",
       " {'target': 8.200756520495782,\n",
       "  'params': {'colsample_bytree': 0.8400676823446944,\n",
       "   'max_bin': 218.03126694416892,\n",
       "   'max_depth': 10.828374957564478,\n",
       "   'min_child_samples': 18.53296578103854,\n",
       "   'min_child_weight': 44.08053706636261,\n",
       "   'num_leaves': 48.2828624584605,\n",
       "   'reg_alpha': 31.386355289971423,\n",
       "   'reg_lambda': 5.16125396023365,\n",
       "   'subsample': 0.8320839011056689}},\n",
       " {'target': 8.197481069653549,\n",
       "  'params': {'colsample_bytree': 0.7178480127649094,\n",
       "   'max_bin': 174.6944105583218,\n",
       "   'max_depth': 10.291625851974237,\n",
       "   'min_child_samples': 36.11565074404746,\n",
       "   'min_child_weight': 11.2039887326501,\n",
       "   'num_leaves': 59.424618627709016,\n",
       "   'reg_alpha': 23.53333846758369,\n",
       "   'reg_lambda': 9.779720391939048,\n",
       "   'subsample': 0.562822235810886}},\n",
       " {'target': 8.206754863699791,\n",
       "  'params': {'colsample_bytree': 0.8023267797378124,\n",
       "   'max_bin': 372.2860100070965,\n",
       "   'max_depth': 13.219571070044436,\n",
       "   'min_child_samples': 189.73023488549583,\n",
       "   'min_child_weight': 29.798620436536304,\n",
       "   'num_leaves': 29.276672554717873,\n",
       "   'reg_alpha': 46.44571088697003,\n",
       "   'reg_lambda': 6.261069677877012,\n",
       "   'subsample': 0.5583173239443255}},\n",
       " {'target': 8.193554223877586,\n",
       "  'params': {'colsample_bytree': 0.6120817815183712,\n",
       "   'max_bin': 56.0127776812391,\n",
       "   'max_depth': 13.317409740581677,\n",
       "   'min_child_samples': 86.02488861817797,\n",
       "   'min_child_weight': 2.5349663365974218,\n",
       "   'num_leaves': 43.42729499707772,\n",
       "   'reg_alpha': 12.803004993547578,\n",
       "   'reg_lambda': 3.4478154743231246,\n",
       "   'subsample': 0.5242887645884554}},\n",
       " {'target': 8.200109944431139,\n",
       "  'params': {'colsample_bytree': 0.6732251624430192,\n",
       "   'max_bin': 294.7874607558146,\n",
       "   'max_depth': 15.03557802324086,\n",
       "   'min_child_samples': 117.94571860407643,\n",
       "   'min_child_weight': 26.818627877552583,\n",
       "   'num_leaves': 46.0687492784547,\n",
       "   'reg_alpha': 13.764074735933072,\n",
       "   'reg_lambda': 3.301926621834465,\n",
       "   'subsample': 0.536326218637151}},\n",
       " {'target': 8.205414929163604,\n",
       "  'params': {'colsample_bytree': 0.8190266681526392,\n",
       "   'max_bin': 33.68191484561372,\n",
       "   'max_depth': 14.314513862874048,\n",
       "   'min_child_samples': 81.77454047856418,\n",
       "   'min_child_weight': 30.156229899215923,\n",
       "   'num_leaves': 39.26811414744852,\n",
       "   'reg_alpha': 19.79003701633323,\n",
       "   'reg_lambda': 7.492847592955431,\n",
       "   'subsample': 0.6173422050108449}},\n",
       " {'target': 8.190244985724913,\n",
       "  'params': {'colsample_bytree': 0.7313688492739636,\n",
       "   'max_bin': 322.5275403491443,\n",
       "   'max_depth': 14.673684562656568,\n",
       "   'min_child_samples': 29.114738453076193,\n",
       "   'min_child_weight': 46.030863317824036,\n",
       "   'num_leaves': 47.0053495458919,\n",
       "   'reg_alpha': 44.834265453778464,\n",
       "   'reg_lambda': 5.78718670439186,\n",
       "   'subsample': 0.6073219592234658}},\n",
       " {'target': 8.203819786344848,\n",
       "  'params': {'colsample_bytree': 0.9711690837725098,\n",
       "   'max_bin': 489.01892794129435,\n",
       "   'max_depth': 15.25460690968541,\n",
       "   'min_child_samples': 49.441701762561564,\n",
       "   'min_child_weight': 26.524651705286505,\n",
       "   'num_leaves': 47.23669174089605,\n",
       "   'reg_alpha': 39.94907265936229,\n",
       "   'reg_lambda': 2.888339333527107,\n",
       "   'subsample': 0.8058092781209045}},\n",
       " {'target': 8.191310306440302,\n",
       "  'params': {'colsample_bytree': 0.7875849687909198,\n",
       "   'max_bin': 240.73276061806476,\n",
       "   'max_depth': 13.271184231558605,\n",
       "   'min_child_samples': 133.44942208159318,\n",
       "   'min_child_weight': 33.92950087465731,\n",
       "   'num_leaves': 28.29136702239342,\n",
       "   'reg_alpha': 39.57648860320042,\n",
       "   'reg_lambda': 1.1096346827494934,\n",
       "   'subsample': 0.7514903797268531}},\n",
       " {'target': 8.172484666063644,\n",
       "  'params': {'colsample_bytree': 0.5948136651099992,\n",
       "   'max_bin': 65.54879996738464,\n",
       "   'max_depth': 13.147136974234437,\n",
       "   'min_child_samples': 102.1230118149357,\n",
       "   'min_child_weight': 8.454065086716847,\n",
       "   'num_leaves': 37.71286374411538,\n",
       "   'reg_alpha': 8.495603759047018,\n",
       "   'reg_lambda': 8.3932459613762,\n",
       "   'subsample': 0.7136850800625171}},\n",
       " {'target': 8.185938050237052,\n",
       "  'params': {'colsample_bytree': 0.5543446579385094,\n",
       "   'max_bin': 266.60902033120465,\n",
       "   'max_depth': 12.646496395874314,\n",
       "   'min_child_samples': 147.43609706902322,\n",
       "   'min_child_weight': 13.197385976374632,\n",
       "   'num_leaves': 45.91016035048342,\n",
       "   'reg_alpha': 23.860024134242312,\n",
       "   'reg_lambda': 8.46904710281589,\n",
       "   'subsample': 0.9725842699472822}},\n",
       " {'target': 8.186104563894819,\n",
       "  'params': {'colsample_bytree': 0.6566524967268413,\n",
       "   'max_bin': 433.3057760989586,\n",
       "   'max_depth': 9.490104821932347,\n",
       "   'min_child_samples': 18.647514843077314,\n",
       "   'min_child_weight': 34.592646399786794,\n",
       "   'num_leaves': 40.311724206988984,\n",
       "   'reg_alpha': 9.1208781474659,\n",
       "   'reg_lambda': 5.538063770411299,\n",
       "   'subsample': 0.5814532301163122}},\n",
       " {'target': 8.183877103368667,\n",
       "  'params': {'colsample_bytree': 0.629860556156569,\n",
       "   'max_bin': 460.82332141706166,\n",
       "   'max_depth': 9.509502228957304,\n",
       "   'min_child_samples': 107.51085863131226,\n",
       "   'min_child_weight': 27.23714172016,\n",
       "   'num_leaves': 29.000040122066785,\n",
       "   'reg_alpha': 36.779227385182146,\n",
       "   'reg_lambda': 0.7092204670193314,\n",
       "   'subsample': 0.9752444932102324}}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.182122940865398, 8.197623319281618, 8.22208704283251, 8.219204451219671, 8.203543721101621, 8.196010825482142, 8.194536759035888, 8.185851778514591, 8.181840547348232, 8.20013517309769, 8.172892840706846, 8.181618598585732, 8.187217277548443, 8.191510637999292, 8.198231394860912, 8.214368607895045, 8.205552464129399, 8.200756520495782, 8.197481069653549, 8.206754863699791, 8.193554223877586, 8.200109944431139, 8.205414929163604, 8.190244985724913, 8.203819786344848, 8.191310306440302, 8.172484666063644, 8.185938050237052, 8.186104563894819, 8.183877103368667]\n",
      "maximum target index: 26\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmin(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 8.172484666063644, 'params': {'colsample_bytree': 0.5948136651099992, 'max_bin': 65.54879996738464, 'max_depth': 13.147136974234437, 'min_child_samples': 102.1230118149357, 'min_child_weight': 8.454065086716847, 'num_leaves': 37.71286374411538, 'reg_alpha': 8.495603759047018, 'reg_lambda': 8.3932459613762, 'subsample': 0.7136850800625171}}\n"
     ]
    }
   ],
   "source": [
    "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
    "max_dict = lgbBO.res[np.argmin(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = DataFrame(X_new)\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_apps_all_with_oof(ftr, target, nfolds=5):\n",
    "    ftr = ftr\n",
    "    target = target\n",
    "\n",
    "    # nfolds 개의 cross validatin fold set을 가지는 KFold 생성 \n",
    "    folds = KFold(n_splits=nfolds, shuffle=True, random_state=0)\n",
    "    \n",
    "    # Out of Folds로 학습된 모델의 validation set을 예측하여 결과 확률을 담을 array 생성.\n",
    "    # validation set가 n_split갯수만큼 있으므로 크기는 ftr_app의 크기가 되어야 함. \n",
    "    oof_preds = np.zeros((ftr.shape[0],))  \n",
    "    \n",
    "    # Ouf of Folds로 학습된 모델의 test dataset을 예측하여 결과 확률을 담을 array 생성. \n",
    "    test_preds = np.zeros(((X_te_new.shape[0],)))\n",
    "    \n",
    "    # n_estimators를 4000까지 확대. \n",
    "    clf = LGBMRegressor(\n",
    "                nthread=4,\n",
    "                n_estimators=4000,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=13,\n",
    "                num_leaves=37,\n",
    "                colsample_bytree=0.594,\n",
    "                subsample=0.713,\n",
    "                max_bin= 65,\n",
    "                reg_alpha=8.495,\n",
    "                reg_lambda=8.393,\n",
    "                min_child_weight=8,\n",
    "                min_child_samples=102,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                )\n",
    "\n",
    "    # nfolds 번 cross validation Iteration 반복하면서 OOF 방식으로 학습 및 테스트 데이터 예측\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(ftr)):\n",
    "        print('##### iteration ', fold_idx, ' 시작')\n",
    "        # 학습용 데이터 세트의 인덱스와 검증용 데이터 세트의 인덱스 추출하여 이를 기반으로 학습/검증 데이터 추출\n",
    "        train_x = ftr.iloc[train_idx, :]\n",
    "        train_y = target.iloc[train_idx]\n",
    "        valid_x = ftr.iloc[valid_idx, :]\n",
    "        valid_y = target.iloc[valid_idx]\n",
    "        \n",
    "        # 추출된 학습/검증 데이터 세트로 모델 학습. early_stopping은 200으로 증가. \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'RMSE', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "        # 검증 데이터 세트로 예측된 확률 저장. 사용되지는 않음. \n",
    "        #oof_preds[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration_)       \n",
    "        # 학습된 모델로 테스트 데이터 세트에 예측 확률 계산. \n",
    "        # nfolds 번 반복 실행하므로 평균 확률을 구하기 위해 개별 수행시 마다 수행 횟수로 나눈 확률을 추후에 더해서 최종 평균 확률 계산. \n",
    "        test_preds += clf.predict(X_te_new, num_iteration=clf.best_iteration_)/folds.n_splits\n",
    "        \n",
    "        \n",
    "    return clf, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### iteration  0  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 8.09925\ttraining's l2: 65.5978\tvalid_1's rmse: 8.6051\tvalid_1's l2: 74.0477\n",
      "[400]\ttraining's rmse: 7.39934\ttraining's l2: 54.7503\tvalid_1's rmse: 8.32582\tvalid_1's l2: 69.3192\n",
      "[600]\ttraining's rmse: 6.94931\ttraining's l2: 48.2929\tvalid_1's rmse: 8.24741\tvalid_1's l2: 68.0197\n",
      "[800]\ttraining's rmse: 6.58443\ttraining's l2: 43.3547\tvalid_1's rmse: 8.21011\tvalid_1's l2: 67.406\n",
      "[1000]\ttraining's rmse: 6.27295\ttraining's l2: 39.3498\tvalid_1's rmse: 8.19383\tvalid_1's l2: 67.1389\n",
      "[1200]\ttraining's rmse: 5.99461\ttraining's l2: 35.9353\tvalid_1's rmse: 8.18104\tvalid_1's l2: 66.9294\n",
      "[1400]\ttraining's rmse: 5.74255\ttraining's l2: 32.9769\tvalid_1's rmse: 8.17517\tvalid_1's l2: 66.8335\n",
      "[1600]\ttraining's rmse: 5.51174\ttraining's l2: 30.3793\tvalid_1's rmse: 8.1713\tvalid_1's l2: 66.7701\n",
      "[1800]\ttraining's rmse: 5.29332\ttraining's l2: 28.0192\tvalid_1's rmse: 8.16836\tvalid_1's l2: 66.722\n",
      "[2000]\ttraining's rmse: 5.08613\ttraining's l2: 25.8687\tvalid_1's rmse: 8.16435\tvalid_1's l2: 66.6566\n",
      "[2200]\ttraining's rmse: 4.89222\ttraining's l2: 23.9338\tvalid_1's rmse: 8.16581\tvalid_1's l2: 66.6805\n",
      "Early stopping, best iteration is:\n",
      "[2044]\ttraining's rmse: 5.04229\ttraining's l2: 25.4247\tvalid_1's rmse: 8.16407\tvalid_1's l2: 66.652\n",
      "##### iteration  1  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 8.10802\ttraining's l2: 65.7399\tvalid_1's rmse: 8.56037\tvalid_1's l2: 73.28\n",
      "[400]\ttraining's rmse: 7.41799\ttraining's l2: 55.0265\tvalid_1's rmse: 8.26422\tvalid_1's l2: 68.2974\n",
      "[600]\ttraining's rmse: 6.97549\ttraining's l2: 48.6575\tvalid_1's rmse: 8.17123\tvalid_1's l2: 66.769\n",
      "[800]\ttraining's rmse: 6.61402\ttraining's l2: 43.7453\tvalid_1's rmse: 8.12194\tvalid_1's l2: 65.9659\n",
      "[1000]\ttraining's rmse: 6.30233\ttraining's l2: 39.7193\tvalid_1's rmse: 8.08952\tvalid_1's l2: 65.4403\n",
      "[1200]\ttraining's rmse: 6.02848\ttraining's l2: 36.3426\tvalid_1's rmse: 8.07696\tvalid_1's l2: 65.2372\n",
      "[1400]\ttraining's rmse: 5.77911\ttraining's l2: 33.3981\tvalid_1's rmse: 8.06582\tvalid_1's l2: 65.0575\n",
      "[1600]\ttraining's rmse: 5.54922\ttraining's l2: 30.7939\tvalid_1's rmse: 8.06422\tvalid_1's l2: 65.0316\n",
      "[1800]\ttraining's rmse: 5.33144\ttraining's l2: 28.4242\tvalid_1's rmse: 8.06143\tvalid_1's l2: 64.9867\n",
      "[2000]\ttraining's rmse: 5.13121\ttraining's l2: 26.3293\tvalid_1's rmse: 8.0577\tvalid_1's l2: 64.9265\n",
      "[2200]\ttraining's rmse: 4.93869\ttraining's l2: 24.3906\tvalid_1's rmse: 8.05485\tvalid_1's l2: 64.8806\n",
      "[2400]\ttraining's rmse: 4.75609\ttraining's l2: 22.6204\tvalid_1's rmse: 8.05574\tvalid_1's l2: 64.895\n",
      "Early stopping, best iteration is:\n",
      "[2315]\ttraining's rmse: 4.83171\ttraining's l2: 23.3455\tvalid_1's rmse: 8.0534\tvalid_1's l2: 64.8573\n",
      "##### iteration  2  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 8.1119\ttraining's l2: 65.803\tvalid_1's rmse: 8.53465\tvalid_1's l2: 72.8402\n",
      "[400]\ttraining's rmse: 7.40851\ttraining's l2: 54.886\tvalid_1's rmse: 8.27079\tvalid_1's l2: 68.4059\n",
      "[600]\ttraining's rmse: 6.9586\ttraining's l2: 48.4221\tvalid_1's rmse: 8.20355\tvalid_1's l2: 67.2982\n",
      "[800]\ttraining's rmse: 6.59285\ttraining's l2: 43.4657\tvalid_1's rmse: 8.16568\tvalid_1's l2: 66.6783\n",
      "[1000]\ttraining's rmse: 6.2814\ttraining's l2: 39.456\tvalid_1's rmse: 8.14416\tvalid_1's l2: 66.3274\n",
      "[1200]\ttraining's rmse: 6.00097\ttraining's l2: 36.0116\tvalid_1's rmse: 8.13185\tvalid_1's l2: 66.1271\n",
      "[1400]\ttraining's rmse: 5.74861\ttraining's l2: 33.0465\tvalid_1's rmse: 8.1239\tvalid_1's l2: 65.9977\n",
      "[1600]\ttraining's rmse: 5.51503\ttraining's l2: 30.4155\tvalid_1's rmse: 8.12053\tvalid_1's l2: 65.9431\n",
      "[1800]\ttraining's rmse: 5.29648\ttraining's l2: 28.0527\tvalid_1's rmse: 8.11845\tvalid_1's l2: 65.9092\n",
      "[2000]\ttraining's rmse: 5.09197\ttraining's l2: 25.9281\tvalid_1's rmse: 8.1164\tvalid_1's l2: 65.876\n",
      "Early stopping, best iteration is:\n",
      "[1967]\ttraining's rmse: 5.12531\ttraining's l2: 26.2688\tvalid_1's rmse: 8.11522\tvalid_1's l2: 65.8568\n",
      "##### iteration  3  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 8.0787\ttraining's l2: 65.2654\tvalid_1's rmse: 8.73656\tvalid_1's l2: 76.3274\n",
      "[400]\ttraining's rmse: 7.38842\ttraining's l2: 54.5888\tvalid_1's rmse: 8.43509\tvalid_1's l2: 71.1508\n",
      "[600]\ttraining's rmse: 6.93536\ttraining's l2: 48.0992\tvalid_1's rmse: 8.33769\tvalid_1's l2: 69.5171\n",
      "[800]\ttraining's rmse: 6.56696\ttraining's l2: 43.1249\tvalid_1's rmse: 8.28733\tvalid_1's l2: 68.6798\n",
      "[1000]\ttraining's rmse: 6.25657\ttraining's l2: 39.1447\tvalid_1's rmse: 8.259\tvalid_1's l2: 68.211\n",
      "[1200]\ttraining's rmse: 5.97837\ttraining's l2: 35.7409\tvalid_1's rmse: 8.24534\tvalid_1's l2: 67.9857\n",
      "[1400]\ttraining's rmse: 5.72959\ttraining's l2: 32.8282\tvalid_1's rmse: 8.23446\tvalid_1's l2: 67.8063\n",
      "[1600]\ttraining's rmse: 5.49915\ttraining's l2: 30.2406\tvalid_1's rmse: 8.22531\tvalid_1's l2: 67.6556\n",
      "[1800]\ttraining's rmse: 5.2813\ttraining's l2: 27.8921\tvalid_1's rmse: 8.22227\tvalid_1's l2: 67.6057\n",
      "Early stopping, best iteration is:\n",
      "[1772]\ttraining's rmse: 5.3107\ttraining's l2: 28.2036\tvalid_1's rmse: 8.22102\tvalid_1's l2: 67.5852\n",
      "##### iteration  4  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 8.11862\ttraining's l2: 65.912\tvalid_1's rmse: 8.58939\tvalid_1's l2: 73.7777\n",
      "[400]\ttraining's rmse: 7.42329\ttraining's l2: 55.1052\tvalid_1's rmse: 8.29169\tvalid_1's l2: 68.7521\n",
      "[600]\ttraining's rmse: 6.97644\ttraining's l2: 48.6707\tvalid_1's rmse: 8.19557\tvalid_1's l2: 67.1673\n",
      "[800]\ttraining's rmse: 6.61758\ttraining's l2: 43.7924\tvalid_1's rmse: 8.14862\tvalid_1's l2: 66.4\n",
      "[1000]\ttraining's rmse: 6.30999\ttraining's l2: 39.816\tvalid_1's rmse: 8.12669\tvalid_1's l2: 66.0431\n",
      "[1200]\ttraining's rmse: 6.03323\ttraining's l2: 36.3998\tvalid_1's rmse: 8.11106\tvalid_1's l2: 65.7893\n",
      "[1400]\ttraining's rmse: 5.77984\ttraining's l2: 33.4066\tvalid_1's rmse: 8.1021\tvalid_1's l2: 65.644\n",
      "[1600]\ttraining's rmse: 5.54791\ttraining's l2: 30.7793\tvalid_1's rmse: 8.09635\tvalid_1's l2: 65.5508\n",
      "[1800]\ttraining's rmse: 5.3296\ttraining's l2: 28.4046\tvalid_1's rmse: 8.09122\tvalid_1's l2: 65.4678\n",
      "[2000]\ttraining's rmse: 5.12543\ttraining's l2: 26.27\tvalid_1's rmse: 8.08841\tvalid_1's l2: 65.4224\n",
      "Early stopping, best iteration is:\n",
      "[1922]\ttraining's rmse: 5.2043\ttraining's l2: 27.0848\tvalid_1's rmse: 8.08711\tvalid_1's l2: 65.4013\n"
     ]
    }
   ],
   "source": [
    "clf, test_preds = train_apps_all_with_oof(ftr, target, nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.48608066, 41.57529689, 26.88872272, ..., 35.15863906,\n",
       "       33.5709692 , 27.06398132])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDtest['age'] = test_preds ; sub = IDtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submissions_0613_hyun_ha_scaled_lgbm_tun.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
