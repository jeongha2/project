{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family=fm.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()) # for Windows OS user\n",
    "import math\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import klib\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys, warnings\n",
    "if not sys.warnoptions: warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import ClassifierMixin\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = pd.read_csv(os.path.abspath(\"../input\")+'/X_train.csv', encoding='cp949')\n",
    "df_x_test = pd.read_csv(os.path.abspath(\"../input\")+'/X_test.csv', encoding='cp949')\n",
    "df_y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv').age\n",
    "df_y_train_mer = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv')\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949')\n",
    "IDtrain = pd.DataFrame({'custid': df_x_train.custid.unique()})\n",
    "IDtest = pd.DataFrame({'custid': df_x_test.custid.unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.abspath(\"../input\")+'/features__2rd_munnew.csv')\n",
    "dft = pd.read_csv(os.path.abspath(\"../input\")+'/features_t__2rd_munnew.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([IDtrain['custid'] , df.iloc[:,1:] ], axis=1)\n",
    "\n",
    "IDtest.index = dft.index\n",
    "data_te = pd.concat([IDtest['custid'] , dft.iloc[:,1:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1219</th>\n",
       "      <th>1220</th>\n",
       "      <th>1221</th>\n",
       "      <th>1222</th>\n",
       "      <th>1223</th>\n",
       "      <th>1224</th>\n",
       "      <th>1225</th>\n",
       "      <th>1226</th>\n",
       "      <th>1227</th>\n",
       "      <th>1228</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.128385</td>\n",
       "      <td>0.177661</td>\n",
       "      <td>-0.076504</td>\n",
       "      <td>-0.019491</td>\n",
       "      <td>-0.153996</td>\n",
       "      <td>-0.018015</td>\n",
       "      <td>0.259428</td>\n",
       "      <td>-0.094061</td>\n",
       "      <td>0.009650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018063</td>\n",
       "      <td>-0.017152</td>\n",
       "      <td>-0.018621</td>\n",
       "      <td>0.020283</td>\n",
       "      <td>-0.006672</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>-8.104087e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.020514</td>\n",
       "      <td>0.183845</td>\n",
       "      <td>-0.100130</td>\n",
       "      <td>0.168055</td>\n",
       "      <td>-0.110714</td>\n",
       "      <td>0.068587</td>\n",
       "      <td>0.271568</td>\n",
       "      <td>-0.257914</td>\n",
       "      <td>-0.075340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.032461</td>\n",
       "      <td>0.042880</td>\n",
       "      <td>-0.058111</td>\n",
       "      <td>0.030624</td>\n",
       "      <td>-0.098446</td>\n",
       "      <td>-0.047456</td>\n",
       "      <td>-0.026214</td>\n",
       "      <td>-0.017247</td>\n",
       "      <td>-1.371190e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.151863</td>\n",
       "      <td>0.087313</td>\n",
       "      <td>0.112846</td>\n",
       "      <td>0.053923</td>\n",
       "      <td>-0.023841</td>\n",
       "      <td>0.106159</td>\n",
       "      <td>0.104671</td>\n",
       "      <td>-0.018463</td>\n",
       "      <td>-0.114120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>-0.006413</td>\n",
       "      <td>-0.007241</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>-0.002858</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>-0.000452</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>-3.992834e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.090748</td>\n",
       "      <td>0.321043</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>-0.030182</td>\n",
       "      <td>-0.096105</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>0.246510</td>\n",
       "      <td>-0.494843</td>\n",
       "      <td>-0.153286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.185318</td>\n",
       "      <td>-0.051097</td>\n",
       "      <td>-0.049447</td>\n",
       "      <td>0.049038</td>\n",
       "      <td>-0.014176</td>\n",
       "      <td>-0.001616</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>-1.370112e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.192596</td>\n",
       "      <td>0.141276</td>\n",
       "      <td>0.119395</td>\n",
       "      <td>0.158113</td>\n",
       "      <td>-0.123039</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.110710</td>\n",
       "      <td>-0.057286</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018063</td>\n",
       "      <td>-0.017152</td>\n",
       "      <td>-0.018621</td>\n",
       "      <td>0.020283</td>\n",
       "      <td>-0.006672</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>-8.104087e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>29995</td>\n",
       "      <td>0.092677</td>\n",
       "      <td>0.058491</td>\n",
       "      <td>0.051903</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>-0.214666</td>\n",
       "      <td>-0.006617</td>\n",
       "      <td>0.232950</td>\n",
       "      <td>-0.030975</td>\n",
       "      <td>-0.081695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017652</td>\n",
       "      <td>0.035054</td>\n",
       "      <td>0.046835</td>\n",
       "      <td>-0.064483</td>\n",
       "      <td>0.035731</td>\n",
       "      <td>-0.026536</td>\n",
       "      <td>-0.015691</td>\n",
       "      <td>-0.015465</td>\n",
       "      <td>-0.010456</td>\n",
       "      <td>-9.696665e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>29996</td>\n",
       "      <td>0.080351</td>\n",
       "      <td>-0.016363</td>\n",
       "      <td>0.097993</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>-0.127212</td>\n",
       "      <td>0.092760</td>\n",
       "      <td>0.239461</td>\n",
       "      <td>-0.070794</td>\n",
       "      <td>-0.213505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.185318</td>\n",
       "      <td>-0.051097</td>\n",
       "      <td>-0.049447</td>\n",
       "      <td>0.049038</td>\n",
       "      <td>-0.014176</td>\n",
       "      <td>-0.001616</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>-1.370112e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>29997</td>\n",
       "      <td>0.051041</td>\n",
       "      <td>0.183228</td>\n",
       "      <td>-0.042149</td>\n",
       "      <td>-0.019735</td>\n",
       "      <td>-0.027181</td>\n",
       "      <td>0.038104</td>\n",
       "      <td>0.370043</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>-0.133187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018063</td>\n",
       "      <td>-0.017152</td>\n",
       "      <td>-0.018621</td>\n",
       "      <td>0.020283</td>\n",
       "      <td>-0.006672</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>-8.104087e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>29998</td>\n",
       "      <td>0.075727</td>\n",
       "      <td>0.119575</td>\n",
       "      <td>0.073133</td>\n",
       "      <td>-0.009972</td>\n",
       "      <td>-0.099283</td>\n",
       "      <td>0.061357</td>\n",
       "      <td>0.225503</td>\n",
       "      <td>-0.024459</td>\n",
       "      <td>-0.172464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.005674</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-3.248017e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21586</th>\n",
       "      <td>29999</td>\n",
       "      <td>0.254841</td>\n",
       "      <td>-0.085915</td>\n",
       "      <td>-0.010114</td>\n",
       "      <td>-0.017507</td>\n",
       "      <td>-0.231735</td>\n",
       "      <td>0.151664</td>\n",
       "      <td>0.294240</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>0.048833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.005674</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-3.248017e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21587 rows × 1230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       custid         0         1         2         3         4         5  \\\n",
       "0           0  0.128385  0.177661 -0.076504 -0.019491 -0.153996 -0.018015   \n",
       "1           2 -0.020514  0.183845 -0.100130  0.168055 -0.110714  0.068587   \n",
       "2           3  0.151863  0.087313  0.112846  0.053923 -0.023841  0.106159   \n",
       "3           4 -0.090748  0.321043  0.002612 -0.030182 -0.096105  0.109478   \n",
       "4           5  0.192596  0.141276  0.119395  0.158113 -0.123039  0.012903   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "21582   29995  0.092677  0.058491  0.051903  0.029485 -0.214666 -0.006617   \n",
       "21583   29996  0.080351 -0.016363  0.097993  0.010958 -0.127212  0.092760   \n",
       "21584   29997  0.051041  0.183228 -0.042149 -0.019735 -0.027181  0.038104   \n",
       "21585   29998  0.075727  0.119575  0.073133 -0.009972 -0.099283  0.061357   \n",
       "21586   29999  0.254841 -0.085915 -0.010114 -0.017507 -0.231735  0.151664   \n",
       "\n",
       "              6         7         8  ...      1219      1220      1221  \\\n",
       "0      0.259428 -0.094061  0.009650  ... -0.018063 -0.017152 -0.018621   \n",
       "1      0.271568 -0.257914 -0.075340  ...  0.016781  0.032461  0.042880   \n",
       "2      0.104671 -0.018463 -0.114120  ... -0.005516 -0.006413 -0.007241   \n",
       "3      0.246510 -0.494843 -0.153286  ... -0.185318 -0.051097 -0.049447   \n",
       "4      0.110710 -0.057286  0.008279  ... -0.018063 -0.017152 -0.018621   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21582  0.232950 -0.030975 -0.081695  ...  0.017652  0.035054  0.046835   \n",
       "21583  0.239461 -0.070794 -0.213505  ... -0.185318 -0.051097 -0.049447   \n",
       "21584  0.370043  0.024100 -0.133187  ... -0.018063 -0.017152 -0.018621   \n",
       "21585  0.225503 -0.024459 -0.172464  ... -0.004198 -0.004998 -0.005674   \n",
       "21586  0.294240 -0.055767  0.048833  ... -0.004198 -0.004998 -0.005674   \n",
       "\n",
       "           1222      1223      1224      1225      1226      1227  \\\n",
       "0      0.020283 -0.006672 -0.000920 -0.000592 -0.000930 -0.000653   \n",
       "1     -0.058111  0.030624 -0.098446 -0.047456 -0.026214 -0.017247   \n",
       "2      0.008185 -0.002858 -0.000441 -0.000284 -0.000452 -0.000318   \n",
       "3      0.049038 -0.014176 -0.001616 -0.001037 -0.001602 -0.001123   \n",
       "4      0.020283 -0.006672 -0.000920 -0.000592 -0.000930 -0.000653   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "21582 -0.064483  0.035731 -0.026536 -0.015691 -0.015465 -0.010456   \n",
       "21583  0.049038 -0.014176 -0.001616 -0.001037 -0.001602 -0.001123   \n",
       "21584  0.020283 -0.006672 -0.000920 -0.000592 -0.000930 -0.000653   \n",
       "21585  0.006447 -0.002271 -0.000357 -0.000230 -0.000367 -0.000258   \n",
       "21586  0.006447 -0.002271 -0.000357 -0.000230 -0.000367 -0.000258   \n",
       "\n",
       "               1228  \n",
       "0     -8.104087e-07  \n",
       "1     -1.371190e-05  \n",
       "2     -3.992834e-07  \n",
       "3     -1.370112e-06  \n",
       "4     -8.104087e-07  \n",
       "...             ...  \n",
       "21582 -9.696665e-06  \n",
       "21583 -1.370112e-06  \n",
       "21584 -8.104087e-07  \n",
       "21585 -3.248017e-07  \n",
       "21586 -3.248017e-07  \n",
       "\n",
       "[21587 rows x 1230 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1219</th>\n",
       "      <th>1220</th>\n",
       "      <th>1221</th>\n",
       "      <th>1222</th>\n",
       "      <th>1223</th>\n",
       "      <th>1224</th>\n",
       "      <th>1225</th>\n",
       "      <th>1226</th>\n",
       "      <th>1227</th>\n",
       "      <th>1228</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.143852</td>\n",
       "      <td>0.153831</td>\n",
       "      <td>0.048903</td>\n",
       "      <td>0.064322</td>\n",
       "      <td>-0.229419</td>\n",
       "      <td>0.043788</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>0.094055</td>\n",
       "      <td>0.140471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048205</td>\n",
       "      <td>-0.031778</td>\n",
       "      <td>-0.032778</td>\n",
       "      <td>0.034161</td>\n",
       "      <td>-0.010536</td>\n",
       "      <td>-0.001311</td>\n",
       "      <td>-0.000842</td>\n",
       "      <td>-0.001311</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-1.130300e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.146270</td>\n",
       "      <td>0.138378</td>\n",
       "      <td>0.128920</td>\n",
       "      <td>0.028282</td>\n",
       "      <td>-0.109028</td>\n",
       "      <td>0.079058</td>\n",
       "      <td>0.177058</td>\n",
       "      <td>-0.158842</td>\n",
       "      <td>-0.046334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027225</td>\n",
       "      <td>0.076419</td>\n",
       "      <td>0.124939</td>\n",
       "      <td>-0.251123</td>\n",
       "      <td>-0.274224</td>\n",
       "      <td>-0.004459</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>-0.004092</td>\n",
       "      <td>-0.002850</td>\n",
       "      <td>-3.281573e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.230146</td>\n",
       "      <td>-0.079094</td>\n",
       "      <td>0.023417</td>\n",
       "      <td>0.121199</td>\n",
       "      <td>-0.219653</td>\n",
       "      <td>0.048492</td>\n",
       "      <td>0.206833</td>\n",
       "      <td>0.063211</td>\n",
       "      <td>-0.222919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.005674</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-3.248017e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30005</td>\n",
       "      <td>0.054412</td>\n",
       "      <td>-0.081932</td>\n",
       "      <td>0.119864</td>\n",
       "      <td>-0.038023</td>\n",
       "      <td>-0.085852</td>\n",
       "      <td>-0.154316</td>\n",
       "      <td>0.137080</td>\n",
       "      <td>-0.021136</td>\n",
       "      <td>-0.071088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.005674</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-3.248017e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30007</td>\n",
       "      <td>0.152365</td>\n",
       "      <td>-0.081623</td>\n",
       "      <td>0.063739</td>\n",
       "      <td>-0.004733</td>\n",
       "      <td>-0.106801</td>\n",
       "      <td>0.078758</td>\n",
       "      <td>0.253193</td>\n",
       "      <td>-0.149726</td>\n",
       "      <td>-0.278331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.005674</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-3.248017e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>49988</td>\n",
       "      <td>0.141857</td>\n",
       "      <td>0.233940</td>\n",
       "      <td>0.049368</td>\n",
       "      <td>0.078593</td>\n",
       "      <td>0.033805</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>0.033352</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>-0.004706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006920</td>\n",
       "      <td>-0.007849</td>\n",
       "      <td>-0.008815</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>-0.000520</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>-4.687525e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>49990</td>\n",
       "      <td>0.143943</td>\n",
       "      <td>-0.044727</td>\n",
       "      <td>0.045782</td>\n",
       "      <td>-0.005088</td>\n",
       "      <td>0.073647</td>\n",
       "      <td>0.091186</td>\n",
       "      <td>0.155645</td>\n",
       "      <td>-0.063254</td>\n",
       "      <td>-0.115031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020994</td>\n",
       "      <td>-0.019116</td>\n",
       "      <td>-0.020608</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-8.650704e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>49992</td>\n",
       "      <td>0.305740</td>\n",
       "      <td>-0.054143</td>\n",
       "      <td>0.175321</td>\n",
       "      <td>0.251084</td>\n",
       "      <td>0.071718</td>\n",
       "      <td>-0.188442</td>\n",
       "      <td>0.237435</td>\n",
       "      <td>0.053513</td>\n",
       "      <td>0.099264</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004137</td>\n",
       "      <td>-0.004932</td>\n",
       "      <td>-0.005600</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>-0.002243</td>\n",
       "      <td>-0.000353</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-3.211364e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>49993</td>\n",
       "      <td>0.154398</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.170772</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>-0.099263</td>\n",
       "      <td>0.089654</td>\n",
       "      <td>0.049362</td>\n",
       "      <td>0.078503</td>\n",
       "      <td>-0.195546</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.005674</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-3.248017e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>49994</td>\n",
       "      <td>0.250433</td>\n",
       "      <td>-0.146145</td>\n",
       "      <td>0.058530</td>\n",
       "      <td>0.108594</td>\n",
       "      <td>-0.006900</td>\n",
       "      <td>0.140393</td>\n",
       "      <td>0.066134</td>\n",
       "      <td>0.055796</td>\n",
       "      <td>-0.042858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.005674</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-3.248017e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 1230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       custid         0         1         2         3         4         5  \\\n",
       "0       30001  0.143852  0.153831  0.048903  0.064322 -0.229419  0.043788   \n",
       "1       30002  0.146270  0.138378  0.128920  0.028282 -0.109028  0.079058   \n",
       "2       30003  0.230146 -0.079094  0.023417  0.121199 -0.219653  0.048492   \n",
       "3       30005  0.054412 -0.081932  0.119864 -0.038023 -0.085852 -0.154316   \n",
       "4       30007  0.152365 -0.081623  0.063739 -0.004733 -0.106801  0.078758   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "14375   49988  0.141857  0.233940  0.049368  0.078593  0.033805  0.066303   \n",
       "14376   49990  0.143943 -0.044727  0.045782 -0.005088  0.073647  0.091186   \n",
       "14377   49992  0.305740 -0.054143  0.175321  0.251084  0.071718 -0.188442   \n",
       "14378   49993  0.154398  0.046210  0.170772  0.008129 -0.099263  0.089654   \n",
       "14379   49994  0.250433 -0.146145  0.058530  0.108594 -0.006900  0.140393   \n",
       "\n",
       "              6         7         8  ...      1219      1220      1221  \\\n",
       "0      0.032007  0.094055  0.140471  ... -0.048205 -0.031778 -0.032778   \n",
       "1      0.177058 -0.158842 -0.046334  ...  0.027225  0.076419  0.124939   \n",
       "2      0.206833  0.063211 -0.222919  ... -0.004198 -0.004998 -0.005674   \n",
       "3      0.137080 -0.021136 -0.071088  ... -0.004198 -0.004998 -0.005674   \n",
       "4      0.253193 -0.149726 -0.278331  ... -0.004198 -0.004998 -0.005674   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "14375  0.033352 -0.013837 -0.004706  ... -0.006920 -0.007849 -0.008815   \n",
       "14376  0.155645 -0.063254 -0.115031  ... -0.020994 -0.019116 -0.020608   \n",
       "14377  0.237435  0.053513  0.099264  ... -0.004137 -0.004932 -0.005600   \n",
       "14378  0.049362  0.078503 -0.195546  ... -0.004198 -0.004998 -0.005674   \n",
       "14379  0.066134  0.055796 -0.042858  ... -0.004198 -0.004998 -0.005674   \n",
       "\n",
       "           1222      1223      1224      1225      1226      1227  \\\n",
       "0      0.034161 -0.010536 -0.001311 -0.000842 -0.001311 -0.000920   \n",
       "1     -0.251123 -0.274224 -0.004459 -0.002834 -0.004092 -0.002850   \n",
       "2      0.006447 -0.002271 -0.000357 -0.000230 -0.000367 -0.000258   \n",
       "3      0.006447 -0.002271 -0.000357 -0.000230 -0.000367 -0.000258   \n",
       "4      0.006447 -0.002271 -0.000357 -0.000230 -0.000367 -0.000258   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "14375  0.009912 -0.003431 -0.000520 -0.000335 -0.000532 -0.000374   \n",
       "14376  0.022307 -0.007267 -0.000986 -0.000634 -0.000995 -0.000698   \n",
       "14377  0.006364 -0.002243 -0.000353 -0.000228 -0.000363 -0.000255   \n",
       "14378  0.006447 -0.002271 -0.000357 -0.000230 -0.000367 -0.000258   \n",
       "14379  0.006447 -0.002271 -0.000357 -0.000230 -0.000367 -0.000258   \n",
       "\n",
       "               1228  \n",
       "0     -1.130300e-06  \n",
       "1     -3.281573e-06  \n",
       "2     -3.248017e-07  \n",
       "3     -3.248017e-07  \n",
       "4     -3.248017e-07  \n",
       "...             ...  \n",
       "14375 -4.687525e-07  \n",
       "14376 -8.650704e-07  \n",
       "14377 -3.211364e-07  \n",
       "14378 -3.248017e-07  \n",
       "14379 -3.248017e-07  \n",
       "\n",
       "[14380 rows x 1230 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( data, data_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21587, 1230), (14380, 1230), (21587,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "data.shape, data_te.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.astype(str)\n",
    "data_te.columns = data_te.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9]+', ' ', x))\n",
    "# data_te = data_te.rename(columns = lambda x:re.sub('[^A-Za-z0-9]+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.values\n",
    "data_te2 = data_te.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = data2[:, 1:]\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17269, 1229), (4318, 1229))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr, target, test_size=0.2 , stratify = target , random_state=0)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 7.88736\ttraining's l2: 62.2104\tvalid_1's rmse: 8.39976\tvalid_1's l2: 70.556\n",
      "[200]\ttraining's rmse: 7.20253\ttraining's l2: 51.8764\tvalid_1's rmse: 8.16454\tvalid_1's l2: 66.6597\n",
      "[300]\ttraining's rmse: 6.7316\ttraining's l2: 45.3144\tvalid_1's rmse: 8.11439\tvalid_1's l2: 65.8433\n",
      "[400]\ttraining's rmse: 6.34671\ttraining's l2: 40.2807\tvalid_1's rmse: 8.10075\tvalid_1's l2: 65.6221\n",
      "[500]\ttraining's rmse: 6.0223\ttraining's l2: 36.2681\tvalid_1's rmse: 8.08733\tvalid_1's l2: 65.4049\n",
      "[600]\ttraining's rmse: 5.73272\ttraining's l2: 32.8641\tvalid_1's rmse: 8.08428\tvalid_1's l2: 65.3556\n",
      "Early stopping, best iteration is:\n",
      "[569]\ttraining's rmse: 5.8205\ttraining's l2: 33.8782\tvalid_1's rmse: 8.08311\tvalid_1's l2: 65.3367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.02, max_depth=12, n_estimators=1000,\n",
       "              num_leaves=32, silent=-1, subsample=0.8, verbose=-1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "clf = LGBMRegressor(\n",
    "        n_jobs=-1,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=32,\n",
    "        subsample=0.8,\n",
    "        max_depth=12,\n",
    "        silent=-1,\n",
    "        verbose=-1\n",
    "        )\n",
    "\n",
    "clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric = 'RMSE', \n",
    "        verbose=100, early_stopping_rounds= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection & Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = data2[:, 1:]\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21587,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15110, 1229), (6477, 1229))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr, target, test_size=0.3, stratify = target,  random_state=1000)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.063286\n",
      "0:\tlearn: 10.2834350\ttotal: 299ms\tremaining: 4m 58s\n",
      "1:\tlearn: 10.1348533\ttotal: 403ms\tremaining: 3m 21s\n",
      "2:\tlearn: 9.9966810\ttotal: 500ms\tremaining: 2m 46s\n",
      "3:\tlearn: 9.8779472\ttotal: 613ms\tremaining: 2m 32s\n",
      "4:\tlearn: 9.7718294\ttotal: 710ms\tremaining: 2m 21s\n",
      "5:\tlearn: 9.6710628\ttotal: 817ms\tremaining: 2m 15s\n",
      "6:\tlearn: 9.5638648\ttotal: 919ms\tremaining: 2m 10s\n",
      "7:\tlearn: 9.4716036\ttotal: 1.03s\tremaining: 2m 7s\n",
      "8:\tlearn: 9.3894009\ttotal: 1.13s\tremaining: 2m 3s\n",
      "9:\tlearn: 9.3130237\ttotal: 1.23s\tremaining: 2m 2s\n",
      "10:\tlearn: 9.2461221\ttotal: 1.34s\tremaining: 2m\n",
      "11:\tlearn: 9.1829406\ttotal: 1.45s\tremaining: 1m 59s\n",
      "12:\tlearn: 9.1302094\ttotal: 1.55s\tremaining: 1m 57s\n",
      "13:\tlearn: 9.0659101\ttotal: 1.66s\tremaining: 1m 56s\n",
      "14:\tlearn: 9.0150695\ttotal: 1.76s\tremaining: 1m 55s\n",
      "15:\tlearn: 8.9554764\ttotal: 1.88s\tremaining: 1m 55s\n",
      "16:\tlearn: 8.9101482\ttotal: 2.01s\tremaining: 1m 56s\n",
      "17:\tlearn: 8.8708861\ttotal: 2.12s\tremaining: 1m 55s\n",
      "18:\tlearn: 8.8315309\ttotal: 2.21s\tremaining: 1m 54s\n",
      "19:\tlearn: 8.7866369\ttotal: 2.32s\tremaining: 1m 53s\n",
      "20:\tlearn: 8.7485353\ttotal: 2.42s\tremaining: 1m 52s\n",
      "21:\tlearn: 8.7087264\ttotal: 2.53s\tremaining: 1m 52s\n",
      "22:\tlearn: 8.6768112\ttotal: 2.63s\tremaining: 1m 51s\n",
      "23:\tlearn: 8.6514733\ttotal: 2.75s\tremaining: 1m 52s\n",
      "24:\tlearn: 8.6263799\ttotal: 2.86s\tremaining: 1m 51s\n",
      "25:\tlearn: 8.5958388\ttotal: 2.98s\tremaining: 1m 51s\n",
      "26:\tlearn: 8.5738760\ttotal: 3.09s\tremaining: 1m 51s\n",
      "27:\tlearn: 8.5509365\ttotal: 3.22s\tremaining: 1m 51s\n",
      "28:\tlearn: 8.5273936\ttotal: 3.33s\tremaining: 1m 51s\n",
      "29:\tlearn: 8.5030572\ttotal: 3.45s\tremaining: 1m 51s\n",
      "30:\tlearn: 8.4822456\ttotal: 3.56s\tremaining: 1m 51s\n",
      "31:\tlearn: 8.4615046\ttotal: 3.67s\tremaining: 1m 51s\n",
      "32:\tlearn: 8.4425436\ttotal: 3.78s\tremaining: 1m 50s\n",
      "33:\tlearn: 8.4218006\ttotal: 3.89s\tremaining: 1m 50s\n",
      "34:\tlearn: 8.4059801\ttotal: 4s\tremaining: 1m 50s\n",
      "35:\tlearn: 8.3852276\ttotal: 4.12s\tremaining: 1m 50s\n",
      "36:\tlearn: 8.3663371\ttotal: 4.22s\tremaining: 1m 49s\n",
      "37:\tlearn: 8.3492943\ttotal: 4.34s\tremaining: 1m 49s\n",
      "38:\tlearn: 8.3355873\ttotal: 4.44s\tremaining: 1m 49s\n",
      "39:\tlearn: 8.3204024\ttotal: 4.56s\tremaining: 1m 49s\n",
      "40:\tlearn: 8.3076287\ttotal: 4.67s\tremaining: 1m 49s\n",
      "41:\tlearn: 8.2925267\ttotal: 4.79s\tremaining: 1m 49s\n",
      "42:\tlearn: 8.2790678\ttotal: 4.92s\tremaining: 1m 49s\n",
      "43:\tlearn: 8.2666108\ttotal: 5.06s\tremaining: 1m 49s\n",
      "44:\tlearn: 8.2571640\ttotal: 5.18s\tremaining: 1m 50s\n",
      "45:\tlearn: 8.2480187\ttotal: 5.3s\tremaining: 1m 50s\n",
      "46:\tlearn: 8.2366114\ttotal: 5.42s\tremaining: 1m 49s\n",
      "47:\tlearn: 8.2264745\ttotal: 5.54s\tremaining: 1m 49s\n",
      "48:\tlearn: 8.2165494\ttotal: 5.65s\tremaining: 1m 49s\n",
      "49:\tlearn: 8.2057405\ttotal: 5.78s\tremaining: 1m 49s\n",
      "50:\tlearn: 8.1952864\ttotal: 5.93s\tremaining: 1m 50s\n",
      "51:\tlearn: 8.1853871\ttotal: 6.05s\tremaining: 1m 50s\n",
      "52:\tlearn: 8.1763009\ttotal: 6.16s\tremaining: 1m 50s\n",
      "53:\tlearn: 8.1681421\ttotal: 6.27s\tremaining: 1m 49s\n",
      "54:\tlearn: 8.1590137\ttotal: 6.38s\tremaining: 1m 49s\n",
      "55:\tlearn: 8.1493507\ttotal: 6.49s\tremaining: 1m 49s\n",
      "56:\tlearn: 8.1418488\ttotal: 6.61s\tremaining: 1m 49s\n",
      "57:\tlearn: 8.1328429\ttotal: 6.71s\tremaining: 1m 49s\n",
      "58:\tlearn: 8.1259073\ttotal: 6.82s\tremaining: 1m 48s\n",
      "59:\tlearn: 8.1188719\ttotal: 6.93s\tremaining: 1m 48s\n",
      "60:\tlearn: 8.1111107\ttotal: 7.04s\tremaining: 1m 48s\n",
      "61:\tlearn: 8.1063580\ttotal: 7.16s\tremaining: 1m 48s\n",
      "62:\tlearn: 8.0991187\ttotal: 7.26s\tremaining: 1m 47s\n",
      "63:\tlearn: 8.0933611\ttotal: 7.37s\tremaining: 1m 47s\n",
      "64:\tlearn: 8.0874460\ttotal: 7.47s\tremaining: 1m 47s\n",
      "65:\tlearn: 8.0805056\ttotal: 7.58s\tremaining: 1m 47s\n",
      "66:\tlearn: 8.0727529\ttotal: 7.68s\tremaining: 1m 46s\n",
      "67:\tlearn: 8.0669572\ttotal: 7.79s\tremaining: 1m 46s\n",
      "68:\tlearn: 8.0614137\ttotal: 7.89s\tremaining: 1m 46s\n",
      "69:\tlearn: 8.0535772\ttotal: 8s\tremaining: 1m 46s\n",
      "70:\tlearn: 8.0477337\ttotal: 8.1s\tremaining: 1m 45s\n",
      "71:\tlearn: 8.0411362\ttotal: 8.21s\tremaining: 1m 45s\n",
      "72:\tlearn: 8.0366901\ttotal: 8.3s\tremaining: 1m 45s\n",
      "73:\tlearn: 8.0310041\ttotal: 8.41s\tremaining: 1m 45s\n",
      "74:\tlearn: 8.0255092\ttotal: 8.51s\tremaining: 1m 44s\n",
      "75:\tlearn: 8.0208003\ttotal: 8.61s\tremaining: 1m 44s\n",
      "76:\tlearn: 8.0172876\ttotal: 8.71s\tremaining: 1m 44s\n",
      "77:\tlearn: 8.0118907\ttotal: 8.81s\tremaining: 1m 44s\n",
      "78:\tlearn: 8.0047264\ttotal: 8.93s\tremaining: 1m 44s\n",
      "79:\tlearn: 7.9987656\ttotal: 9.03s\tremaining: 1m 43s\n",
      "80:\tlearn: 7.9931122\ttotal: 9.13s\tremaining: 1m 43s\n",
      "81:\tlearn: 7.9880170\ttotal: 9.25s\tremaining: 1m 43s\n",
      "82:\tlearn: 7.9839935\ttotal: 9.35s\tremaining: 1m 43s\n",
      "83:\tlearn: 7.9787549\ttotal: 9.45s\tremaining: 1m 43s\n",
      "84:\tlearn: 7.9732972\ttotal: 9.55s\tremaining: 1m 42s\n",
      "85:\tlearn: 7.9708652\ttotal: 9.66s\tremaining: 1m 42s\n",
      "86:\tlearn: 7.9675376\ttotal: 9.76s\tremaining: 1m 42s\n",
      "87:\tlearn: 7.9635074\ttotal: 9.86s\tremaining: 1m 42s\n",
      "88:\tlearn: 7.9585798\ttotal: 9.96s\tremaining: 1m 41s\n",
      "89:\tlearn: 7.9531226\ttotal: 10.1s\tremaining: 1m 41s\n",
      "90:\tlearn: 7.9495177\ttotal: 10.2s\tremaining: 1m 41s\n",
      "91:\tlearn: 7.9446487\ttotal: 10.3s\tremaining: 1m 41s\n",
      "92:\tlearn: 7.9408021\ttotal: 10.4s\tremaining: 1m 41s\n",
      "93:\tlearn: 7.9362716\ttotal: 10.5s\tremaining: 1m 41s\n",
      "94:\tlearn: 7.9314161\ttotal: 10.6s\tremaining: 1m 40s\n",
      "95:\tlearn: 7.9272488\ttotal: 10.7s\tremaining: 1m 40s\n",
      "96:\tlearn: 7.9236698\ttotal: 10.8s\tremaining: 1m 40s\n",
      "97:\tlearn: 7.9198260\ttotal: 10.9s\tremaining: 1m 40s\n",
      "98:\tlearn: 7.9161633\ttotal: 11s\tremaining: 1m 40s\n",
      "99:\tlearn: 7.9122115\ttotal: 11.1s\tremaining: 1m 40s\n",
      "100:\tlearn: 7.9078792\ttotal: 11.3s\tremaining: 1m 40s\n",
      "101:\tlearn: 7.9045887\ttotal: 11.4s\tremaining: 1m 40s\n",
      "102:\tlearn: 7.9001604\ttotal: 11.5s\tremaining: 1m 40s\n",
      "103:\tlearn: 7.8951456\ttotal: 11.6s\tremaining: 1m 40s\n",
      "104:\tlearn: 7.8916059\ttotal: 11.7s\tremaining: 1m 40s\n",
      "105:\tlearn: 7.8891282\ttotal: 11.9s\tremaining: 1m 39s\n",
      "106:\tlearn: 7.8859218\ttotal: 12s\tremaining: 1m 39s\n",
      "107:\tlearn: 7.8808717\ttotal: 12.1s\tremaining: 1m 39s\n",
      "108:\tlearn: 7.8759226\ttotal: 12.2s\tremaining: 1m 39s\n",
      "109:\tlearn: 7.8723775\ttotal: 12.3s\tremaining: 1m 39s\n",
      "110:\tlearn: 7.8682416\ttotal: 12.4s\tremaining: 1m 39s\n",
      "111:\tlearn: 7.8655776\ttotal: 12.5s\tremaining: 1m 39s\n",
      "112:\tlearn: 7.8613372\ttotal: 12.6s\tremaining: 1m 39s\n",
      "113:\tlearn: 7.8583758\ttotal: 12.7s\tremaining: 1m 38s\n",
      "114:\tlearn: 7.8541835\ttotal: 12.8s\tremaining: 1m 38s\n",
      "115:\tlearn: 7.8512068\ttotal: 13s\tremaining: 1m 38s\n",
      "116:\tlearn: 7.8468759\ttotal: 13.1s\tremaining: 1m 38s\n",
      "117:\tlearn: 7.8427471\ttotal: 13.2s\tremaining: 1m 38s\n",
      "118:\tlearn: 7.8381551\ttotal: 13.3s\tremaining: 1m 38s\n",
      "119:\tlearn: 7.8351659\ttotal: 13.4s\tremaining: 1m 38s\n",
      "120:\tlearn: 7.8315443\ttotal: 13.6s\tremaining: 1m 38s\n",
      "121:\tlearn: 7.8282927\ttotal: 13.7s\tremaining: 1m 38s\n",
      "122:\tlearn: 7.8261406\ttotal: 13.8s\tremaining: 1m 38s\n",
      "123:\tlearn: 7.8231487\ttotal: 13.9s\tremaining: 1m 38s\n",
      "124:\tlearn: 7.8193887\ttotal: 14s\tremaining: 1m 38s\n",
      "125:\tlearn: 7.8152060\ttotal: 14.1s\tremaining: 1m 38s\n",
      "126:\tlearn: 7.8109072\ttotal: 14.2s\tremaining: 1m 37s\n",
      "127:\tlearn: 7.8082100\ttotal: 14.3s\tremaining: 1m 37s\n",
      "128:\tlearn: 7.8058542\ttotal: 14.4s\tremaining: 1m 37s\n",
      "129:\tlearn: 7.8025855\ttotal: 14.6s\tremaining: 1m 37s\n",
      "130:\tlearn: 7.8004440\ttotal: 14.7s\tremaining: 1m 37s\n",
      "131:\tlearn: 7.7957417\ttotal: 14.8s\tremaining: 1m 37s\n",
      "132:\tlearn: 7.7923361\ttotal: 14.9s\tremaining: 1m 36s\n",
      "133:\tlearn: 7.7883735\ttotal: 15s\tremaining: 1m 36s\n",
      "134:\tlearn: 7.7853756\ttotal: 15.1s\tremaining: 1m 36s\n",
      "135:\tlearn: 7.7821061\ttotal: 15.2s\tremaining: 1m 36s\n",
      "136:\tlearn: 7.7772279\ttotal: 15.3s\tremaining: 1m 36s\n",
      "137:\tlearn: 7.7719924\ttotal: 15.4s\tremaining: 1m 36s\n",
      "138:\tlearn: 7.7680870\ttotal: 15.5s\tremaining: 1m 35s\n",
      "139:\tlearn: 7.7639956\ttotal: 15.6s\tremaining: 1m 35s\n",
      "140:\tlearn: 7.7608710\ttotal: 15.7s\tremaining: 1m 35s\n",
      "141:\tlearn: 7.7570006\ttotal: 15.9s\tremaining: 1m 35s\n",
      "142:\tlearn: 7.7542325\ttotal: 16s\tremaining: 1m 35s\n",
      "143:\tlearn: 7.7506794\ttotal: 16.1s\tremaining: 1m 35s\n",
      "144:\tlearn: 7.7468938\ttotal: 16.2s\tremaining: 1m 35s\n",
      "145:\tlearn: 7.7422866\ttotal: 16.3s\tremaining: 1m 35s\n",
      "146:\tlearn: 7.7388292\ttotal: 16.4s\tremaining: 1m 34s\n",
      "147:\tlearn: 7.7344766\ttotal: 16.5s\tremaining: 1m 34s\n",
      "148:\tlearn: 7.7271156\ttotal: 16.6s\tremaining: 1m 34s\n",
      "149:\tlearn: 7.7239247\ttotal: 16.7s\tremaining: 1m 34s\n",
      "150:\tlearn: 7.7194736\ttotal: 16.8s\tremaining: 1m 34s\n",
      "151:\tlearn: 7.7145742\ttotal: 16.9s\tremaining: 1m 34s\n",
      "152:\tlearn: 7.7084856\ttotal: 17s\tremaining: 1m 33s\n",
      "153:\tlearn: 7.7052483\ttotal: 17.1s\tremaining: 1m 33s\n",
      "154:\tlearn: 7.7023746\ttotal: 17.2s\tremaining: 1m 33s\n",
      "155:\tlearn: 7.6981266\ttotal: 17.3s\tremaining: 1m 33s\n",
      "156:\tlearn: 7.6956023\ttotal: 17.3s\tremaining: 1m 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157:\tlearn: 7.6896942\ttotal: 17.4s\tremaining: 1m 32s\n",
      "158:\tlearn: 7.6849607\ttotal: 17.5s\tremaining: 1m 32s\n",
      "159:\tlearn: 7.6794584\ttotal: 17.7s\tremaining: 1m 32s\n",
      "160:\tlearn: 7.6761424\ttotal: 17.7s\tremaining: 1m 32s\n",
      "161:\tlearn: 7.6711424\ttotal: 17.9s\tremaining: 1m 32s\n",
      "162:\tlearn: 7.6665272\ttotal: 17.9s\tremaining: 1m 32s\n",
      "163:\tlearn: 7.6615237\ttotal: 18s\tremaining: 1m 32s\n",
      "164:\tlearn: 7.6587285\ttotal: 18.1s\tremaining: 1m 31s\n",
      "165:\tlearn: 7.6528502\ttotal: 18.3s\tremaining: 1m 31s\n",
      "166:\tlearn: 7.6499831\ttotal: 18.4s\tremaining: 1m 31s\n",
      "167:\tlearn: 7.6443897\ttotal: 18.5s\tremaining: 1m 31s\n",
      "168:\tlearn: 7.6414841\ttotal: 18.6s\tremaining: 1m 31s\n",
      "169:\tlearn: 7.6367091\ttotal: 18.7s\tremaining: 1m 31s\n",
      "170:\tlearn: 7.6304209\ttotal: 18.8s\tremaining: 1m 30s\n",
      "171:\tlearn: 7.6273847\ttotal: 18.9s\tremaining: 1m 30s\n",
      "172:\tlearn: 7.6241539\ttotal: 19s\tremaining: 1m 30s\n",
      "173:\tlearn: 7.6211587\ttotal: 19.1s\tremaining: 1m 30s\n",
      "174:\tlearn: 7.6150352\ttotal: 19.2s\tremaining: 1m 30s\n",
      "175:\tlearn: 7.6119886\ttotal: 19.3s\tremaining: 1m 30s\n",
      "176:\tlearn: 7.6074882\ttotal: 19.4s\tremaining: 1m 30s\n",
      "177:\tlearn: 7.6009728\ttotal: 19.5s\tremaining: 1m 30s\n",
      "178:\tlearn: 7.5976111\ttotal: 19.6s\tremaining: 1m 29s\n",
      "179:\tlearn: 7.5927652\ttotal: 19.7s\tremaining: 1m 29s\n",
      "180:\tlearn: 7.5875461\ttotal: 19.8s\tremaining: 1m 29s\n",
      "181:\tlearn: 7.5826996\ttotal: 20s\tremaining: 1m 29s\n",
      "182:\tlearn: 7.5785531\ttotal: 20.1s\tremaining: 1m 29s\n",
      "183:\tlearn: 7.5722380\ttotal: 20.2s\tremaining: 1m 29s\n",
      "184:\tlearn: 7.5696541\ttotal: 20.3s\tremaining: 1m 29s\n",
      "185:\tlearn: 7.5670894\ttotal: 20.4s\tremaining: 1m 29s\n",
      "186:\tlearn: 7.5620747\ttotal: 20.5s\tremaining: 1m 29s\n",
      "187:\tlearn: 7.5567172\ttotal: 20.6s\tremaining: 1m 29s\n",
      "188:\tlearn: 7.5529896\ttotal: 20.7s\tremaining: 1m 28s\n",
      "189:\tlearn: 7.5480680\ttotal: 20.8s\tremaining: 1m 28s\n",
      "190:\tlearn: 7.5438253\ttotal: 20.9s\tremaining: 1m 28s\n",
      "191:\tlearn: 7.5403150\ttotal: 21s\tremaining: 1m 28s\n",
      "192:\tlearn: 7.5367893\ttotal: 21.2s\tremaining: 1m 28s\n",
      "193:\tlearn: 7.5314908\ttotal: 21.3s\tremaining: 1m 28s\n",
      "194:\tlearn: 7.5267895\ttotal: 21.4s\tremaining: 1m 28s\n",
      "195:\tlearn: 7.5233526\ttotal: 21.5s\tremaining: 1m 28s\n",
      "196:\tlearn: 7.5197301\ttotal: 21.6s\tremaining: 1m 28s\n",
      "197:\tlearn: 7.5147334\ttotal: 21.7s\tremaining: 1m 27s\n",
      "198:\tlearn: 7.5115600\ttotal: 21.8s\tremaining: 1m 27s\n",
      "199:\tlearn: 7.5092516\ttotal: 21.9s\tremaining: 1m 27s\n",
      "200:\tlearn: 7.5078799\ttotal: 22s\tremaining: 1m 27s\n",
      "201:\tlearn: 7.5035820\ttotal: 22.1s\tremaining: 1m 27s\n",
      "202:\tlearn: 7.4991897\ttotal: 22.2s\tremaining: 1m 27s\n",
      "203:\tlearn: 7.4939402\ttotal: 22.3s\tremaining: 1m 27s\n",
      "204:\tlearn: 7.4901191\ttotal: 22.5s\tremaining: 1m 27s\n",
      "205:\tlearn: 7.4852646\ttotal: 22.6s\tremaining: 1m 26s\n",
      "206:\tlearn: 7.4807068\ttotal: 22.7s\tremaining: 1m 26s\n",
      "207:\tlearn: 7.4760635\ttotal: 22.8s\tremaining: 1m 26s\n",
      "208:\tlearn: 7.4716782\ttotal: 22.9s\tremaining: 1m 26s\n",
      "209:\tlearn: 7.4678615\ttotal: 23s\tremaining: 1m 26s\n",
      "210:\tlearn: 7.4640321\ttotal: 23.1s\tremaining: 1m 26s\n",
      "211:\tlearn: 7.4590561\ttotal: 23.2s\tremaining: 1m 26s\n",
      "212:\tlearn: 7.4552122\ttotal: 23.3s\tremaining: 1m 25s\n",
      "213:\tlearn: 7.4504905\ttotal: 23.4s\tremaining: 1m 25s\n",
      "214:\tlearn: 7.4460665\ttotal: 23.5s\tremaining: 1m 25s\n",
      "215:\tlearn: 7.4418750\ttotal: 23.6s\tremaining: 1m 25s\n",
      "216:\tlearn: 7.4385535\ttotal: 23.7s\tremaining: 1m 25s\n",
      "217:\tlearn: 7.4355081\ttotal: 23.8s\tremaining: 1m 25s\n",
      "218:\tlearn: 7.4326172\ttotal: 23.9s\tremaining: 1m 25s\n",
      "219:\tlearn: 7.4270634\ttotal: 24s\tremaining: 1m 24s\n",
      "220:\tlearn: 7.4229444\ttotal: 24.1s\tremaining: 1m 24s\n",
      "221:\tlearn: 7.4188513\ttotal: 24.2s\tremaining: 1m 24s\n",
      "222:\tlearn: 7.4134998\ttotal: 24.3s\tremaining: 1m 24s\n",
      "223:\tlearn: 7.4085053\ttotal: 24.4s\tremaining: 1m 24s\n",
      "224:\tlearn: 7.4039871\ttotal: 24.5s\tremaining: 1m 24s\n",
      "225:\tlearn: 7.4020950\ttotal: 24.6s\tremaining: 1m 24s\n",
      "226:\tlearn: 7.3967314\ttotal: 24.7s\tremaining: 1m 24s\n",
      "227:\tlearn: 7.3931992\ttotal: 24.8s\tremaining: 1m 23s\n",
      "228:\tlearn: 7.3902183\ttotal: 24.9s\tremaining: 1m 23s\n",
      "229:\tlearn: 7.3857067\ttotal: 25s\tremaining: 1m 23s\n",
      "230:\tlearn: 7.3817449\ttotal: 25.1s\tremaining: 1m 23s\n",
      "231:\tlearn: 7.3787800\ttotal: 25.2s\tremaining: 1m 23s\n",
      "232:\tlearn: 7.3752263\ttotal: 25.3s\tremaining: 1m 23s\n",
      "233:\tlearn: 7.3714206\ttotal: 25.4s\tremaining: 1m 23s\n",
      "234:\tlearn: 7.3691685\ttotal: 25.5s\tremaining: 1m 22s\n",
      "235:\tlearn: 7.3638225\ttotal: 25.6s\tremaining: 1m 22s\n",
      "236:\tlearn: 7.3607503\ttotal: 25.7s\tremaining: 1m 22s\n",
      "237:\tlearn: 7.3553435\ttotal: 25.8s\tremaining: 1m 22s\n",
      "238:\tlearn: 7.3524637\ttotal: 25.9s\tremaining: 1m 22s\n",
      "239:\tlearn: 7.3477916\ttotal: 26s\tremaining: 1m 22s\n",
      "240:\tlearn: 7.3427883\ttotal: 26.1s\tremaining: 1m 22s\n",
      "241:\tlearn: 7.3390416\ttotal: 26.2s\tremaining: 1m 22s\n",
      "242:\tlearn: 7.3337685\ttotal: 26.3s\tremaining: 1m 22s\n",
      "243:\tlearn: 7.3299031\ttotal: 26.4s\tremaining: 1m 21s\n",
      "244:\tlearn: 7.3262922\ttotal: 26.5s\tremaining: 1m 21s\n",
      "245:\tlearn: 7.3226663\ttotal: 26.6s\tremaining: 1m 21s\n",
      "246:\tlearn: 7.3163507\ttotal: 26.7s\tremaining: 1m 21s\n",
      "247:\tlearn: 7.3122077\ttotal: 26.9s\tremaining: 1m 21s\n",
      "248:\tlearn: 7.3093804\ttotal: 27s\tremaining: 1m 21s\n",
      "249:\tlearn: 7.3067638\ttotal: 27.1s\tremaining: 1m 21s\n",
      "250:\tlearn: 7.3013001\ttotal: 27.2s\tremaining: 1m 21s\n",
      "251:\tlearn: 7.2966363\ttotal: 27.3s\tremaining: 1m 21s\n",
      "252:\tlearn: 7.2922786\ttotal: 27.4s\tremaining: 1m 20s\n",
      "253:\tlearn: 7.2896826\ttotal: 27.5s\tremaining: 1m 20s\n",
      "254:\tlearn: 7.2859599\ttotal: 27.7s\tremaining: 1m 20s\n",
      "255:\tlearn: 7.2816286\ttotal: 27.8s\tremaining: 1m 20s\n",
      "256:\tlearn: 7.2783801\ttotal: 27.9s\tremaining: 1m 20s\n",
      "257:\tlearn: 7.2749410\ttotal: 28.1s\tremaining: 1m 20s\n",
      "258:\tlearn: 7.2727097\ttotal: 28.2s\tremaining: 1m 20s\n",
      "259:\tlearn: 7.2672993\ttotal: 28.3s\tremaining: 1m 20s\n",
      "260:\tlearn: 7.2624096\ttotal: 28.4s\tremaining: 1m 20s\n",
      "261:\tlearn: 7.2579101\ttotal: 28.6s\tremaining: 1m 20s\n",
      "262:\tlearn: 7.2537335\ttotal: 28.7s\tremaining: 1m 20s\n",
      "263:\tlearn: 7.2509624\ttotal: 28.8s\tremaining: 1m 20s\n",
      "264:\tlearn: 7.2455546\ttotal: 28.9s\tremaining: 1m 20s\n",
      "265:\tlearn: 7.2413165\ttotal: 29.1s\tremaining: 1m 20s\n",
      "266:\tlearn: 7.2389761\ttotal: 29.2s\tremaining: 1m 20s\n",
      "267:\tlearn: 7.2354766\ttotal: 29.3s\tremaining: 1m 19s\n",
      "268:\tlearn: 7.2324665\ttotal: 29.4s\tremaining: 1m 19s\n",
      "269:\tlearn: 7.2285469\ttotal: 29.5s\tremaining: 1m 19s\n",
      "270:\tlearn: 7.2243811\ttotal: 29.6s\tremaining: 1m 19s\n",
      "271:\tlearn: 7.2211800\ttotal: 29.7s\tremaining: 1m 19s\n",
      "272:\tlearn: 7.2181075\ttotal: 29.8s\tremaining: 1m 19s\n",
      "273:\tlearn: 7.2136002\ttotal: 29.9s\tremaining: 1m 19s\n",
      "274:\tlearn: 7.2097714\ttotal: 30.1s\tremaining: 1m 19s\n",
      "275:\tlearn: 7.2065402\ttotal: 30.2s\tremaining: 1m 19s\n",
      "276:\tlearn: 7.2039850\ttotal: 30.3s\tremaining: 1m 18s\n",
      "277:\tlearn: 7.2008176\ttotal: 30.4s\tremaining: 1m 18s\n",
      "278:\tlearn: 7.1974381\ttotal: 30.5s\tremaining: 1m 18s\n",
      "279:\tlearn: 7.1922010\ttotal: 30.6s\tremaining: 1m 18s\n",
      "280:\tlearn: 7.1907853\ttotal: 30.7s\tremaining: 1m 18s\n",
      "281:\tlearn: 7.1865647\ttotal: 30.8s\tremaining: 1m 18s\n",
      "282:\tlearn: 7.1833799\ttotal: 30.9s\tremaining: 1m 18s\n",
      "283:\tlearn: 7.1828132\ttotal: 30.9s\tremaining: 1m 18s\n",
      "284:\tlearn: 7.1785117\ttotal: 31.1s\tremaining: 1m 17s\n",
      "285:\tlearn: 7.1739718\ttotal: 31.1s\tremaining: 1m 17s\n",
      "286:\tlearn: 7.1708193\ttotal: 31.3s\tremaining: 1m 17s\n",
      "287:\tlearn: 7.1673059\ttotal: 31.4s\tremaining: 1m 17s\n",
      "288:\tlearn: 7.1647092\ttotal: 31.5s\tremaining: 1m 17s\n",
      "289:\tlearn: 7.1600074\ttotal: 31.5s\tremaining: 1m 17s\n",
      "290:\tlearn: 7.1557067\ttotal: 31.7s\tremaining: 1m 17s\n",
      "291:\tlearn: 7.1540440\ttotal: 31.7s\tremaining: 1m 16s\n",
      "292:\tlearn: 7.1496786\ttotal: 31.8s\tremaining: 1m 16s\n",
      "293:\tlearn: 7.1476379\ttotal: 31.9s\tremaining: 1m 16s\n",
      "294:\tlearn: 7.1445395\ttotal: 32s\tremaining: 1m 16s\n",
      "295:\tlearn: 7.1413197\ttotal: 32.1s\tremaining: 1m 16s\n",
      "296:\tlearn: 7.1379079\ttotal: 32.3s\tremaining: 1m 16s\n",
      "297:\tlearn: 7.1336652\ttotal: 32.4s\tremaining: 1m 16s\n",
      "298:\tlearn: 7.1294220\ttotal: 32.5s\tremaining: 1m 16s\n",
      "299:\tlearn: 7.1256809\ttotal: 32.6s\tremaining: 1m 16s\n",
      "300:\tlearn: 7.1222228\ttotal: 32.7s\tremaining: 1m 16s\n",
      "301:\tlearn: 7.1184276\ttotal: 32.8s\tremaining: 1m 15s\n",
      "302:\tlearn: 7.1161188\ttotal: 32.9s\tremaining: 1m 15s\n",
      "303:\tlearn: 7.1118557\ttotal: 33.1s\tremaining: 1m 15s\n",
      "304:\tlearn: 7.1086472\ttotal: 33.2s\tremaining: 1m 15s\n",
      "305:\tlearn: 7.1042989\ttotal: 33.3s\tremaining: 1m 15s\n",
      "306:\tlearn: 7.1018030\ttotal: 33.4s\tremaining: 1m 15s\n",
      "307:\tlearn: 7.1000868\ttotal: 33.5s\tremaining: 1m 15s\n",
      "308:\tlearn: 7.0954999\ttotal: 33.6s\tremaining: 1m 15s\n",
      "309:\tlearn: 7.0910652\ttotal: 33.7s\tremaining: 1m 15s\n",
      "310:\tlearn: 7.0877185\ttotal: 33.9s\tremaining: 1m 15s\n",
      "311:\tlearn: 7.0832687\ttotal: 34s\tremaining: 1m 14s\n",
      "312:\tlearn: 7.0803185\ttotal: 34.1s\tremaining: 1m 14s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313:\tlearn: 7.0768129\ttotal: 34.2s\tremaining: 1m 14s\n",
      "314:\tlearn: 7.0737538\ttotal: 34.3s\tremaining: 1m 14s\n",
      "315:\tlearn: 7.0706796\ttotal: 34.5s\tremaining: 1m 14s\n",
      "316:\tlearn: 7.0659725\ttotal: 34.6s\tremaining: 1m 14s\n",
      "317:\tlearn: 7.0627242\ttotal: 34.7s\tremaining: 1m 14s\n",
      "318:\tlearn: 7.0592783\ttotal: 34.8s\tremaining: 1m 14s\n",
      "319:\tlearn: 7.0541558\ttotal: 35s\tremaining: 1m 14s\n",
      "320:\tlearn: 7.0514997\ttotal: 35.1s\tremaining: 1m 14s\n",
      "321:\tlearn: 7.0470272\ttotal: 35.2s\tremaining: 1m 14s\n",
      "322:\tlearn: 7.0435527\ttotal: 35.3s\tremaining: 1m 14s\n",
      "323:\tlearn: 7.0397808\ttotal: 35.4s\tremaining: 1m 13s\n",
      "324:\tlearn: 7.0343581\ttotal: 35.6s\tremaining: 1m 13s\n",
      "325:\tlearn: 7.0315952\ttotal: 35.7s\tremaining: 1m 13s\n",
      "326:\tlearn: 7.0311512\ttotal: 35.8s\tremaining: 1m 13s\n",
      "327:\tlearn: 7.0276566\ttotal: 35.9s\tremaining: 1m 13s\n",
      "328:\tlearn: 7.0254577\ttotal: 36s\tremaining: 1m 13s\n",
      "329:\tlearn: 7.0218990\ttotal: 36.2s\tremaining: 1m 13s\n",
      "330:\tlearn: 7.0188452\ttotal: 36.3s\tremaining: 1m 13s\n",
      "331:\tlearn: 7.0161639\ttotal: 36.4s\tremaining: 1m 13s\n",
      "332:\tlearn: 7.0122862\ttotal: 36.5s\tremaining: 1m 13s\n",
      "333:\tlearn: 7.0094497\ttotal: 36.6s\tremaining: 1m 13s\n",
      "334:\tlearn: 7.0062800\ttotal: 36.8s\tremaining: 1m 13s\n",
      "335:\tlearn: 7.0032276\ttotal: 36.9s\tremaining: 1m 12s\n",
      "336:\tlearn: 6.9992937\ttotal: 37s\tremaining: 1m 12s\n",
      "337:\tlearn: 6.9973004\ttotal: 37.1s\tremaining: 1m 12s\n",
      "338:\tlearn: 6.9948036\ttotal: 37.2s\tremaining: 1m 12s\n",
      "339:\tlearn: 6.9910293\ttotal: 37.4s\tremaining: 1m 12s\n",
      "340:\tlearn: 6.9882416\ttotal: 37.5s\tremaining: 1m 12s\n",
      "341:\tlearn: 6.9857573\ttotal: 37.6s\tremaining: 1m 12s\n",
      "342:\tlearn: 6.9824773\ttotal: 37.7s\tremaining: 1m 12s\n",
      "343:\tlearn: 6.9815326\ttotal: 37.8s\tremaining: 1m 12s\n",
      "344:\tlearn: 6.9777724\ttotal: 37.9s\tremaining: 1m 11s\n",
      "345:\tlearn: 6.9752514\ttotal: 38s\tremaining: 1m 11s\n",
      "346:\tlearn: 6.9719588\ttotal: 38.1s\tremaining: 1m 11s\n",
      "347:\tlearn: 6.9686137\ttotal: 38.2s\tremaining: 1m 11s\n",
      "348:\tlearn: 6.9657789\ttotal: 38.3s\tremaining: 1m 11s\n",
      "349:\tlearn: 6.9628395\ttotal: 38.4s\tremaining: 1m 11s\n",
      "350:\tlearn: 6.9587989\ttotal: 38.6s\tremaining: 1m 11s\n",
      "351:\tlearn: 6.9562360\ttotal: 38.7s\tremaining: 1m 11s\n",
      "352:\tlearn: 6.9514595\ttotal: 38.8s\tremaining: 1m 11s\n",
      "353:\tlearn: 6.9488105\ttotal: 38.9s\tremaining: 1m 10s\n",
      "354:\tlearn: 6.9446080\ttotal: 39s\tremaining: 1m 10s\n",
      "355:\tlearn: 6.9418743\ttotal: 39.1s\tremaining: 1m 10s\n",
      "356:\tlearn: 6.9414529\ttotal: 39.2s\tremaining: 1m 10s\n",
      "357:\tlearn: 6.9364824\ttotal: 39.4s\tremaining: 1m 10s\n",
      "358:\tlearn: 6.9317197\ttotal: 39.5s\tremaining: 1m 10s\n",
      "359:\tlearn: 6.9268721\ttotal: 39.6s\tremaining: 1m 10s\n",
      "360:\tlearn: 6.9231491\ttotal: 39.7s\tremaining: 1m 10s\n",
      "361:\tlearn: 6.9194846\ttotal: 39.8s\tremaining: 1m 10s\n",
      "362:\tlearn: 6.9157164\ttotal: 39.9s\tremaining: 1m 10s\n",
      "363:\tlearn: 6.9128015\ttotal: 40s\tremaining: 1m 9s\n",
      "364:\tlearn: 6.9104491\ttotal: 40.1s\tremaining: 1m 9s\n",
      "365:\tlearn: 6.9087526\ttotal: 40.2s\tremaining: 1m 9s\n",
      "366:\tlearn: 6.9058677\ttotal: 40.4s\tremaining: 1m 9s\n",
      "367:\tlearn: 6.9021791\ttotal: 40.5s\tremaining: 1m 9s\n",
      "368:\tlearn: 6.8992710\ttotal: 40.6s\tremaining: 1m 9s\n",
      "369:\tlearn: 6.8955499\ttotal: 40.7s\tremaining: 1m 9s\n",
      "370:\tlearn: 6.8927998\ttotal: 40.9s\tremaining: 1m 9s\n",
      "371:\tlearn: 6.8894488\ttotal: 41s\tremaining: 1m 9s\n",
      "372:\tlearn: 6.8847095\ttotal: 41.1s\tremaining: 1m 9s\n",
      "373:\tlearn: 6.8818926\ttotal: 41.2s\tremaining: 1m 9s\n",
      "374:\tlearn: 6.8786733\ttotal: 41.4s\tremaining: 1m 8s\n",
      "375:\tlearn: 6.8739525\ttotal: 41.5s\tremaining: 1m 8s\n",
      "376:\tlearn: 6.8711359\ttotal: 41.6s\tremaining: 1m 8s\n",
      "377:\tlearn: 6.8693880\ttotal: 41.7s\tremaining: 1m 8s\n",
      "378:\tlearn: 6.8671853\ttotal: 41.8s\tremaining: 1m 8s\n",
      "379:\tlearn: 6.8638462\ttotal: 42s\tremaining: 1m 8s\n",
      "380:\tlearn: 6.8603183\ttotal: 42.1s\tremaining: 1m 8s\n",
      "381:\tlearn: 6.8577260\ttotal: 42.2s\tremaining: 1m 8s\n",
      "382:\tlearn: 6.8540950\ttotal: 42.4s\tremaining: 1m 8s\n",
      "383:\tlearn: 6.8504943\ttotal: 42.5s\tremaining: 1m 8s\n",
      "384:\tlearn: 6.8474976\ttotal: 42.6s\tremaining: 1m 8s\n",
      "385:\tlearn: 6.8451014\ttotal: 42.7s\tremaining: 1m 7s\n",
      "386:\tlearn: 6.8402981\ttotal: 42.9s\tremaining: 1m 7s\n",
      "387:\tlearn: 6.8399426\ttotal: 43s\tremaining: 1m 7s\n",
      "388:\tlearn: 6.8348613\ttotal: 43.1s\tremaining: 1m 7s\n",
      "389:\tlearn: 6.8307040\ttotal: 43.2s\tremaining: 1m 7s\n",
      "390:\tlearn: 6.8275927\ttotal: 43.3s\tremaining: 1m 7s\n",
      "391:\tlearn: 6.8229852\ttotal: 43.5s\tremaining: 1m 7s\n",
      "392:\tlearn: 6.8199325\ttotal: 43.6s\tremaining: 1m 7s\n",
      "393:\tlearn: 6.8158391\ttotal: 43.8s\tremaining: 1m 7s\n",
      "394:\tlearn: 6.8127026\ttotal: 43.9s\tremaining: 1m 7s\n",
      "395:\tlearn: 6.8080486\ttotal: 44s\tremaining: 1m 7s\n",
      "396:\tlearn: 6.8047456\ttotal: 44.1s\tremaining: 1m 6s\n",
      "397:\tlearn: 6.8027888\ttotal: 44.2s\tremaining: 1m 6s\n",
      "398:\tlearn: 6.7986374\ttotal: 44.3s\tremaining: 1m 6s\n",
      "399:\tlearn: 6.7934127\ttotal: 44.5s\tremaining: 1m 6s\n",
      "400:\tlearn: 6.7879981\ttotal: 44.6s\tremaining: 1m 6s\n",
      "401:\tlearn: 6.7848301\ttotal: 44.7s\tremaining: 1m 6s\n",
      "402:\tlearn: 6.7819035\ttotal: 44.8s\tremaining: 1m 6s\n",
      "403:\tlearn: 6.7804123\ttotal: 44.9s\tremaining: 1m 6s\n",
      "404:\tlearn: 6.7771286\ttotal: 45s\tremaining: 1m 6s\n",
      "405:\tlearn: 6.7759013\ttotal: 45.1s\tremaining: 1m 6s\n",
      "406:\tlearn: 6.7720077\ttotal: 45.2s\tremaining: 1m 5s\n",
      "407:\tlearn: 6.7677436\ttotal: 45.3s\tremaining: 1m 5s\n",
      "408:\tlearn: 6.7655531\ttotal: 45.5s\tremaining: 1m 5s\n",
      "409:\tlearn: 6.7637695\ttotal: 45.6s\tremaining: 1m 5s\n",
      "410:\tlearn: 6.7599135\ttotal: 45.7s\tremaining: 1m 5s\n",
      "411:\tlearn: 6.7556849\ttotal: 45.8s\tremaining: 1m 5s\n",
      "412:\tlearn: 6.7523007\ttotal: 45.9s\tremaining: 1m 5s\n",
      "413:\tlearn: 6.7472528\ttotal: 46s\tremaining: 1m 5s\n",
      "414:\tlearn: 6.7445544\ttotal: 46.1s\tremaining: 1m 5s\n",
      "415:\tlearn: 6.7403782\ttotal: 46.2s\tremaining: 1m 4s\n",
      "416:\tlearn: 6.7363327\ttotal: 46.4s\tremaining: 1m 4s\n",
      "417:\tlearn: 6.7326183\ttotal: 46.5s\tremaining: 1m 4s\n",
      "418:\tlearn: 6.7289712\ttotal: 46.6s\tremaining: 1m 4s\n",
      "419:\tlearn: 6.7261249\ttotal: 46.7s\tremaining: 1m 4s\n",
      "420:\tlearn: 6.7217683\ttotal: 46.8s\tremaining: 1m 4s\n",
      "421:\tlearn: 6.7184956\ttotal: 46.9s\tremaining: 1m 4s\n",
      "422:\tlearn: 6.7144353\ttotal: 47s\tremaining: 1m 4s\n",
      "423:\tlearn: 6.7107190\ttotal: 47.1s\tremaining: 1m 3s\n",
      "424:\tlearn: 6.7070569\ttotal: 47.2s\tremaining: 1m 3s\n",
      "425:\tlearn: 6.7042251\ttotal: 47.3s\tremaining: 1m 3s\n",
      "426:\tlearn: 6.7016918\ttotal: 47.4s\tremaining: 1m 3s\n",
      "427:\tlearn: 6.6989070\ttotal: 47.5s\tremaining: 1m 3s\n",
      "428:\tlearn: 6.6967087\ttotal: 47.6s\tremaining: 1m 3s\n",
      "429:\tlearn: 6.6937668\ttotal: 47.7s\tremaining: 1m 3s\n",
      "430:\tlearn: 6.6906615\ttotal: 47.8s\tremaining: 1m 3s\n",
      "431:\tlearn: 6.6879421\ttotal: 47.9s\tremaining: 1m 2s\n",
      "432:\tlearn: 6.6852149\ttotal: 48s\tremaining: 1m 2s\n",
      "433:\tlearn: 6.6809254\ttotal: 48.1s\tremaining: 1m 2s\n",
      "434:\tlearn: 6.6785077\ttotal: 48.2s\tremaining: 1m 2s\n",
      "435:\tlearn: 6.6754494\ttotal: 48.3s\tremaining: 1m 2s\n",
      "436:\tlearn: 6.6716090\ttotal: 48.4s\tremaining: 1m 2s\n",
      "437:\tlearn: 6.6677956\ttotal: 48.5s\tremaining: 1m 2s\n",
      "438:\tlearn: 6.6639955\ttotal: 48.6s\tremaining: 1m 2s\n",
      "439:\tlearn: 6.6604010\ttotal: 48.8s\tremaining: 1m 2s\n",
      "440:\tlearn: 6.6600861\ttotal: 48.9s\tremaining: 1m 1s\n",
      "441:\tlearn: 6.6561191\ttotal: 49s\tremaining: 1m 1s\n",
      "442:\tlearn: 6.6536878\ttotal: 49.1s\tremaining: 1m 1s\n",
      "443:\tlearn: 6.6506119\ttotal: 49.2s\tremaining: 1m 1s\n",
      "444:\tlearn: 6.6480571\ttotal: 49.3s\tremaining: 1m 1s\n",
      "445:\tlearn: 6.6448848\ttotal: 49.4s\tremaining: 1m 1s\n",
      "446:\tlearn: 6.6426007\ttotal: 49.5s\tremaining: 1m 1s\n",
      "447:\tlearn: 6.6397043\ttotal: 49.6s\tremaining: 1m 1s\n",
      "448:\tlearn: 6.6366719\ttotal: 49.7s\tremaining: 1m 1s\n",
      "449:\tlearn: 6.6325891\ttotal: 49.9s\tremaining: 1m\n",
      "450:\tlearn: 6.6281121\ttotal: 50s\tremaining: 1m\n",
      "451:\tlearn: 6.6226463\ttotal: 50.1s\tremaining: 1m\n",
      "452:\tlearn: 6.6205649\ttotal: 50.2s\tremaining: 1m\n",
      "453:\tlearn: 6.6161553\ttotal: 50.3s\tremaining: 1m\n",
      "454:\tlearn: 6.6136330\ttotal: 50.4s\tremaining: 1m\n",
      "455:\tlearn: 6.6098668\ttotal: 50.5s\tremaining: 1m\n",
      "456:\tlearn: 6.6049221\ttotal: 50.6s\tremaining: 1m\n",
      "457:\tlearn: 6.6014496\ttotal: 50.8s\tremaining: 1m\n",
      "458:\tlearn: 6.5979718\ttotal: 50.9s\tremaining: 60s\n",
      "459:\tlearn: 6.5945795\ttotal: 51s\tremaining: 59.8s\n",
      "460:\tlearn: 6.5916225\ttotal: 51.1s\tremaining: 59.7s\n",
      "461:\tlearn: 6.5879773\ttotal: 51.2s\tremaining: 59.6s\n",
      "462:\tlearn: 6.5849042\ttotal: 51.3s\tremaining: 59.5s\n",
      "463:\tlearn: 6.5813566\ttotal: 51.4s\tremaining: 59.4s\n",
      "464:\tlearn: 6.5789253\ttotal: 51.6s\tremaining: 59.3s\n",
      "465:\tlearn: 6.5753563\ttotal: 51.7s\tremaining: 59.2s\n",
      "466:\tlearn: 6.5718261\ttotal: 51.8s\tremaining: 59.2s\n",
      "467:\tlearn: 6.5691853\ttotal: 52s\tremaining: 59.1s\n",
      "468:\tlearn: 6.5653946\ttotal: 52.1s\tremaining: 59s\n",
      "469:\tlearn: 6.5651346\ttotal: 52.2s\tremaining: 58.9s\n",
      "470:\tlearn: 6.5624014\ttotal: 52.3s\tremaining: 58.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471:\tlearn: 6.5575581\ttotal: 52.4s\tremaining: 58.7s\n",
      "472:\tlearn: 6.5546268\ttotal: 52.5s\tremaining: 58.5s\n",
      "473:\tlearn: 6.5505202\ttotal: 52.7s\tremaining: 58.4s\n",
      "474:\tlearn: 6.5484766\ttotal: 52.8s\tremaining: 58.4s\n",
      "475:\tlearn: 6.5461829\ttotal: 53s\tremaining: 58.3s\n",
      "476:\tlearn: 6.5439552\ttotal: 53.1s\tremaining: 58.2s\n",
      "477:\tlearn: 6.5411479\ttotal: 53.2s\tremaining: 58.1s\n",
      "478:\tlearn: 6.5395361\ttotal: 53.3s\tremaining: 58s\n",
      "479:\tlearn: 6.5393192\ttotal: 53.4s\tremaining: 57.9s\n",
      "480:\tlearn: 6.5361827\ttotal: 53.5s\tremaining: 57.8s\n",
      "481:\tlearn: 6.5324155\ttotal: 53.6s\tremaining: 57.6s\n",
      "482:\tlearn: 6.5291225\ttotal: 53.7s\tremaining: 57.5s\n",
      "483:\tlearn: 6.5259928\ttotal: 53.9s\tremaining: 57.4s\n",
      "484:\tlearn: 6.5227413\ttotal: 54s\tremaining: 57.3s\n",
      "485:\tlearn: 6.5199859\ttotal: 54.1s\tremaining: 57.2s\n",
      "486:\tlearn: 6.5169742\ttotal: 54.2s\tremaining: 57.1s\n",
      "487:\tlearn: 6.5135376\ttotal: 54.4s\tremaining: 57.1s\n",
      "488:\tlearn: 6.5084898\ttotal: 54.5s\tremaining: 57s\n",
      "489:\tlearn: 6.5055296\ttotal: 54.7s\tremaining: 56.9s\n",
      "490:\tlearn: 6.5034687\ttotal: 54.8s\tremaining: 56.8s\n",
      "491:\tlearn: 6.5008696\ttotal: 54.9s\tremaining: 56.6s\n",
      "492:\tlearn: 6.4974069\ttotal: 55s\tremaining: 56.5s\n",
      "493:\tlearn: 6.4958094\ttotal: 55.1s\tremaining: 56.5s\n",
      "494:\tlearn: 6.4939762\ttotal: 55.2s\tremaining: 56.3s\n",
      "495:\tlearn: 6.4905436\ttotal: 55.3s\tremaining: 56.2s\n",
      "496:\tlearn: 6.4875195\ttotal: 55.5s\tremaining: 56.1s\n",
      "497:\tlearn: 6.4855149\ttotal: 55.6s\tremaining: 56s\n",
      "498:\tlearn: 6.4824830\ttotal: 55.7s\tremaining: 55.9s\n",
      "499:\tlearn: 6.4797102\ttotal: 55.8s\tremaining: 55.8s\n",
      "500:\tlearn: 6.4761365\ttotal: 55.9s\tremaining: 55.7s\n",
      "501:\tlearn: 6.4729720\ttotal: 56.1s\tremaining: 55.6s\n",
      "502:\tlearn: 6.4697843\ttotal: 56.2s\tremaining: 55.5s\n",
      "503:\tlearn: 6.4659528\ttotal: 56.3s\tremaining: 55.4s\n",
      "504:\tlearn: 6.4627067\ttotal: 56.4s\tremaining: 55.3s\n",
      "505:\tlearn: 6.4594650\ttotal: 56.5s\tremaining: 55.2s\n",
      "506:\tlearn: 6.4561480\ttotal: 56.6s\tremaining: 55.1s\n",
      "507:\tlearn: 6.4523658\ttotal: 56.7s\tremaining: 55s\n",
      "508:\tlearn: 6.4491217\ttotal: 56.9s\tremaining: 54.9s\n",
      "509:\tlearn: 6.4461116\ttotal: 57s\tremaining: 54.8s\n",
      "510:\tlearn: 6.4436212\ttotal: 57.1s\tremaining: 54.7s\n",
      "511:\tlearn: 6.4402209\ttotal: 57.2s\tremaining: 54.5s\n",
      "512:\tlearn: 6.4390583\ttotal: 57.3s\tremaining: 54.4s\n",
      "513:\tlearn: 6.4369361\ttotal: 57.4s\tremaining: 54.3s\n",
      "514:\tlearn: 6.4345065\ttotal: 57.5s\tremaining: 54.2s\n",
      "515:\tlearn: 6.4310355\ttotal: 57.6s\tremaining: 54.1s\n",
      "516:\tlearn: 6.4267863\ttotal: 57.7s\tremaining: 53.9s\n",
      "517:\tlearn: 6.4239725\ttotal: 57.9s\tremaining: 53.8s\n",
      "518:\tlearn: 6.4206236\ttotal: 58s\tremaining: 53.7s\n",
      "519:\tlearn: 6.4200927\ttotal: 58.1s\tremaining: 53.6s\n",
      "520:\tlearn: 6.4196185\ttotal: 58.2s\tremaining: 53.5s\n",
      "521:\tlearn: 6.4167247\ttotal: 58.3s\tremaining: 53.4s\n",
      "522:\tlearn: 6.4137052\ttotal: 58.4s\tremaining: 53.3s\n",
      "523:\tlearn: 6.4116858\ttotal: 58.5s\tremaining: 53.1s\n",
      "524:\tlearn: 6.4087595\ttotal: 58.6s\tremaining: 53s\n",
      "525:\tlearn: 6.4055133\ttotal: 58.7s\tremaining: 52.9s\n",
      "526:\tlearn: 6.4025938\ttotal: 58.8s\tremaining: 52.8s\n",
      "527:\tlearn: 6.4001606\ttotal: 58.9s\tremaining: 52.7s\n",
      "528:\tlearn: 6.3978281\ttotal: 59s\tremaining: 52.5s\n",
      "529:\tlearn: 6.3947956\ttotal: 59.1s\tremaining: 52.4s\n",
      "530:\tlearn: 6.3926135\ttotal: 59.2s\tremaining: 52.3s\n",
      "531:\tlearn: 6.3902721\ttotal: 59.3s\tremaining: 52.2s\n",
      "532:\tlearn: 6.3879049\ttotal: 59.4s\tremaining: 52.1s\n",
      "533:\tlearn: 6.3861536\ttotal: 59.5s\tremaining: 51.9s\n",
      "534:\tlearn: 6.3837567\ttotal: 59.6s\tremaining: 51.8s\n",
      "535:\tlearn: 6.3805966\ttotal: 59.7s\tremaining: 51.7s\n",
      "536:\tlearn: 6.3779815\ttotal: 59.8s\tremaining: 51.6s\n",
      "537:\tlearn: 6.3748516\ttotal: 59.9s\tremaining: 51.5s\n",
      "538:\tlearn: 6.3718448\ttotal: 1m\tremaining: 51.4s\n",
      "539:\tlearn: 6.3692119\ttotal: 1m\tremaining: 51.3s\n",
      "540:\tlearn: 6.3668259\ttotal: 1m\tremaining: 51.1s\n",
      "541:\tlearn: 6.3632824\ttotal: 1m\tremaining: 51s\n",
      "542:\tlearn: 6.3598848\ttotal: 1m\tremaining: 50.9s\n",
      "543:\tlearn: 6.3574283\ttotal: 1m\tremaining: 50.8s\n",
      "544:\tlearn: 6.3536447\ttotal: 1m\tremaining: 50.7s\n",
      "545:\tlearn: 6.3504405\ttotal: 1m\tremaining: 50.6s\n",
      "546:\tlearn: 6.3473193\ttotal: 1m\tremaining: 50.5s\n",
      "547:\tlearn: 6.3440359\ttotal: 1m 1s\tremaining: 50.3s\n",
      "548:\tlearn: 6.3410903\ttotal: 1m 1s\tremaining: 50.2s\n",
      "549:\tlearn: 6.3404512\ttotal: 1m 1s\tremaining: 50.1s\n",
      "550:\tlearn: 6.3375777\ttotal: 1m 1s\tremaining: 50s\n",
      "551:\tlearn: 6.3342822\ttotal: 1m 1s\tremaining: 49.9s\n",
      "552:\tlearn: 6.3298581\ttotal: 1m 1s\tremaining: 49.8s\n",
      "553:\tlearn: 6.3261754\ttotal: 1m 1s\tremaining: 49.7s\n",
      "554:\tlearn: 6.3242241\ttotal: 1m 1s\tremaining: 49.6s\n",
      "555:\tlearn: 6.3220278\ttotal: 1m 1s\tremaining: 49.4s\n",
      "556:\tlearn: 6.3187200\ttotal: 1m 2s\tremaining: 49.3s\n",
      "557:\tlearn: 6.3154526\ttotal: 1m 2s\tremaining: 49.2s\n",
      "558:\tlearn: 6.3125632\ttotal: 1m 2s\tremaining: 49.1s\n",
      "559:\tlearn: 6.3096161\ttotal: 1m 2s\tremaining: 49s\n",
      "560:\tlearn: 6.3074136\ttotal: 1m 2s\tremaining: 48.9s\n",
      "561:\tlearn: 6.3053454\ttotal: 1m 2s\tremaining: 48.7s\n",
      "562:\tlearn: 6.3024625\ttotal: 1m 2s\tremaining: 48.6s\n",
      "563:\tlearn: 6.2995789\ttotal: 1m 2s\tremaining: 48.5s\n",
      "564:\tlearn: 6.2983325\ttotal: 1m 2s\tremaining: 48.4s\n",
      "565:\tlearn: 6.2965807\ttotal: 1m 2s\tremaining: 48.3s\n",
      "566:\tlearn: 6.2932664\ttotal: 1m 3s\tremaining: 48.2s\n",
      "567:\tlearn: 6.2894972\ttotal: 1m 3s\tremaining: 48s\n",
      "568:\tlearn: 6.2859062\ttotal: 1m 3s\tremaining: 47.9s\n",
      "569:\tlearn: 6.2838309\ttotal: 1m 3s\tremaining: 47.8s\n",
      "570:\tlearn: 6.2806469\ttotal: 1m 3s\tremaining: 47.7s\n",
      "571:\tlearn: 6.2778646\ttotal: 1m 3s\tremaining: 47.6s\n",
      "572:\tlearn: 6.2743685\ttotal: 1m 3s\tremaining: 47.5s\n",
      "573:\tlearn: 6.2714251\ttotal: 1m 3s\tremaining: 47.4s\n",
      "574:\tlearn: 6.2712380\ttotal: 1m 3s\tremaining: 47.3s\n",
      "575:\tlearn: 6.2682445\ttotal: 1m 4s\tremaining: 47.1s\n",
      "576:\tlearn: 6.2668945\ttotal: 1m 4s\tremaining: 47s\n",
      "577:\tlearn: 6.2640818\ttotal: 1m 4s\tremaining: 46.9s\n",
      "578:\tlearn: 6.2604399\ttotal: 1m 4s\tremaining: 46.8s\n",
      "579:\tlearn: 6.2576606\ttotal: 1m 4s\tremaining: 46.7s\n",
      "580:\tlearn: 6.2535541\ttotal: 1m 4s\tremaining: 46.6s\n",
      "581:\tlearn: 6.2501919\ttotal: 1m 4s\tremaining: 46.5s\n",
      "582:\tlearn: 6.2460170\ttotal: 1m 4s\tremaining: 46.4s\n",
      "583:\tlearn: 6.2432007\ttotal: 1m 5s\tremaining: 46.3s\n",
      "584:\tlearn: 6.2403026\ttotal: 1m 5s\tremaining: 46.2s\n",
      "585:\tlearn: 6.2374310\ttotal: 1m 5s\tremaining: 46.1s\n",
      "586:\tlearn: 6.2343605\ttotal: 1m 5s\tremaining: 46s\n",
      "587:\tlearn: 6.2312956\ttotal: 1m 5s\tremaining: 45.9s\n",
      "588:\tlearn: 6.2286042\ttotal: 1m 5s\tremaining: 45.8s\n",
      "589:\tlearn: 6.2257967\ttotal: 1m 5s\tremaining: 45.7s\n",
      "590:\tlearn: 6.2240352\ttotal: 1m 5s\tremaining: 45.6s\n",
      "591:\tlearn: 6.2197643\ttotal: 1m 5s\tremaining: 45.5s\n",
      "592:\tlearn: 6.2166564\ttotal: 1m 6s\tremaining: 45.4s\n",
      "593:\tlearn: 6.2131698\ttotal: 1m 6s\tremaining: 45.3s\n",
      "594:\tlearn: 6.2115332\ttotal: 1m 6s\tremaining: 45.2s\n",
      "595:\tlearn: 6.2074734\ttotal: 1m 6s\tremaining: 45.1s\n",
      "596:\tlearn: 6.2047858\ttotal: 1m 6s\tremaining: 45s\n",
      "597:\tlearn: 6.2014443\ttotal: 1m 6s\tremaining: 44.9s\n",
      "598:\tlearn: 6.1988693\ttotal: 1m 6s\tremaining: 44.8s\n",
      "599:\tlearn: 6.1973583\ttotal: 1m 6s\tremaining: 44.6s\n",
      "600:\tlearn: 6.1950253\ttotal: 1m 7s\tremaining: 44.5s\n",
      "601:\tlearn: 6.1923443\ttotal: 1m 7s\tremaining: 44.4s\n",
      "602:\tlearn: 6.1920613\ttotal: 1m 7s\tremaining: 44.3s\n",
      "603:\tlearn: 6.1916459\ttotal: 1m 7s\tremaining: 44.2s\n",
      "604:\tlearn: 6.1889677\ttotal: 1m 7s\tremaining: 44.1s\n",
      "605:\tlearn: 6.1858626\ttotal: 1m 7s\tremaining: 44s\n",
      "606:\tlearn: 6.1834638\ttotal: 1m 7s\tremaining: 43.9s\n",
      "607:\tlearn: 6.1804932\ttotal: 1m 7s\tremaining: 43.8s\n",
      "608:\tlearn: 6.1773256\ttotal: 1m 8s\tremaining: 43.7s\n",
      "609:\tlearn: 6.1741427\ttotal: 1m 8s\tremaining: 43.6s\n",
      "610:\tlearn: 6.1713404\ttotal: 1m 8s\tremaining: 43.5s\n",
      "611:\tlearn: 6.1683814\ttotal: 1m 8s\tremaining: 43.4s\n",
      "612:\tlearn: 6.1651249\ttotal: 1m 8s\tremaining: 43.4s\n",
      "613:\tlearn: 6.1625668\ttotal: 1m 8s\tremaining: 43.3s\n",
      "614:\tlearn: 6.1608294\ttotal: 1m 8s\tremaining: 43.1s\n",
      "615:\tlearn: 6.1579224\ttotal: 1m 9s\tremaining: 43.1s\n",
      "616:\tlearn: 6.1534932\ttotal: 1m 9s\tremaining: 43s\n",
      "617:\tlearn: 6.1520547\ttotal: 1m 9s\tremaining: 42.8s\n",
      "618:\tlearn: 6.1491185\ttotal: 1m 9s\tremaining: 42.8s\n",
      "619:\tlearn: 6.1465616\ttotal: 1m 9s\tremaining: 42.7s\n",
      "620:\tlearn: 6.1446646\ttotal: 1m 9s\tremaining: 42.5s\n",
      "621:\tlearn: 6.1428876\ttotal: 1m 9s\tremaining: 42.5s\n",
      "622:\tlearn: 6.1404632\ttotal: 1m 9s\tremaining: 42.4s\n",
      "623:\tlearn: 6.1394743\ttotal: 1m 10s\tremaining: 42.2s\n",
      "624:\tlearn: 6.1371848\ttotal: 1m 10s\tremaining: 42.1s\n",
      "625:\tlearn: 6.1334249\ttotal: 1m 10s\tremaining: 42s\n",
      "626:\tlearn: 6.1317751\ttotal: 1m 10s\tremaining: 41.9s\n",
      "627:\tlearn: 6.1298790\ttotal: 1m 10s\tremaining: 41.9s\n",
      "628:\tlearn: 6.1268801\ttotal: 1m 10s\tremaining: 41.8s\n",
      "629:\tlearn: 6.1236792\ttotal: 1m 10s\tremaining: 41.6s\n",
      "630:\tlearn: 6.1199536\ttotal: 1m 11s\tremaining: 41.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631:\tlearn: 6.1179356\ttotal: 1m 11s\tremaining: 41.4s\n",
      "632:\tlearn: 6.1156901\ttotal: 1m 11s\tremaining: 41.3s\n",
      "633:\tlearn: 6.1134568\ttotal: 1m 11s\tremaining: 41.2s\n",
      "634:\tlearn: 6.1114826\ttotal: 1m 11s\tremaining: 41.1s\n",
      "635:\tlearn: 6.1079798\ttotal: 1m 11s\tremaining: 41s\n",
      "636:\tlearn: 6.1057664\ttotal: 1m 11s\tremaining: 40.8s\n",
      "637:\tlearn: 6.1029919\ttotal: 1m 11s\tremaining: 40.7s\n",
      "638:\tlearn: 6.1026337\ttotal: 1m 11s\tremaining: 40.6s\n",
      "639:\tlearn: 6.1003631\ttotal: 1m 11s\tremaining: 40.5s\n",
      "640:\tlearn: 6.0970460\ttotal: 1m 12s\tremaining: 40.4s\n",
      "641:\tlearn: 6.0940030\ttotal: 1m 12s\tremaining: 40.3s\n",
      "642:\tlearn: 6.0932559\ttotal: 1m 12s\tremaining: 40.1s\n",
      "643:\tlearn: 6.0907929\ttotal: 1m 12s\tremaining: 40s\n",
      "644:\tlearn: 6.0880120\ttotal: 1m 12s\tremaining: 39.9s\n",
      "645:\tlearn: 6.0859390\ttotal: 1m 12s\tremaining: 39.8s\n",
      "646:\tlearn: 6.0824852\ttotal: 1m 12s\tremaining: 39.7s\n",
      "647:\tlearn: 6.0799097\ttotal: 1m 12s\tremaining: 39.5s\n",
      "648:\tlearn: 6.0770584\ttotal: 1m 12s\tremaining: 39.4s\n",
      "649:\tlearn: 6.0742677\ttotal: 1m 13s\tremaining: 39.3s\n",
      "650:\tlearn: 6.0713022\ttotal: 1m 13s\tremaining: 39.2s\n",
      "651:\tlearn: 6.0697306\ttotal: 1m 13s\tremaining: 39.1s\n",
      "652:\tlearn: 6.0667504\ttotal: 1m 13s\tremaining: 39s\n",
      "653:\tlearn: 6.0649513\ttotal: 1m 13s\tremaining: 38.9s\n",
      "654:\tlearn: 6.0628201\ttotal: 1m 13s\tremaining: 38.7s\n",
      "655:\tlearn: 6.0599790\ttotal: 1m 13s\tremaining: 38.6s\n",
      "656:\tlearn: 6.0564335\ttotal: 1m 13s\tremaining: 38.5s\n",
      "657:\tlearn: 6.0530329\ttotal: 1m 13s\tremaining: 38.4s\n",
      "658:\tlearn: 6.0500662\ttotal: 1m 13s\tremaining: 38.3s\n",
      "659:\tlearn: 6.0487696\ttotal: 1m 14s\tremaining: 38.2s\n",
      "660:\tlearn: 6.0461753\ttotal: 1m 14s\tremaining: 38s\n",
      "661:\tlearn: 6.0440470\ttotal: 1m 14s\tremaining: 37.9s\n",
      "662:\tlearn: 6.0407520\ttotal: 1m 14s\tremaining: 37.8s\n",
      "663:\tlearn: 6.0382857\ttotal: 1m 14s\tremaining: 37.7s\n",
      "664:\tlearn: 6.0365325\ttotal: 1m 14s\tremaining: 37.6s\n",
      "665:\tlearn: 6.0337578\ttotal: 1m 14s\tremaining: 37.4s\n",
      "666:\tlearn: 6.0336061\ttotal: 1m 14s\tremaining: 37.3s\n",
      "667:\tlearn: 6.0303383\ttotal: 1m 14s\tremaining: 37.2s\n",
      "668:\tlearn: 6.0301692\ttotal: 1m 14s\tremaining: 37.1s\n",
      "669:\tlearn: 6.0276922\ttotal: 1m 15s\tremaining: 37s\n",
      "670:\tlearn: 6.0247824\ttotal: 1m 15s\tremaining: 36.8s\n",
      "671:\tlearn: 6.0217927\ttotal: 1m 15s\tremaining: 36.7s\n",
      "672:\tlearn: 6.0193280\ttotal: 1m 15s\tremaining: 36.6s\n",
      "673:\tlearn: 6.0163327\ttotal: 1m 15s\tremaining: 36.5s\n",
      "674:\tlearn: 6.0135428\ttotal: 1m 15s\tremaining: 36.4s\n",
      "675:\tlearn: 6.0119297\ttotal: 1m 15s\tremaining: 36.2s\n",
      "676:\tlearn: 6.0094634\ttotal: 1m 15s\tremaining: 36.1s\n",
      "677:\tlearn: 6.0063190\ttotal: 1m 15s\tremaining: 36s\n",
      "678:\tlearn: 6.0042518\ttotal: 1m 15s\tremaining: 35.9s\n",
      "679:\tlearn: 6.0040003\ttotal: 1m 16s\tremaining: 35.8s\n",
      "680:\tlearn: 6.0022884\ttotal: 1m 16s\tremaining: 35.7s\n",
      "681:\tlearn: 6.0006511\ttotal: 1m 16s\tremaining: 35.6s\n",
      "682:\tlearn: 5.9965217\ttotal: 1m 16s\tremaining: 35.4s\n",
      "683:\tlearn: 5.9950360\ttotal: 1m 16s\tremaining: 35.3s\n",
      "684:\tlearn: 5.9928479\ttotal: 1m 16s\tremaining: 35.2s\n",
      "685:\tlearn: 5.9897704\ttotal: 1m 16s\tremaining: 35.1s\n",
      "686:\tlearn: 5.9864016\ttotal: 1m 16s\tremaining: 35s\n",
      "687:\tlearn: 5.9843531\ttotal: 1m 16s\tremaining: 34.9s\n",
      "688:\tlearn: 5.9821458\ttotal: 1m 17s\tremaining: 34.8s\n",
      "689:\tlearn: 5.9793269\ttotal: 1m 17s\tremaining: 34.6s\n",
      "690:\tlearn: 5.9766278\ttotal: 1m 17s\tremaining: 34.5s\n",
      "691:\tlearn: 5.9738540\ttotal: 1m 17s\tremaining: 34.4s\n",
      "692:\tlearn: 5.9708570\ttotal: 1m 17s\tremaining: 34.3s\n",
      "693:\tlearn: 5.9674792\ttotal: 1m 17s\tremaining: 34.2s\n",
      "694:\tlearn: 5.9645448\ttotal: 1m 17s\tremaining: 34.1s\n",
      "695:\tlearn: 5.9623010\ttotal: 1m 17s\tremaining: 34s\n",
      "696:\tlearn: 5.9591053\ttotal: 1m 17s\tremaining: 33.9s\n",
      "697:\tlearn: 5.9563347\ttotal: 1m 18s\tremaining: 33.8s\n",
      "698:\tlearn: 5.9531754\ttotal: 1m 18s\tremaining: 33.6s\n",
      "699:\tlearn: 5.9525059\ttotal: 1m 18s\tremaining: 33.5s\n",
      "700:\tlearn: 5.9502205\ttotal: 1m 18s\tremaining: 33.4s\n",
      "701:\tlearn: 5.9471596\ttotal: 1m 18s\tremaining: 33.3s\n",
      "702:\tlearn: 5.9441947\ttotal: 1m 18s\tremaining: 33.2s\n",
      "703:\tlearn: 5.9411133\ttotal: 1m 18s\tremaining: 33.1s\n",
      "704:\tlearn: 5.9382633\ttotal: 1m 18s\tremaining: 33s\n",
      "705:\tlearn: 5.9351678\ttotal: 1m 18s\tremaining: 32.9s\n",
      "706:\tlearn: 5.9322934\ttotal: 1m 19s\tremaining: 32.8s\n",
      "707:\tlearn: 5.9299074\ttotal: 1m 19s\tremaining: 32.6s\n",
      "708:\tlearn: 5.9280042\ttotal: 1m 19s\tremaining: 32.5s\n",
      "709:\tlearn: 5.9256054\ttotal: 1m 19s\tremaining: 32.4s\n",
      "710:\tlearn: 5.9235357\ttotal: 1m 19s\tremaining: 32.3s\n",
      "711:\tlearn: 5.9201217\ttotal: 1m 19s\tremaining: 32.2s\n",
      "712:\tlearn: 5.9175570\ttotal: 1m 19s\tremaining: 32.1s\n",
      "713:\tlearn: 5.9151126\ttotal: 1m 19s\tremaining: 32s\n",
      "714:\tlearn: 5.9130483\ttotal: 1m 19s\tremaining: 31.9s\n",
      "715:\tlearn: 5.9102120\ttotal: 1m 20s\tremaining: 31.7s\n",
      "716:\tlearn: 5.9071786\ttotal: 1m 20s\tremaining: 31.6s\n",
      "717:\tlearn: 5.9051910\ttotal: 1m 20s\tremaining: 31.5s\n",
      "718:\tlearn: 5.9029681\ttotal: 1m 20s\tremaining: 31.4s\n",
      "719:\tlearn: 5.9006345\ttotal: 1m 20s\tremaining: 31.3s\n",
      "720:\tlearn: 5.8970639\ttotal: 1m 20s\tremaining: 31.2s\n",
      "721:\tlearn: 5.8953207\ttotal: 1m 20s\tremaining: 31.1s\n",
      "722:\tlearn: 5.8941706\ttotal: 1m 20s\tremaining: 31s\n",
      "723:\tlearn: 5.8924722\ttotal: 1m 20s\tremaining: 30.8s\n",
      "724:\tlearn: 5.8896981\ttotal: 1m 21s\tremaining: 30.7s\n",
      "725:\tlearn: 5.8861850\ttotal: 1m 21s\tremaining: 30.6s\n",
      "726:\tlearn: 5.8843969\ttotal: 1m 21s\tremaining: 30.5s\n",
      "727:\tlearn: 5.8828562\ttotal: 1m 21s\tremaining: 30.4s\n",
      "728:\tlearn: 5.8810265\ttotal: 1m 21s\tremaining: 30.3s\n",
      "729:\tlearn: 5.8803512\ttotal: 1m 21s\tremaining: 30.2s\n",
      "730:\tlearn: 5.8776536\ttotal: 1m 21s\tremaining: 30s\n",
      "731:\tlearn: 5.8751239\ttotal: 1m 21s\tremaining: 29.9s\n",
      "732:\tlearn: 5.8748781\ttotal: 1m 21s\tremaining: 29.8s\n",
      "733:\tlearn: 5.8724997\ttotal: 1m 21s\tremaining: 29.7s\n",
      "734:\tlearn: 5.8703386\ttotal: 1m 22s\tremaining: 29.6s\n",
      "735:\tlearn: 5.8696691\ttotal: 1m 22s\tremaining: 29.5s\n",
      "736:\tlearn: 5.8671898\ttotal: 1m 22s\tremaining: 29.4s\n",
      "737:\tlearn: 5.8641073\ttotal: 1m 22s\tremaining: 29.2s\n",
      "738:\tlearn: 5.8612750\ttotal: 1m 22s\tremaining: 29.1s\n",
      "739:\tlearn: 5.8586494\ttotal: 1m 22s\tremaining: 29s\n",
      "740:\tlearn: 5.8562678\ttotal: 1m 22s\tremaining: 28.9s\n",
      "741:\tlearn: 5.8544856\ttotal: 1m 22s\tremaining: 28.8s\n",
      "742:\tlearn: 5.8517416\ttotal: 1m 22s\tremaining: 28.7s\n",
      "743:\tlearn: 5.8485947\ttotal: 1m 22s\tremaining: 28.5s\n",
      "744:\tlearn: 5.8467894\ttotal: 1m 23s\tremaining: 28.4s\n",
      "745:\tlearn: 5.8431526\ttotal: 1m 23s\tremaining: 28.3s\n",
      "746:\tlearn: 5.8406082\ttotal: 1m 23s\tremaining: 28.2s\n",
      "747:\tlearn: 5.8379530\ttotal: 1m 23s\tremaining: 28.1s\n",
      "748:\tlearn: 5.8350159\ttotal: 1m 23s\tremaining: 28s\n",
      "749:\tlearn: 5.8317554\ttotal: 1m 23s\tremaining: 27.9s\n",
      "750:\tlearn: 5.8285452\ttotal: 1m 23s\tremaining: 27.7s\n",
      "751:\tlearn: 5.8255245\ttotal: 1m 23s\tremaining: 27.6s\n",
      "752:\tlearn: 5.8231479\ttotal: 1m 23s\tremaining: 27.5s\n",
      "753:\tlearn: 5.8206759\ttotal: 1m 23s\tremaining: 27.4s\n",
      "754:\tlearn: 5.8177706\ttotal: 1m 24s\tremaining: 27.3s\n",
      "755:\tlearn: 5.8152000\ttotal: 1m 24s\tremaining: 27.2s\n",
      "756:\tlearn: 5.8128546\ttotal: 1m 24s\tremaining: 27.1s\n",
      "757:\tlearn: 5.8117308\ttotal: 1m 24s\tremaining: 27s\n",
      "758:\tlearn: 5.8097903\ttotal: 1m 24s\tremaining: 26.8s\n",
      "759:\tlearn: 5.8066634\ttotal: 1m 24s\tremaining: 26.7s\n",
      "760:\tlearn: 5.8042867\ttotal: 1m 24s\tremaining: 26.6s\n",
      "761:\tlearn: 5.8014281\ttotal: 1m 24s\tremaining: 26.5s\n",
      "762:\tlearn: 5.7995446\ttotal: 1m 24s\tremaining: 26.4s\n",
      "763:\tlearn: 5.7964563\ttotal: 1m 25s\tremaining: 26.3s\n",
      "764:\tlearn: 5.7936365\ttotal: 1m 25s\tremaining: 26.2s\n",
      "765:\tlearn: 5.7933662\ttotal: 1m 25s\tremaining: 26.1s\n",
      "766:\tlearn: 5.7901890\ttotal: 1m 25s\tremaining: 25.9s\n",
      "767:\tlearn: 5.7885201\ttotal: 1m 25s\tremaining: 25.8s\n",
      "768:\tlearn: 5.7860926\ttotal: 1m 25s\tremaining: 25.7s\n",
      "769:\tlearn: 5.7859404\ttotal: 1m 25s\tremaining: 25.6s\n",
      "770:\tlearn: 5.7857787\ttotal: 1m 25s\tremaining: 25.5s\n",
      "771:\tlearn: 5.7831070\ttotal: 1m 25s\tremaining: 25.4s\n",
      "772:\tlearn: 5.7803216\ttotal: 1m 26s\tremaining: 25.3s\n",
      "773:\tlearn: 5.7788548\ttotal: 1m 26s\tremaining: 25.2s\n",
      "774:\tlearn: 5.7762890\ttotal: 1m 26s\tremaining: 25s\n",
      "775:\tlearn: 5.7728690\ttotal: 1m 26s\tremaining: 24.9s\n",
      "776:\tlearn: 5.7708019\ttotal: 1m 26s\tremaining: 24.8s\n",
      "777:\tlearn: 5.7682663\ttotal: 1m 26s\tremaining: 24.7s\n",
      "778:\tlearn: 5.7649934\ttotal: 1m 26s\tremaining: 24.6s\n",
      "779:\tlearn: 5.7630300\ttotal: 1m 26s\tremaining: 24.5s\n",
      "780:\tlearn: 5.7610525\ttotal: 1m 26s\tremaining: 24.4s\n",
      "781:\tlearn: 5.7593023\ttotal: 1m 27s\tremaining: 24.3s\n",
      "782:\tlearn: 5.7564461\ttotal: 1m 27s\tremaining: 24.1s\n",
      "783:\tlearn: 5.7543707\ttotal: 1m 27s\tremaining: 24s\n",
      "784:\tlearn: 5.7519231\ttotal: 1m 27s\tremaining: 23.9s\n",
      "785:\tlearn: 5.7485845\ttotal: 1m 27s\tremaining: 23.8s\n",
      "786:\tlearn: 5.7454620\ttotal: 1m 27s\tremaining: 23.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787:\tlearn: 5.7429106\ttotal: 1m 27s\tremaining: 23.6s\n",
      "788:\tlearn: 5.7406165\ttotal: 1m 27s\tremaining: 23.5s\n",
      "789:\tlearn: 5.7397099\ttotal: 1m 27s\tremaining: 23.4s\n",
      "790:\tlearn: 5.7378890\ttotal: 1m 28s\tremaining: 23.3s\n",
      "791:\tlearn: 5.7353971\ttotal: 1m 28s\tremaining: 23.1s\n",
      "792:\tlearn: 5.7340927\ttotal: 1m 28s\tremaining: 23s\n",
      "793:\tlearn: 5.7315914\ttotal: 1m 28s\tremaining: 22.9s\n",
      "794:\tlearn: 5.7288407\ttotal: 1m 28s\tremaining: 22.8s\n",
      "795:\tlearn: 5.7249591\ttotal: 1m 28s\tremaining: 22.7s\n",
      "796:\tlearn: 5.7225911\ttotal: 1m 28s\tremaining: 22.6s\n",
      "797:\tlearn: 5.7200885\ttotal: 1m 28s\tremaining: 22.5s\n",
      "798:\tlearn: 5.7176038\ttotal: 1m 28s\tremaining: 22.4s\n",
      "799:\tlearn: 5.7157267\ttotal: 1m 28s\tremaining: 22.2s\n",
      "800:\tlearn: 5.7129801\ttotal: 1m 29s\tremaining: 22.1s\n",
      "801:\tlearn: 5.7113458\ttotal: 1m 29s\tremaining: 22s\n",
      "802:\tlearn: 5.7073431\ttotal: 1m 29s\tremaining: 21.9s\n",
      "803:\tlearn: 5.7054324\ttotal: 1m 29s\tremaining: 21.8s\n",
      "804:\tlearn: 5.7033296\ttotal: 1m 29s\tremaining: 21.7s\n",
      "805:\tlearn: 5.7012145\ttotal: 1m 29s\tremaining: 21.6s\n",
      "806:\tlearn: 5.6995348\ttotal: 1m 29s\tremaining: 21.5s\n",
      "807:\tlearn: 5.6977431\ttotal: 1m 29s\tremaining: 21.4s\n",
      "808:\tlearn: 5.6950623\ttotal: 1m 30s\tremaining: 21.2s\n",
      "809:\tlearn: 5.6916613\ttotal: 1m 30s\tremaining: 21.1s\n",
      "810:\tlearn: 5.6887018\ttotal: 1m 30s\tremaining: 21s\n",
      "811:\tlearn: 5.6866762\ttotal: 1m 30s\tremaining: 20.9s\n",
      "812:\tlearn: 5.6840579\ttotal: 1m 30s\tremaining: 20.8s\n",
      "813:\tlearn: 5.6815252\ttotal: 1m 30s\tremaining: 20.7s\n",
      "814:\tlearn: 5.6796106\ttotal: 1m 30s\tremaining: 20.6s\n",
      "815:\tlearn: 5.6788911\ttotal: 1m 30s\tremaining: 20.5s\n",
      "816:\tlearn: 5.6759025\ttotal: 1m 30s\tremaining: 20.4s\n",
      "817:\tlearn: 5.6721756\ttotal: 1m 30s\tremaining: 20.2s\n",
      "818:\tlearn: 5.6696717\ttotal: 1m 31s\tremaining: 20.1s\n",
      "819:\tlearn: 5.6673249\ttotal: 1m 31s\tremaining: 20s\n",
      "820:\tlearn: 5.6656998\ttotal: 1m 31s\tremaining: 19.9s\n",
      "821:\tlearn: 5.6637022\ttotal: 1m 31s\tremaining: 19.8s\n",
      "822:\tlearn: 5.6613033\ttotal: 1m 31s\tremaining: 19.7s\n",
      "823:\tlearn: 5.6589969\ttotal: 1m 31s\tremaining: 19.6s\n",
      "824:\tlearn: 5.6567593\ttotal: 1m 31s\tremaining: 19.5s\n",
      "825:\tlearn: 5.6545220\ttotal: 1m 31s\tremaining: 19.3s\n",
      "826:\tlearn: 5.6527259\ttotal: 1m 31s\tremaining: 19.2s\n",
      "827:\tlearn: 5.6503760\ttotal: 1m 32s\tremaining: 19.1s\n",
      "828:\tlearn: 5.6480957\ttotal: 1m 32s\tremaining: 19s\n",
      "829:\tlearn: 5.6456388\ttotal: 1m 32s\tremaining: 18.9s\n",
      "830:\tlearn: 5.6454412\ttotal: 1m 32s\tremaining: 18.8s\n",
      "831:\tlearn: 5.6424984\ttotal: 1m 32s\tremaining: 18.7s\n",
      "832:\tlearn: 5.6399240\ttotal: 1m 32s\tremaining: 18.6s\n",
      "833:\tlearn: 5.6384376\ttotal: 1m 32s\tremaining: 18.4s\n",
      "834:\tlearn: 5.6372068\ttotal: 1m 32s\tremaining: 18.3s\n",
      "835:\tlearn: 5.6338612\ttotal: 1m 32s\tremaining: 18.2s\n",
      "836:\tlearn: 5.6322446\ttotal: 1m 32s\tremaining: 18.1s\n",
      "837:\tlearn: 5.6302126\ttotal: 1m 33s\tremaining: 18s\n",
      "838:\tlearn: 5.6278971\ttotal: 1m 33s\tremaining: 17.9s\n",
      "839:\tlearn: 5.6241910\ttotal: 1m 33s\tremaining: 17.8s\n",
      "840:\tlearn: 5.6222851\ttotal: 1m 33s\tremaining: 17.7s\n",
      "841:\tlearn: 5.6197882\ttotal: 1m 33s\tremaining: 17.5s\n",
      "842:\tlearn: 5.6173531\ttotal: 1m 33s\tremaining: 17.4s\n",
      "843:\tlearn: 5.6146170\ttotal: 1m 33s\tremaining: 17.3s\n",
      "844:\tlearn: 5.6107592\ttotal: 1m 33s\tremaining: 17.2s\n",
      "845:\tlearn: 5.6079932\ttotal: 1m 33s\tremaining: 17.1s\n",
      "846:\tlearn: 5.6056699\ttotal: 1m 34s\tremaining: 17s\n",
      "847:\tlearn: 5.6035454\ttotal: 1m 34s\tremaining: 16.9s\n",
      "848:\tlearn: 5.6023468\ttotal: 1m 34s\tremaining: 16.8s\n",
      "849:\tlearn: 5.5984597\ttotal: 1m 34s\tremaining: 16.7s\n",
      "850:\tlearn: 5.5962258\ttotal: 1m 34s\tremaining: 16.5s\n",
      "851:\tlearn: 5.5939385\ttotal: 1m 34s\tremaining: 16.4s\n",
      "852:\tlearn: 5.5912610\ttotal: 1m 34s\tremaining: 16.3s\n",
      "853:\tlearn: 5.5881477\ttotal: 1m 34s\tremaining: 16.2s\n",
      "854:\tlearn: 5.5859907\ttotal: 1m 34s\tremaining: 16.1s\n",
      "855:\tlearn: 5.5836569\ttotal: 1m 35s\tremaining: 16s\n",
      "856:\tlearn: 5.5835208\ttotal: 1m 35s\tremaining: 15.9s\n",
      "857:\tlearn: 5.5808376\ttotal: 1m 35s\tremaining: 15.8s\n",
      "858:\tlearn: 5.5791246\ttotal: 1m 35s\tremaining: 15.6s\n",
      "859:\tlearn: 5.5758827\ttotal: 1m 35s\tremaining: 15.5s\n",
      "860:\tlearn: 5.5731155\ttotal: 1m 35s\tremaining: 15.4s\n",
      "861:\tlearn: 5.5716160\ttotal: 1m 35s\tremaining: 15.3s\n",
      "862:\tlearn: 5.5698757\ttotal: 1m 35s\tremaining: 15.2s\n",
      "863:\tlearn: 5.5678967\ttotal: 1m 35s\tremaining: 15.1s\n",
      "864:\tlearn: 5.5650268\ttotal: 1m 35s\tremaining: 15s\n",
      "865:\tlearn: 5.5622991\ttotal: 1m 36s\tremaining: 14.9s\n",
      "866:\tlearn: 5.5594497\ttotal: 1m 36s\tremaining: 14.8s\n",
      "867:\tlearn: 5.5562731\ttotal: 1m 36s\tremaining: 14.6s\n",
      "868:\tlearn: 5.5537470\ttotal: 1m 36s\tremaining: 14.5s\n",
      "869:\tlearn: 5.5520226\ttotal: 1m 36s\tremaining: 14.4s\n",
      "870:\tlearn: 5.5496457\ttotal: 1m 36s\tremaining: 14.3s\n",
      "871:\tlearn: 5.5474303\ttotal: 1m 36s\tremaining: 14.2s\n",
      "872:\tlearn: 5.5460973\ttotal: 1m 36s\tremaining: 14.1s\n",
      "873:\tlearn: 5.5433791\ttotal: 1m 36s\tremaining: 14s\n",
      "874:\tlearn: 5.5408545\ttotal: 1m 37s\tremaining: 13.9s\n",
      "875:\tlearn: 5.5395894\ttotal: 1m 37s\tremaining: 13.7s\n",
      "876:\tlearn: 5.5371826\ttotal: 1m 37s\tremaining: 13.6s\n",
      "877:\tlearn: 5.5343985\ttotal: 1m 37s\tremaining: 13.5s\n",
      "878:\tlearn: 5.5314899\ttotal: 1m 37s\tremaining: 13.4s\n",
      "879:\tlearn: 5.5295012\ttotal: 1m 37s\tremaining: 13.3s\n",
      "880:\tlearn: 5.5258512\ttotal: 1m 37s\tremaining: 13.2s\n",
      "881:\tlearn: 5.5235021\ttotal: 1m 37s\tremaining: 13.1s\n",
      "882:\tlearn: 5.5216873\ttotal: 1m 37s\tremaining: 13s\n",
      "883:\tlearn: 5.5200492\ttotal: 1m 37s\tremaining: 12.8s\n",
      "884:\tlearn: 5.5180017\ttotal: 1m 38s\tremaining: 12.7s\n",
      "885:\tlearn: 5.5152125\ttotal: 1m 38s\tremaining: 12.6s\n",
      "886:\tlearn: 5.5122490\ttotal: 1m 38s\tremaining: 12.5s\n",
      "887:\tlearn: 5.5104757\ttotal: 1m 38s\tremaining: 12.4s\n",
      "888:\tlearn: 5.5075954\ttotal: 1m 38s\tremaining: 12.3s\n",
      "889:\tlearn: 5.5055189\ttotal: 1m 38s\tremaining: 12.2s\n",
      "890:\tlearn: 5.5032009\ttotal: 1m 38s\tremaining: 12.1s\n",
      "891:\tlearn: 5.5006757\ttotal: 1m 38s\tremaining: 12s\n",
      "892:\tlearn: 5.4997390\ttotal: 1m 38s\tremaining: 11.8s\n",
      "893:\tlearn: 5.4976069\ttotal: 1m 38s\tremaining: 11.7s\n",
      "894:\tlearn: 5.4960956\ttotal: 1m 39s\tremaining: 11.6s\n",
      "895:\tlearn: 5.4935267\ttotal: 1m 39s\tremaining: 11.5s\n",
      "896:\tlearn: 5.4933503\ttotal: 1m 39s\tremaining: 11.4s\n",
      "897:\tlearn: 5.4898114\ttotal: 1m 39s\tremaining: 11.3s\n",
      "898:\tlearn: 5.4880008\ttotal: 1m 39s\tremaining: 11.2s\n",
      "899:\tlearn: 5.4877711\ttotal: 1m 39s\tremaining: 11.1s\n",
      "900:\tlearn: 5.4851576\ttotal: 1m 39s\tremaining: 11s\n",
      "901:\tlearn: 5.4826399\ttotal: 1m 39s\tremaining: 10.8s\n",
      "902:\tlearn: 5.4805261\ttotal: 1m 39s\tremaining: 10.7s\n",
      "903:\tlearn: 5.4782353\ttotal: 1m 40s\tremaining: 10.6s\n",
      "904:\tlearn: 5.4780847\ttotal: 1m 40s\tremaining: 10.5s\n",
      "905:\tlearn: 5.4758853\ttotal: 1m 40s\tremaining: 10.4s\n",
      "906:\tlearn: 5.4730995\ttotal: 1m 40s\tremaining: 10.3s\n",
      "907:\tlearn: 5.4706457\ttotal: 1m 40s\tremaining: 10.2s\n",
      "908:\tlearn: 5.4681233\ttotal: 1m 40s\tremaining: 10.1s\n",
      "909:\tlearn: 5.4666416\ttotal: 1m 40s\tremaining: 9.96s\n",
      "910:\tlearn: 5.4644311\ttotal: 1m 40s\tremaining: 9.85s\n",
      "911:\tlearn: 5.4610466\ttotal: 1m 40s\tremaining: 9.74s\n",
      "912:\tlearn: 5.4587141\ttotal: 1m 41s\tremaining: 9.63s\n",
      "913:\tlearn: 5.4549179\ttotal: 1m 41s\tremaining: 9.52s\n",
      "914:\tlearn: 5.4523173\ttotal: 1m 41s\tremaining: 9.41s\n",
      "915:\tlearn: 5.4502377\ttotal: 1m 41s\tremaining: 9.3s\n",
      "916:\tlearn: 5.4501377\ttotal: 1m 41s\tremaining: 9.19s\n",
      "917:\tlearn: 5.4483859\ttotal: 1m 41s\tremaining: 9.08s\n",
      "918:\tlearn: 5.4462643\ttotal: 1m 41s\tremaining: 8.97s\n",
      "919:\tlearn: 5.4434415\ttotal: 1m 41s\tremaining: 8.86s\n",
      "920:\tlearn: 5.4415179\ttotal: 1m 41s\tremaining: 8.75s\n",
      "921:\tlearn: 5.4395583\ttotal: 1m 42s\tremaining: 8.64s\n",
      "922:\tlearn: 5.4367676\ttotal: 1m 42s\tremaining: 8.53s\n",
      "923:\tlearn: 5.4355105\ttotal: 1m 42s\tremaining: 8.41s\n",
      "924:\tlearn: 5.4334679\ttotal: 1m 42s\tremaining: 8.3s\n",
      "925:\tlearn: 5.4315596\ttotal: 1m 42s\tremaining: 8.2s\n",
      "926:\tlearn: 5.4295634\ttotal: 1m 42s\tremaining: 8.09s\n",
      "927:\tlearn: 5.4272674\ttotal: 1m 42s\tremaining: 7.97s\n",
      "928:\tlearn: 5.4252484\ttotal: 1m 42s\tremaining: 7.86s\n",
      "929:\tlearn: 5.4231444\ttotal: 1m 43s\tremaining: 7.75s\n",
      "930:\tlearn: 5.4211846\ttotal: 1m 43s\tremaining: 7.64s\n",
      "931:\tlearn: 5.4190751\ttotal: 1m 43s\tremaining: 7.53s\n",
      "932:\tlearn: 5.4163534\ttotal: 1m 43s\tremaining: 7.42s\n",
      "933:\tlearn: 5.4142935\ttotal: 1m 43s\tremaining: 7.31s\n",
      "934:\tlearn: 5.4136453\ttotal: 1m 43s\tremaining: 7.2s\n",
      "935:\tlearn: 5.4117305\ttotal: 1m 43s\tremaining: 7.08s\n",
      "936:\tlearn: 5.4105086\ttotal: 1m 43s\tremaining: 6.97s\n",
      "937:\tlearn: 5.4087749\ttotal: 1m 43s\tremaining: 6.86s\n",
      "938:\tlearn: 5.4085974\ttotal: 1m 43s\tremaining: 6.75s\n",
      "939:\tlearn: 5.4070957\ttotal: 1m 44s\tremaining: 6.64s\n",
      "940:\tlearn: 5.4042177\ttotal: 1m 44s\tremaining: 6.53s\n",
      "941:\tlearn: 5.4024910\ttotal: 1m 44s\tremaining: 6.42s\n",
      "942:\tlearn: 5.4007899\ttotal: 1m 44s\tremaining: 6.31s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943:\tlearn: 5.3981758\ttotal: 1m 44s\tremaining: 6.2s\n",
      "944:\tlearn: 5.3965112\ttotal: 1m 44s\tremaining: 6.08s\n",
      "945:\tlearn: 5.3935576\ttotal: 1m 44s\tremaining: 5.97s\n",
      "946:\tlearn: 5.3934675\ttotal: 1m 44s\tremaining: 5.86s\n",
      "947:\tlearn: 5.3909211\ttotal: 1m 44s\tremaining: 5.75s\n",
      "948:\tlearn: 5.3883077\ttotal: 1m 44s\tremaining: 5.64s\n",
      "949:\tlearn: 5.3865949\ttotal: 1m 45s\tremaining: 5.53s\n",
      "950:\tlearn: 5.3837841\ttotal: 1m 45s\tremaining: 5.42s\n",
      "951:\tlearn: 5.3816843\ttotal: 1m 45s\tremaining: 5.31s\n",
      "952:\tlearn: 5.3791211\ttotal: 1m 45s\tremaining: 5.2s\n",
      "953:\tlearn: 5.3774253\ttotal: 1m 45s\tremaining: 5.08s\n",
      "954:\tlearn: 5.3754857\ttotal: 1m 45s\tremaining: 4.97s\n",
      "955:\tlearn: 5.3730185\ttotal: 1m 45s\tremaining: 4.86s\n",
      "956:\tlearn: 5.3710362\ttotal: 1m 45s\tremaining: 4.75s\n",
      "957:\tlearn: 5.3693228\ttotal: 1m 45s\tremaining: 4.64s\n",
      "958:\tlearn: 5.3669034\ttotal: 1m 45s\tremaining: 4.53s\n",
      "959:\tlearn: 5.3649721\ttotal: 1m 46s\tremaining: 4.42s\n",
      "960:\tlearn: 5.3629676\ttotal: 1m 46s\tremaining: 4.31s\n",
      "961:\tlearn: 5.3609455\ttotal: 1m 46s\tremaining: 4.2s\n",
      "962:\tlearn: 5.3579406\ttotal: 1m 46s\tremaining: 4.09s\n",
      "963:\tlearn: 5.3551772\ttotal: 1m 46s\tremaining: 3.98s\n",
      "964:\tlearn: 5.3526835\ttotal: 1m 46s\tremaining: 3.86s\n",
      "965:\tlearn: 5.3511961\ttotal: 1m 46s\tremaining: 3.75s\n",
      "966:\tlearn: 5.3486148\ttotal: 1m 46s\tremaining: 3.64s\n",
      "967:\tlearn: 5.3452724\ttotal: 1m 46s\tremaining: 3.53s\n",
      "968:\tlearn: 5.3450371\ttotal: 1m 46s\tremaining: 3.42s\n",
      "969:\tlearn: 5.3430495\ttotal: 1m 47s\tremaining: 3.31s\n",
      "970:\tlearn: 5.3407680\ttotal: 1m 47s\tremaining: 3.2s\n",
      "971:\tlearn: 5.3381828\ttotal: 1m 47s\tremaining: 3.09s\n",
      "972:\tlearn: 5.3356237\ttotal: 1m 47s\tremaining: 2.98s\n",
      "973:\tlearn: 5.3332008\ttotal: 1m 47s\tremaining: 2.87s\n",
      "974:\tlearn: 5.3315849\ttotal: 1m 47s\tremaining: 2.76s\n",
      "975:\tlearn: 5.3288890\ttotal: 1m 47s\tremaining: 2.65s\n",
      "976:\tlearn: 5.3271973\ttotal: 1m 47s\tremaining: 2.54s\n",
      "977:\tlearn: 5.3250008\ttotal: 1m 47s\tremaining: 2.43s\n",
      "978:\tlearn: 5.3228766\ttotal: 1m 48s\tremaining: 2.32s\n",
      "979:\tlearn: 5.3205557\ttotal: 1m 48s\tremaining: 2.21s\n",
      "980:\tlearn: 5.3191300\ttotal: 1m 48s\tremaining: 2.1s\n",
      "981:\tlearn: 5.3162080\ttotal: 1m 48s\tremaining: 1.99s\n",
      "982:\tlearn: 5.3141519\ttotal: 1m 48s\tremaining: 1.88s\n",
      "983:\tlearn: 5.3121386\ttotal: 1m 48s\tremaining: 1.76s\n",
      "984:\tlearn: 5.3107920\ttotal: 1m 48s\tremaining: 1.65s\n",
      "985:\tlearn: 5.3087419\ttotal: 1m 48s\tremaining: 1.54s\n",
      "986:\tlearn: 5.3052963\ttotal: 1m 48s\tremaining: 1.43s\n",
      "987:\tlearn: 5.3037677\ttotal: 1m 48s\tremaining: 1.32s\n",
      "988:\tlearn: 5.3031705\ttotal: 1m 49s\tremaining: 1.21s\n",
      "989:\tlearn: 5.3002445\ttotal: 1m 49s\tremaining: 1.1s\n",
      "990:\tlearn: 5.2983820\ttotal: 1m 49s\tremaining: 993ms\n",
      "991:\tlearn: 5.2969485\ttotal: 1m 49s\tremaining: 882ms\n",
      "992:\tlearn: 5.2946994\ttotal: 1m 49s\tremaining: 772ms\n",
      "993:\tlearn: 5.2914612\ttotal: 1m 49s\tremaining: 662ms\n",
      "994:\tlearn: 5.2912945\ttotal: 1m 49s\tremaining: 551ms\n",
      "995:\tlearn: 5.2887514\ttotal: 1m 49s\tremaining: 441ms\n",
      "996:\tlearn: 5.2864345\ttotal: 1m 49s\tremaining: 331ms\n",
      "997:\tlearn: 5.2843015\ttotal: 1m 50s\tremaining: 221ms\n",
      "998:\tlearn: 5.2824081\ttotal: 1m 50s\tremaining: 110ms\n",
      "999:\tlearn: 5.2799710\ttotal: 1m 50s\tremaining: 0us\n",
      "LGBMRegressor 로그 변환된 RMSE: 8.207\n",
      "CatBoostRegressor 로그 변환된 RMSE: 8.17\n",
      "XGBRegressor 로그 변환된 RMSE: 8.71\n",
      "Ridge 로그 변환된 RMSE: 8.613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.206723188377227, 8.169511039842016, 8.70962163964539, 8.612842337408413]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rmse(model):\n",
    "    pred = model.predict(valid_x)\n",
    "    mse = mean_squared_error(valid_y , pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('{0} 로그 변환된 RMSE: {1}'.format(model.__class__.__name__,np.round(rmse, 3)))\n",
    "    return rmse\n",
    "\n",
    "def get_rmses(models):\n",
    "    rmses = [ ]\n",
    "    for model in models:\n",
    "        rmse = get_rmse(model)\n",
    "        rmses.append(rmse)\n",
    "    return rmses\n",
    "\n",
    "\n",
    "\n",
    "lgbm = LGBMRegressor(random_state = 1000  )\n",
    "lgbm = lgbm.fit(train_x , train_y)\n",
    "\n",
    "cat = CatBoostRegressor(random_state=1000 )\n",
    "cat = cat.fit(train_x , train_y)\n",
    "\n",
    "xgb = XGBRegressor(random_state = 1000 )\n",
    "xgb.fit(train_x , train_y )\n",
    "\n",
    "reg_ridge = Ridge(random_state = 1000)\n",
    "reg_ridge.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "models = [lgbm, cat, xgb, reg_ridge ]\n",
    "get_rmses(models)\n",
    "\n",
    "\n",
    "# LGBMRegressor 로그 변환된 RMSE: 8.207\n",
    "# CatBoostRegressor 로그 변환된 RMSE: 8.17\n",
    "# XGBRegressor 로그 변환된 RMSE: 8.71\n",
    "# Ridge 로그 변환된 RMSE: 8.613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_params = {\n",
    "    'max_depth':(8, 16),\n",
    "    'num_leaves':(24, 64),\n",
    "    'min_child_samples':(10, 200),\n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1),\n",
    "    'colsample_bytree':(0.5, 1),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha':(0.01, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_rmse_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree, max_bin, reg_lambda, reg_alpha):\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\":2000, \n",
    "        \"learning_rate\":0.02,\n",
    "        'max_depth':int(round(max_depth)),\n",
    "        'num_leaves':int(round(num_leaves)),\n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample':max(min(subsample, 1), 0),\n",
    "        'colsample_bytree':max(min(colsample_bytree, 1), 0),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0)\n",
    "    }\n",
    "    \n",
    "    lgb_model = LGBMRegressor(**params)\n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'RMSE', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    valid_pred = lgb_model.predict(valid_x)\n",
    "    RMSE = np.sqrt(mean_squared_error(valid_y, valid_pred))\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.87656\ttraining's l2: 62.0401\tvalid_1's rmse: 8.3853\tvalid_1's l2: 70.3132\n",
      "[200]\ttraining's rmse: 7.19928\ttraining's l2: 51.8297\tvalid_1's rmse: 8.16586\tvalid_1's l2: 66.6813\n",
      "[300]\ttraining's rmse: 6.74315\ttraining's l2: 45.47\tvalid_1's rmse: 8.11178\tvalid_1's l2: 65.8009\n",
      "[400]\ttraining's rmse: 6.37198\ttraining's l2: 40.6021\tvalid_1's rmse: 8.09781\tvalid_1's l2: 65.5745\n",
      "[500]\ttraining's rmse: 6.05296\ttraining's l2: 36.6383\tvalid_1's rmse: 8.08935\tvalid_1's l2: 65.4375\n",
      "[600]\ttraining's rmse: 5.76775\ttraining's l2: 33.267\tvalid_1's rmse: 8.0912\tvalid_1's l2: 65.4675\n",
      "Early stopping, best iteration is:\n",
      "[522]\ttraining's rmse: 5.98662\ttraining's l2: 35.8396\tvalid_1's rmse: 8.08803\tvalid_1's l2: 65.4163\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 8.088   \u001b[0m | \u001b[0m 0.8268  \u001b[0m | \u001b[0m 66.35   \u001b[0m | \u001b[0m 15.6    \u001b[0m | \u001b[0m 101.6   \u001b[0m | \u001b[0m 43.75   \u001b[0m | \u001b[0m 32.49   \u001b[0m | \u001b[0m 2.045   \u001b[0m | \u001b[0m 3.973   \u001b[0m | \u001b[0m 0.6166  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.56476\ttraining's l2: 57.2255\tvalid_1's rmse: 8.34962\tvalid_1's l2: 69.7162\n",
      "[200]\ttraining's rmse: 6.6724\ttraining's l2: 44.5209\tvalid_1's rmse: 8.14757\tvalid_1's l2: 66.3829\n",
      "[300]\ttraining's rmse: 6.04835\ttraining's l2: 36.5826\tvalid_1's rmse: 8.10924\tvalid_1's l2: 65.7598\n",
      "[400]\ttraining's rmse: 5.54696\ttraining's l2: 30.7688\tvalid_1's rmse: 8.09951\tvalid_1's l2: 65.6021\n",
      "Early stopping, best iteration is:\n",
      "[374]\ttraining's rmse: 5.66697\ttraining's l2: 32.1145\tvalid_1's rmse: 8.0985\tvalid_1's l2: 65.5858\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 8.099   \u001b[0m | \u001b[95m 0.9209  \u001b[0m | \u001b[95m 111.5   \u001b[0m | \u001b[95m 13.94   \u001b[0m | \u001b[95m 84.51   \u001b[0m | \u001b[95m 9.931   \u001b[0m | \u001b[95m 53.74   \u001b[0m | \u001b[95m 3.488   \u001b[0m | \u001b[95m 8.853   \u001b[0m | \u001b[95m 0.9763  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.75648\ttraining's l2: 60.163\tvalid_1's rmse: 8.36288\tvalid_1's l2: 69.9378\n",
      "[200]\ttraining's rmse: 7.11442\ttraining's l2: 50.6149\tvalid_1's rmse: 8.16106\tvalid_1's l2: 66.6029\n",
      "[300]\ttraining's rmse: 6.73138\ttraining's l2: 45.3115\tvalid_1's rmse: 8.11442\tvalid_1's l2: 65.8437\n",
      "[400]\ttraining's rmse: 6.43833\ttraining's l2: 41.452\tvalid_1's rmse: 8.09932\tvalid_1's l2: 65.599\n",
      "[500]\ttraining's rmse: 6.20596\ttraining's l2: 38.514\tvalid_1's rmse: 8.09274\tvalid_1's l2: 65.4925\n",
      "[600]\ttraining's rmse: 5.99111\ttraining's l2: 35.8934\tvalid_1's rmse: 8.09366\tvalid_1's l2: 65.5074\n",
      "Early stopping, best iteration is:\n",
      "[532]\ttraining's rmse: 6.12632\ttraining's l2: 37.5318\tvalid_1's rmse: 8.09159\tvalid_1's l2: 65.4738\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 8.092   \u001b[0m | \u001b[0m 0.9656  \u001b[0m | \u001b[0m 213.6   \u001b[0m | \u001b[0m 8.232   \u001b[0m | \u001b[0m 196.6   \u001b[0m | \u001b[0m 17.64   \u001b[0m | \u001b[0m 52.27   \u001b[0m | \u001b[0m 18.1    \u001b[0m | \u001b[0m 0.352   \u001b[0m | \u001b[0m 0.9275  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.04457\ttraining's l2: 64.7151\tvalid_1's rmse: 8.41201\tvalid_1's l2: 70.7619\n",
      "[200]\ttraining's rmse: 7.46811\ttraining's l2: 55.7727\tvalid_1's rmse: 8.17319\tvalid_1's l2: 66.801\n",
      "[300]\ttraining's rmse: 7.10761\ttraining's l2: 50.5181\tvalid_1's rmse: 8.10983\tvalid_1's l2: 65.7693\n",
      "[400]\ttraining's rmse: 6.81458\ttraining's l2: 46.4386\tvalid_1's rmse: 8.08326\tvalid_1's l2: 65.3391\n",
      "[500]\ttraining's rmse: 6.5574\ttraining's l2: 42.9995\tvalid_1's rmse: 8.07463\tvalid_1's l2: 65.1997\n",
      "[600]\ttraining's rmse: 6.33238\ttraining's l2: 40.0991\tvalid_1's rmse: 8.06809\tvalid_1's l2: 65.0941\n",
      "[700]\ttraining's rmse: 6.11828\ttraining's l2: 37.4334\tvalid_1's rmse: 8.07082\tvalid_1's l2: 65.1381\n",
      "Early stopping, best iteration is:\n",
      "[637]\ttraining's rmse: 6.25031\ttraining's l2: 39.0664\tvalid_1's rmse: 8.06711\tvalid_1's l2: 65.0783\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 8.067   \u001b[0m | \u001b[0m 0.8286  \u001b[0m | \u001b[0m 385.2   \u001b[0m | \u001b[0m 12.43   \u001b[0m | \u001b[0m 178.2   \u001b[0m | \u001b[0m 45.31   \u001b[0m | \u001b[0m 24.42   \u001b[0m | \u001b[0m 3.737   \u001b[0m | \u001b[0m 2.447   \u001b[0m | \u001b[0m 0.5667  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.02264\ttraining's l2: 64.3628\tvalid_1's rmse: 8.42553\tvalid_1's l2: 70.9896\n",
      "[200]\ttraining's rmse: 7.42177\ttraining's l2: 55.0826\tvalid_1's rmse: 8.19745\tvalid_1's l2: 67.1981\n",
      "[300]\ttraining's rmse: 7.03317\ttraining's l2: 49.4655\tvalid_1's rmse: 8.13661\tvalid_1's l2: 66.2044\n",
      "[400]\ttraining's rmse: 6.71121\ttraining's l2: 45.0403\tvalid_1's rmse: 8.11328\tvalid_1's l2: 65.8254\n",
      "[500]\ttraining's rmse: 6.43644\ttraining's l2: 41.4278\tvalid_1's rmse: 8.10696\tvalid_1's l2: 65.7228\n",
      "[600]\ttraining's rmse: 6.18614\ttraining's l2: 38.2683\tvalid_1's rmse: 8.10095\tvalid_1's l2: 65.6255\n",
      "Early stopping, best iteration is:\n",
      "[583]\ttraining's rmse: 6.22587\ttraining's l2: 38.7614\tvalid_1's rmse: 8.10095\tvalid_1's l2: 65.6254\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 8.101   \u001b[0m | \u001b[95m 0.849   \u001b[0m | \u001b[95m 205.1   \u001b[0m | \u001b[95m 15.06   \u001b[0m | \u001b[95m 44.39   \u001b[0m | \u001b[95m 22.19   \u001b[0m | \u001b[95m 24.73   \u001b[0m | \u001b[95m 34.57   \u001b[0m | \u001b[95m 4.697   \u001b[0m | \u001b[95m 0.5641  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.78445\ttraining's l2: 60.5976\tvalid_1's rmse: 8.39859\tvalid_1's l2: 70.5363\n",
      "[200]\ttraining's rmse: 7.03359\ttraining's l2: 49.4715\tvalid_1's rmse: 8.18137\tvalid_1's l2: 66.9347\n",
      "[300]\ttraining's rmse: 6.5207\ttraining's l2: 42.5196\tvalid_1's rmse: 8.13192\tvalid_1's l2: 66.1281\n",
      "[400]\ttraining's rmse: 6.09615\ttraining's l2: 37.163\tvalid_1's rmse: 8.11433\tvalid_1's l2: 65.8424\n",
      "[500]\ttraining's rmse: 5.73547\ttraining's l2: 32.8957\tvalid_1's rmse: 8.10699\tvalid_1's l2: 65.7232\n",
      "[600]\ttraining's rmse: 5.41598\ttraining's l2: 29.3328\tvalid_1's rmse: 8.10522\tvalid_1's l2: 65.6945\n",
      "[700]\ttraining's rmse: 5.13108\ttraining's l2: 26.328\tvalid_1's rmse: 8.10275\tvalid_1's l2: 65.6546\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttraining's rmse: 5.17208\ttraining's l2: 26.7504\tvalid_1's rmse: 8.102\tvalid_1's l2: 65.6424\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 8.102   \u001b[0m | \u001b[95m 0.8498  \u001b[0m | \u001b[95m 125.9   \u001b[0m | \u001b[95m 14.37   \u001b[0m | \u001b[95m 10.64   \u001b[0m | \u001b[95m 6.904   \u001b[0m | \u001b[95m 39.4    \u001b[0m | \u001b[95m 41.1    \u001b[0m | \u001b[95m 7.448   \u001b[0m | \u001b[95m 0.5557  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.99497\ttraining's l2: 63.9195\tvalid_1's rmse: 8.4059\tvalid_1's l2: 70.6592\n",
      "[200]\ttraining's rmse: 7.37455\ttraining's l2: 54.384\tvalid_1's rmse: 8.1753\tvalid_1's l2: 66.8355\n",
      "[300]\ttraining's rmse: 6.97222\ttraining's l2: 48.6118\tvalid_1's rmse: 8.115\tvalid_1's l2: 65.8533\n",
      "[400]\ttraining's rmse: 6.63761\ttraining's l2: 44.0579\tvalid_1's rmse: 8.09248\tvalid_1's l2: 65.4882\n",
      "[500]\ttraining's rmse: 6.34906\ttraining's l2: 40.3106\tvalid_1's rmse: 8.08219\tvalid_1's l2: 65.3218\n",
      "[600]\ttraining's rmse: 6.09345\ttraining's l2: 37.1302\tvalid_1's rmse: 8.07696\tvalid_1's l2: 65.2373\n",
      "[700]\ttraining's rmse: 5.86231\ttraining's l2: 34.3667\tvalid_1's rmse: 8.07556\tvalid_1's l2: 65.2147\n",
      "Early stopping, best iteration is:\n",
      "[632]\ttraining's rmse: 6.01752\ttraining's l2: 36.2105\tvalid_1's rmse: 8.07436\tvalid_1's l2: 65.1952\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 8.074   \u001b[0m | \u001b[0m 0.6164  \u001b[0m | \u001b[0m 196.7   \u001b[0m | \u001b[0m 13.94   \u001b[0m | \u001b[0m 40.92   \u001b[0m | \u001b[0m 17.82   \u001b[0m | \u001b[0m 27.72   \u001b[0m | \u001b[0m 37.33   \u001b[0m | \u001b[0m 9.548   \u001b[0m | \u001b[0m 0.7088  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.82146\ttraining's l2: 61.1753\tvalid_1's rmse: 8.3857\tvalid_1's l2: 70.32\n",
      "[200]\ttraining's rmse: 7.1005\ttraining's l2: 50.4171\tvalid_1's rmse: 8.16251\tvalid_1's l2: 66.6265\n",
      "[300]\ttraining's rmse: 6.60732\ttraining's l2: 43.6566\tvalid_1's rmse: 8.10615\tvalid_1's l2: 65.7097\n",
      "[400]\ttraining's rmse: 6.19982\ttraining's l2: 38.4378\tvalid_1's rmse: 8.09366\tvalid_1's l2: 65.5074\n",
      "[500]\ttraining's rmse: 5.85315\ttraining's l2: 34.2593\tvalid_1's rmse: 8.08948\tvalid_1's l2: 65.4396\n",
      "[600]\ttraining's rmse: 5.54413\ttraining's l2: 30.7373\tvalid_1's rmse: 8.08449\tvalid_1's l2: 65.359\n",
      "[700]\ttraining's rmse: 5.26683\ttraining's l2: 27.7395\tvalid_1's rmse: 8.09319\tvalid_1's l2: 65.4997\n",
      "Early stopping, best iteration is:\n",
      "[600]\ttraining's rmse: 5.54413\ttraining's l2: 30.7373\tvalid_1's rmse: 8.08449\tvalid_1's l2: 65.359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 8.084   \u001b[0m | \u001b[0m 0.7675  \u001b[0m | \u001b[0m 132.0   \u001b[0m | \u001b[0m 14.3    \u001b[0m | \u001b[0m 40.39   \u001b[0m | \u001b[0m 44.76   \u001b[0m | \u001b[0m 35.85   \u001b[0m | \u001b[0m 33.16   \u001b[0m | \u001b[0m 4.179   \u001b[0m | \u001b[0m 0.9905  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.49633\ttraining's l2: 56.195\tvalid_1's rmse: 8.33383\tvalid_1's l2: 69.4527\n",
      "[200]\ttraining's rmse: 6.64347\ttraining's l2: 44.1357\tvalid_1's rmse: 8.13451\tvalid_1's l2: 66.1703\n",
      "[300]\ttraining's rmse: 6.13538\ttraining's l2: 37.6429\tvalid_1's rmse: 8.09517\tvalid_1's l2: 65.5318\n",
      "[400]\ttraining's rmse: 5.73892\ttraining's l2: 32.9352\tvalid_1's rmse: 8.08305\tvalid_1's l2: 65.3358\n",
      "[500]\ttraining's rmse: 5.41334\ttraining's l2: 29.3042\tvalid_1's rmse: 8.07933\tvalid_1's l2: 65.2756\n",
      "[600]\ttraining's rmse: 5.09909\ttraining's l2: 26.0007\tvalid_1's rmse: 8.07925\tvalid_1's l2: 65.2742\n",
      "Early stopping, best iteration is:\n",
      "[585]\ttraining's rmse: 5.14549\ttraining's l2: 26.476\tvalid_1's rmse: 8.0786\tvalid_1's l2: 65.2637\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 8.079   \u001b[0m | \u001b[0m 0.5909  \u001b[0m | \u001b[0m 151.4   \u001b[0m | \u001b[0m 8.126   \u001b[0m | \u001b[0m 67.71   \u001b[0m | \u001b[0m 12.18   \u001b[0m | \u001b[0m 57.97   \u001b[0m | \u001b[0m 5.113   \u001b[0m | \u001b[0m 2.963   \u001b[0m | \u001b[0m 0.5074  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.95926\ttraining's l2: 63.3497\tvalid_1's rmse: 8.404\tvalid_1's l2: 70.6272\n",
      "[200]\ttraining's rmse: 7.33473\ttraining's l2: 53.7982\tvalid_1's rmse: 8.1728\tvalid_1's l2: 66.7946\n",
      "[300]\ttraining's rmse: 6.92792\ttraining's l2: 47.9961\tvalid_1's rmse: 8.11581\tvalid_1's l2: 65.8664\n",
      "[400]\ttraining's rmse: 6.58714\ttraining's l2: 43.3904\tvalid_1's rmse: 8.09394\tvalid_1's l2: 65.5118\n",
      "[500]\ttraining's rmse: 6.29045\ttraining's l2: 39.5697\tvalid_1's rmse: 8.08509\tvalid_1's l2: 65.3687\n",
      "[600]\ttraining's rmse: 6.02117\ttraining's l2: 36.2545\tvalid_1's rmse: 8.08203\tvalid_1's l2: 65.3192\n",
      "[700]\ttraining's rmse: 5.77916\ttraining's l2: 33.3987\tvalid_1's rmse: 8.08379\tvalid_1's l2: 65.3477\n",
      "Early stopping, best iteration is:\n",
      "[622]\ttraining's rmse: 5.96664\ttraining's l2: 35.6008\tvalid_1's rmse: 8.08049\tvalid_1's l2: 65.2943\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 8.08    \u001b[0m | \u001b[0m 0.9254  \u001b[0m | \u001b[0m 416.7   \u001b[0m | \u001b[0m 10.77   \u001b[0m | \u001b[0m 126.9   \u001b[0m | \u001b[0m 26.11   \u001b[0m | \u001b[0m 29.61   \u001b[0m | \u001b[0m 48.7    \u001b[0m | \u001b[0m 7.307   \u001b[0m | \u001b[0m 0.5611  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.91477\ttraining's l2: 62.6436\tvalid_1's rmse: 8.39603\tvalid_1's l2: 70.4934\n",
      "[200]\ttraining's rmse: 7.26933\ttraining's l2: 52.8431\tvalid_1's rmse: 8.16991\tvalid_1's l2: 66.7475\n",
      "[300]\ttraining's rmse: 6.83945\ttraining's l2: 46.7781\tvalid_1's rmse: 8.11762\tvalid_1's l2: 65.8957\n",
      "[400]\ttraining's rmse: 6.48133\ttraining's l2: 42.0077\tvalid_1's rmse: 8.10043\tvalid_1's l2: 65.617\n",
      "[500]\ttraining's rmse: 6.1712\ttraining's l2: 38.0837\tvalid_1's rmse: 8.09565\tvalid_1's l2: 65.5395\n",
      "[600]\ttraining's rmse: 5.89366\ttraining's l2: 34.7352\tvalid_1's rmse: 8.09497\tvalid_1's l2: 65.5285\n",
      "Early stopping, best iteration is:\n",
      "[525]\ttraining's rmse: 6.09966\ttraining's l2: 37.2059\tvalid_1's rmse: 8.09333\tvalid_1's l2: 65.5019\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 8.093   \u001b[0m | \u001b[0m 0.5141  \u001b[0m | \u001b[0m 254.3   \u001b[0m | \u001b[0m 15.33   \u001b[0m | \u001b[0m 103.2   \u001b[0m | \u001b[0m 46.9    \u001b[0m | \u001b[0m 32.34   \u001b[0m | \u001b[0m 12.22   \u001b[0m | \u001b[0m 9.777   \u001b[0m | \u001b[0m 0.6989  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.86907\ttraining's l2: 61.9223\tvalid_1's rmse: 8.3839\tvalid_1's l2: 70.2898\n",
      "[200]\ttraining's rmse: 7.19087\ttraining's l2: 51.7086\tvalid_1's rmse: 8.15399\tvalid_1's l2: 66.4876\n",
      "[300]\ttraining's rmse: 6.73715\ttraining's l2: 45.3892\tvalid_1's rmse: 8.10052\tvalid_1's l2: 65.6184\n",
      "[400]\ttraining's rmse: 6.35967\ttraining's l2: 40.4454\tvalid_1's rmse: 8.08496\tvalid_1's l2: 65.3667\n",
      "[500]\ttraining's rmse: 6.0316\ttraining's l2: 36.3802\tvalid_1's rmse: 8.0841\tvalid_1's l2: 65.3527\n",
      "[600]\ttraining's rmse: 5.73789\ttraining's l2: 32.9234\tvalid_1's rmse: 8.08429\tvalid_1's l2: 65.3558\n",
      "Early stopping, best iteration is:\n",
      "[526]\ttraining's rmse: 5.95256\ttraining's l2: 35.433\tvalid_1's rmse: 8.08245\tvalid_1's l2: 65.326\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 8.082   \u001b[0m | \u001b[0m 0.5715  \u001b[0m | \u001b[0m 420.3   \u001b[0m | \u001b[0m 15.04   \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 3.524   \u001b[0m | \u001b[0m 35.44   \u001b[0m | \u001b[0m 22.55   \u001b[0m | \u001b[0m 3.946   \u001b[0m | \u001b[0m 0.9637  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.7629\ttraining's l2: 60.2626\tvalid_1's rmse: 8.37255\tvalid_1's l2: 70.0996\n",
      "[200]\ttraining's rmse: 7.01687\ttraining's l2: 49.2364\tvalid_1's rmse: 8.15338\tvalid_1's l2: 66.4776\n",
      "[300]\ttraining's rmse: 6.50329\ttraining's l2: 42.2928\tvalid_1's rmse: 8.09945\tvalid_1's l2: 65.6011\n",
      "[400]\ttraining's rmse: 6.07709\ttraining's l2: 36.931\tvalid_1's rmse: 8.0845\tvalid_1's l2: 65.3591\n",
      "[500]\ttraining's rmse: 5.7085\ttraining's l2: 32.587\tvalid_1's rmse: 8.08306\tvalid_1's l2: 65.3359\n",
      "[600]\ttraining's rmse: 5.3895\ttraining's l2: 29.0467\tvalid_1's rmse: 8.08063\tvalid_1's l2: 65.2966\n",
      "[700]\ttraining's rmse: 5.09949\ttraining's l2: 26.0048\tvalid_1's rmse: 8.07862\tvalid_1's l2: 65.2641\n",
      "Early stopping, best iteration is:\n",
      "[673]\ttraining's rmse: 5.17402\ttraining's l2: 26.7705\tvalid_1's rmse: 8.07727\tvalid_1's l2: 65.2422\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 8.077   \u001b[0m | \u001b[0m 0.5793  \u001b[0m | \u001b[0m 255.2   \u001b[0m | \u001b[0m 13.55   \u001b[0m | \u001b[0m 12.51   \u001b[0m | \u001b[0m 29.43   \u001b[0m | \u001b[0m 39.82   \u001b[0m | \u001b[0m 33.96   \u001b[0m | \u001b[0m 5.653   \u001b[0m | \u001b[0m 0.8581  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.66582\ttraining's l2: 58.7648\tvalid_1's rmse: 8.36224\tvalid_1's l2: 69.9271\n",
      "[200]\ttraining's rmse: 6.87519\ttraining's l2: 47.2682\tvalid_1's rmse: 8.15003\tvalid_1's l2: 66.423\n",
      "[300]\ttraining's rmse: 6.33154\ttraining's l2: 40.0884\tvalid_1's rmse: 8.10398\tvalid_1's l2: 65.6745\n",
      "[400]\ttraining's rmse: 5.88858\ttraining's l2: 34.6754\tvalid_1's rmse: 8.0872\tvalid_1's l2: 65.4028\n",
      "[500]\ttraining's rmse: 5.50417\ttraining's l2: 30.2959\tvalid_1's rmse: 8.08455\tvalid_1's l2: 65.3599\n",
      "[600]\ttraining's rmse: 5.16544\ttraining's l2: 26.6817\tvalid_1's rmse: 8.08681\tvalid_1's l2: 65.3965\n",
      "Early stopping, best iteration is:\n",
      "[539]\ttraining's rmse: 5.36864\ttraining's l2: 28.8223\tvalid_1's rmse: 8.08299\tvalid_1's l2: 65.3348\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 8.083   \u001b[0m | \u001b[0m 0.6464  \u001b[0m | \u001b[0m 212.8   \u001b[0m | \u001b[0m 9.076   \u001b[0m | \u001b[0m 32.07   \u001b[0m | \u001b[0m 22.8    \u001b[0m | \u001b[0m 47.68   \u001b[0m | \u001b[0m 48.94   \u001b[0m | \u001b[0m 5.883   \u001b[0m | \u001b[0m 0.8768  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.61501\ttraining's l2: 57.9883\tvalid_1's rmse: 8.34598\tvalid_1's l2: 69.6554\n",
      "[200]\ttraining's rmse: 6.76891\ttraining's l2: 45.8181\tvalid_1's rmse: 8.13377\tvalid_1's l2: 66.1583\n",
      "[300]\ttraining's rmse: 6.17797\ttraining's l2: 38.1673\tvalid_1's rmse: 8.09346\tvalid_1's l2: 65.5042\n",
      "[400]\ttraining's rmse: 5.68695\ttraining's l2: 32.3414\tvalid_1's rmse: 8.08256\tvalid_1's l2: 65.3278\n",
      "[500]\ttraining's rmse: 5.26454\ttraining's l2: 27.7153\tvalid_1's rmse: 8.08209\tvalid_1's l2: 65.3201\n",
      "[600]\ttraining's rmse: 4.89167\ttraining's l2: 23.9284\tvalid_1's rmse: 8.08164\tvalid_1's l2: 65.3129\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttraining's rmse: 5.20835\ttraining's l2: 27.1269\tvalid_1's rmse: 8.07999\tvalid_1's l2: 65.2863\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 8.08    \u001b[0m | \u001b[0m 0.6659  \u001b[0m | \u001b[0m 318.9   \u001b[0m | \u001b[0m 14.7    \u001b[0m | \u001b[0m 89.29   \u001b[0m | \u001b[0m 7.679   \u001b[0m | \u001b[0m 54.4    \u001b[0m | \u001b[0m 41.98   \u001b[0m | \u001b[0m 4.397   \u001b[0m | \u001b[0m 0.6464  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.49028\ttraining's l2: 56.1044\tvalid_1's rmse: 8.35794\tvalid_1's l2: 69.8551\n",
      "[200]\ttraining's rmse: 6.58165\ttraining's l2: 43.3181\tvalid_1's rmse: 8.1527\tvalid_1's l2: 66.4665\n",
      "[300]\ttraining's rmse: 5.95434\ttraining's l2: 35.4542\tvalid_1's rmse: 8.10968\tvalid_1's l2: 65.767\n",
      "[400]\ttraining's rmse: 5.44038\ttraining's l2: 29.5977\tvalid_1's rmse: 8.09749\tvalid_1's l2: 65.5693\n",
      "[500]\ttraining's rmse: 5.00854\ttraining's l2: 25.0855\tvalid_1's rmse: 8.10028\tvalid_1's l2: 65.6146\n",
      "Early stopping, best iteration is:\n",
      "[409]\ttraining's rmse: 5.39847\ttraining's l2: 29.1435\tvalid_1's rmse: 8.0967\tvalid_1's l2: 65.5566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 8.097   \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 9.587   \u001b[0m | \u001b[0m 45.26   \u001b[0m | \u001b[0m 38.36   \u001b[0m | \u001b[0m 58.79   \u001b[0m | \u001b[0m 48.62   \u001b[0m | \u001b[0m 2.709   \u001b[0m | \u001b[0m 0.9832  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.89274\ttraining's l2: 62.2953\tvalid_1's rmse: 8.39942\tvalid_1's l2: 70.5502\n",
      "[200]\ttraining's rmse: 7.22659\ttraining's l2: 52.2237\tvalid_1's rmse: 8.17713\tvalid_1's l2: 66.8654\n",
      "[300]\ttraining's rmse: 6.78659\ttraining's l2: 46.0579\tvalid_1's rmse: 8.11826\tvalid_1's l2: 65.9061\n",
      "[400]\ttraining's rmse: 6.41864\ttraining's l2: 41.1989\tvalid_1's rmse: 8.09936\tvalid_1's l2: 65.5996\n",
      "[500]\ttraining's rmse: 6.10856\ttraining's l2: 37.3145\tvalid_1's rmse: 8.0964\tvalid_1's l2: 65.5517\n",
      "[600]\ttraining's rmse: 5.83138\ttraining's l2: 34.005\tvalid_1's rmse: 8.0942\tvalid_1's l2: 65.516\n",
      "[700]\ttraining's rmse: 5.58117\ttraining's l2: 31.1495\tvalid_1's rmse: 8.09392\tvalid_1's l2: 65.5116\n",
      "Early stopping, best iteration is:\n",
      "[653]\ttraining's rmse: 5.69691\ttraining's l2: 32.4548\tvalid_1's rmse: 8.09172\tvalid_1's l2: 65.4759\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 8.092   \u001b[0m | \u001b[0m 0.9319  \u001b[0m | \u001b[0m 265.1   \u001b[0m | \u001b[0m 8.635   \u001b[0m | \u001b[0m 55.92   \u001b[0m | \u001b[0m 4.254   \u001b[0m | \u001b[0m 32.04   \u001b[0m | \u001b[0m 37.83   \u001b[0m | \u001b[0m 6.108   \u001b[0m | \u001b[0m 0.9044  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.62754\ttraining's l2: 58.1794\tvalid_1's rmse: 8.37445\tvalid_1's l2: 70.1315\n",
      "[200]\ttraining's rmse: 6.78782\ttraining's l2: 46.0746\tvalid_1's rmse: 8.16692\tvalid_1's l2: 66.6986\n",
      "[300]\ttraining's rmse: 6.20971\ttraining's l2: 38.5605\tvalid_1's rmse: 8.11499\tvalid_1's l2: 65.853\n",
      "[400]\ttraining's rmse: 5.7343\ttraining's l2: 32.8822\tvalid_1's rmse: 8.09798\tvalid_1's l2: 65.5773\n",
      "[500]\ttraining's rmse: 5.33156\ttraining's l2: 28.4255\tvalid_1's rmse: 8.09612\tvalid_1's l2: 65.5471\n",
      "Early stopping, best iteration is:\n",
      "[467]\ttraining's rmse: 5.46094\ttraining's l2: 29.8219\tvalid_1's rmse: 8.09419\tvalid_1's l2: 65.516\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 8.094   \u001b[0m | \u001b[0m 0.8401  \u001b[0m | \u001b[0m 218.0   \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 18.53   \u001b[0m | \u001b[0m 44.08   \u001b[0m | \u001b[0m 48.28   \u001b[0m | \u001b[0m 31.39   \u001b[0m | \u001b[0m 5.161   \u001b[0m | \u001b[0m 0.8321  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.49539\ttraining's l2: 56.1808\tvalid_1's rmse: 8.34833\tvalid_1's l2: 69.6946\n",
      "[200]\ttraining's rmse: 6.58229\ttraining's l2: 43.3265\tvalid_1's rmse: 8.14541\tvalid_1's l2: 66.3478\n",
      "[300]\ttraining's rmse: 5.95195\ttraining's l2: 35.4257\tvalid_1's rmse: 8.10723\tvalid_1's l2: 65.7272\n",
      "[400]\ttraining's rmse: 5.44394\ttraining's l2: 29.6364\tvalid_1's rmse: 8.09228\tvalid_1's l2: 65.4849\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's rmse: 5.58223\ttraining's l2: 31.1612\tvalid_1's rmse: 8.08989\tvalid_1's l2: 65.4462\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 8.09    \u001b[0m | \u001b[0m 0.7178  \u001b[0m | \u001b[0m 174.7   \u001b[0m | \u001b[0m 10.29   \u001b[0m | \u001b[0m 36.12   \u001b[0m | \u001b[0m 11.2    \u001b[0m | \u001b[0m 59.42   \u001b[0m | \u001b[0m 23.53   \u001b[0m | \u001b[0m 9.78    \u001b[0m | \u001b[0m 0.5628  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.99926\ttraining's l2: 63.9881\tvalid_1's rmse: 8.40986\tvalid_1's l2: 70.7258\n",
      "[200]\ttraining's rmse: 7.39629\ttraining's l2: 54.7051\tvalid_1's rmse: 8.17194\tvalid_1's l2: 66.7806\n",
      "[300]\ttraining's rmse: 7.00896\ttraining's l2: 49.1256\tvalid_1's rmse: 8.11049\tvalid_1's l2: 65.7801\n",
      "[400]\ttraining's rmse: 6.68632\ttraining's l2: 44.7068\tvalid_1's rmse: 8.08513\tvalid_1's l2: 65.3694\n",
      "[500]\ttraining's rmse: 6.40424\ttraining's l2: 41.0143\tvalid_1's rmse: 8.07555\tvalid_1's l2: 65.2145\n",
      "[600]\ttraining's rmse: 6.15076\ttraining's l2: 37.8318\tvalid_1's rmse: 8.07153\tvalid_1's l2: 65.1496\n",
      "[700]\ttraining's rmse: 5.91675\ttraining's l2: 35.0079\tvalid_1's rmse: 8.07506\tvalid_1's l2: 65.2066\n",
      "Early stopping, best iteration is:\n",
      "[631]\ttraining's rmse: 6.07735\ttraining's l2: 36.9342\tvalid_1's rmse: 8.07137\tvalid_1's l2: 65.1471\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 8.071   \u001b[0m | \u001b[0m 0.8023  \u001b[0m | \u001b[0m 372.3   \u001b[0m | \u001b[0m 13.22   \u001b[0m | \u001b[0m 189.7   \u001b[0m | \u001b[0m 29.8    \u001b[0m | \u001b[0m 29.28   \u001b[0m | \u001b[0m 46.45   \u001b[0m | \u001b[0m 6.261   \u001b[0m | \u001b[0m 0.5583  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.71681\ttraining's l2: 59.5492\tvalid_1's rmse: 8.34735\tvalid_1's l2: 69.6783\n",
      "[200]\ttraining's rmse: 6.94374\ttraining's l2: 48.2156\tvalid_1's rmse: 8.13988\tvalid_1's l2: 66.2576\n",
      "[300]\ttraining's rmse: 6.40907\ttraining's l2: 41.0762\tvalid_1's rmse: 8.09115\tvalid_1's l2: 65.4668\n",
      "[400]\ttraining's rmse: 5.96686\ttraining's l2: 35.6034\tvalid_1's rmse: 8.07579\tvalid_1's l2: 65.2185\n",
      "[500]\ttraining's rmse: 5.58957\ttraining's l2: 31.2432\tvalid_1's rmse: 8.06995\tvalid_1's l2: 65.1242\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's rmse: 5.61254\ttraining's l2: 31.5006\tvalid_1's rmse: 8.06879\tvalid_1's l2: 65.1054\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 8.069   \u001b[0m | \u001b[0m 0.6121  \u001b[0m | \u001b[0m 56.01   \u001b[0m | \u001b[0m 13.32   \u001b[0m | \u001b[0m 86.02   \u001b[0m | \u001b[0m 2.535   \u001b[0m | \u001b[0m 43.43   \u001b[0m | \u001b[0m 12.8    \u001b[0m | \u001b[0m 3.448   \u001b[0m | \u001b[0m 0.5243  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.69169\ttraining's l2: 59.1621\tvalid_1's rmse: 8.34966\tvalid_1's l2: 69.7168\n",
      "[200]\ttraining's rmse: 6.906\ttraining's l2: 47.6929\tvalid_1's rmse: 8.1362\tvalid_1's l2: 66.1978\n",
      "[300]\ttraining's rmse: 6.35835\ttraining's l2: 40.4286\tvalid_1's rmse: 8.09507\tvalid_1's l2: 65.5301\n",
      "[400]\ttraining's rmse: 5.90328\ttraining's l2: 34.8487\tvalid_1's rmse: 8.08148\tvalid_1's l2: 65.3103\n",
      "[500]\ttraining's rmse: 5.51108\ttraining's l2: 30.372\tvalid_1's rmse: 8.07498\tvalid_1's l2: 65.2053\n",
      "Early stopping, best iteration is:\n",
      "[488]\ttraining's rmse: 5.55728\ttraining's l2: 30.8834\tvalid_1's rmse: 8.07309\tvalid_1's l2: 65.1747\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 8.073   \u001b[0m | \u001b[0m 0.6732  \u001b[0m | \u001b[0m 294.8   \u001b[0m | \u001b[0m 15.04   \u001b[0m | \u001b[0m 117.9   \u001b[0m | \u001b[0m 26.82   \u001b[0m | \u001b[0m 46.07   \u001b[0m | \u001b[0m 13.76   \u001b[0m | \u001b[0m 3.302   \u001b[0m | \u001b[0m 0.5363  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.78854\ttraining's l2: 60.6614\tvalid_1's rmse: 8.37264\tvalid_1's l2: 70.101\n",
      "[200]\ttraining's rmse: 7.04369\ttraining's l2: 49.6136\tvalid_1's rmse: 8.15457\tvalid_1's l2: 66.497\n",
      "[300]\ttraining's rmse: 6.53588\ttraining's l2: 42.7177\tvalid_1's rmse: 8.10879\tvalid_1's l2: 65.7524\n",
      "[400]\ttraining's rmse: 6.11579\ttraining's l2: 37.4029\tvalid_1's rmse: 8.09437\tvalid_1's l2: 65.5188\n",
      "[500]\ttraining's rmse: 5.75676\ttraining's l2: 33.1403\tvalid_1's rmse: 8.09133\tvalid_1's l2: 65.4697\n",
      "Early stopping, best iteration is:\n",
      "[489]\ttraining's rmse: 5.79331\ttraining's l2: 33.5625\tvalid_1's rmse: 8.08935\tvalid_1's l2: 65.4376\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 8.089   \u001b[0m | \u001b[0m 0.819   \u001b[0m | \u001b[0m 33.68   \u001b[0m | \u001b[0m 14.31   \u001b[0m | \u001b[0m 81.77   \u001b[0m | \u001b[0m 30.16   \u001b[0m | \u001b[0m 39.27   \u001b[0m | \u001b[0m 19.79   \u001b[0m | \u001b[0m 7.493   \u001b[0m | \u001b[0m 0.6173  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.66871\ttraining's l2: 58.8091\tvalid_1's rmse: 8.35895\tvalid_1's l2: 69.8721\n",
      "[200]\ttraining's rmse: 6.86199\ttraining's l2: 47.0869\tvalid_1's rmse: 8.1556\tvalid_1's l2: 66.5138\n",
      "[300]\ttraining's rmse: 6.30111\ttraining's l2: 39.704\tvalid_1's rmse: 8.10882\tvalid_1's l2: 65.753\n",
      "[400]\ttraining's rmse: 5.83268\ttraining's l2: 34.0201\tvalid_1's rmse: 8.09153\tvalid_1's l2: 65.4729\n",
      "[500]\ttraining's rmse: 5.43129\ttraining's l2: 29.4989\tvalid_1's rmse: 8.08886\tvalid_1's l2: 65.4296\n",
      "[600]\ttraining's rmse: 5.08199\ttraining's l2: 25.8266\tvalid_1's rmse: 8.08755\tvalid_1's l2: 65.4084\n",
      "Early stopping, best iteration is:\n",
      "[554]\ttraining's rmse: 5.23675\ttraining's l2: 27.4236\tvalid_1's rmse: 8.08606\tvalid_1's l2: 65.3843\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 8.086   \u001b[0m | \u001b[0m 0.7314  \u001b[0m | \u001b[0m 322.5   \u001b[0m | \u001b[0m 14.67   \u001b[0m | \u001b[0m 29.11   \u001b[0m | \u001b[0m 46.03   \u001b[0m | \u001b[0m 47.01   \u001b[0m | \u001b[0m 44.83   \u001b[0m | \u001b[0m 5.787   \u001b[0m | \u001b[0m 0.6073  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.6413\ttraining's l2: 58.3895\tvalid_1's rmse: 8.36942\tvalid_1's l2: 70.0472\n",
      "[200]\ttraining's rmse: 6.80483\ttraining's l2: 46.3058\tvalid_1's rmse: 8.16549\tvalid_1's l2: 66.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttraining's rmse: 6.21949\ttraining's l2: 38.6821\tvalid_1's rmse: 8.11844\tvalid_1's l2: 65.909\n",
      "[400]\ttraining's rmse: 5.73966\ttraining's l2: 32.9437\tvalid_1's rmse: 8.11391\tvalid_1's l2: 65.8356\n",
      "[500]\ttraining's rmse: 5.33422\ttraining's l2: 28.4539\tvalid_1's rmse: 8.10836\tvalid_1's l2: 65.7455\n",
      "[600]\ttraining's rmse: 4.9779\ttraining's l2: 24.7794\tvalid_1's rmse: 8.1077\tvalid_1's l2: 65.7348\n",
      "Early stopping, best iteration is:\n",
      "[569]\ttraining's rmse: 5.08338\ttraining's l2: 25.8408\tvalid_1's rmse: 8.1058\tvalid_1's l2: 65.704\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m 8.106   \u001b[0m | \u001b[95m 0.9712  \u001b[0m | \u001b[95m 489.0   \u001b[0m | \u001b[95m 15.25   \u001b[0m | \u001b[95m 49.44   \u001b[0m | \u001b[95m 26.52   \u001b[0m | \u001b[95m 47.24   \u001b[0m | \u001b[95m 39.95   \u001b[0m | \u001b[95m 2.888   \u001b[0m | \u001b[95m 0.8058  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.98011\ttraining's l2: 63.6822\tvalid_1's rmse: 8.41014\tvalid_1's l2: 70.7304\n",
      "[200]\ttraining's rmse: 7.36094\ttraining's l2: 54.1834\tvalid_1's rmse: 8.17986\tvalid_1's l2: 66.9101\n",
      "[300]\ttraining's rmse: 6.96725\ttraining's l2: 48.5426\tvalid_1's rmse: 8.11708\tvalid_1's l2: 65.887\n",
      "[400]\ttraining's rmse: 6.63843\ttraining's l2: 44.0688\tvalid_1's rmse: 8.09744\tvalid_1's l2: 65.5685\n",
      "[500]\ttraining's rmse: 6.35289\ttraining's l2: 40.3592\tvalid_1's rmse: 8.08728\tvalid_1's l2: 65.404\n",
      "[600]\ttraining's rmse: 6.09545\ttraining's l2: 37.1545\tvalid_1's rmse: 8.08447\tvalid_1's l2: 65.3586\n",
      "[700]\ttraining's rmse: 5.8613\ttraining's l2: 34.3548\tvalid_1's rmse: 8.08365\tvalid_1's l2: 65.3455\n",
      "Early stopping, best iteration is:\n",
      "[666]\ttraining's rmse: 5.93854\ttraining's l2: 35.2663\tvalid_1's rmse: 8.08235\tvalid_1's l2: 65.3244\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 8.082   \u001b[0m | \u001b[0m 0.7876  \u001b[0m | \u001b[0m 240.7   \u001b[0m | \u001b[0m 13.27   \u001b[0m | \u001b[0m 133.4   \u001b[0m | \u001b[0m 33.93   \u001b[0m | \u001b[0m 28.29   \u001b[0m | \u001b[0m 39.58   \u001b[0m | \u001b[0m 1.11    \u001b[0m | \u001b[0m 0.7515  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.80777\ttraining's l2: 60.9613\tvalid_1's rmse: 8.37629\tvalid_1's l2: 70.1623\n",
      "[200]\ttraining's rmse: 7.09923\ttraining's l2: 50.3991\tvalid_1's rmse: 8.15423\tvalid_1's l2: 66.4915\n",
      "[300]\ttraining's rmse: 6.6167\ttraining's l2: 43.7807\tvalid_1's rmse: 8.10302\tvalid_1's l2: 65.659\n",
      "[400]\ttraining's rmse: 6.21397\ttraining's l2: 38.6134\tvalid_1's rmse: 8.08644\tvalid_1's l2: 65.3904\n",
      "[500]\ttraining's rmse: 5.86248\ttraining's l2: 34.3687\tvalid_1's rmse: 8.08418\tvalid_1's l2: 65.354\n",
      "Early stopping, best iteration is:\n",
      "[465]\ttraining's rmse: 5.97928\ttraining's l2: 35.7518\tvalid_1's rmse: 8.08256\tvalid_1's l2: 65.3278\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 8.083   \u001b[0m | \u001b[0m 0.5948  \u001b[0m | \u001b[0m 65.55   \u001b[0m | \u001b[0m 13.15   \u001b[0m | \u001b[0m 102.1   \u001b[0m | \u001b[0m 8.454   \u001b[0m | \u001b[0m 37.71   \u001b[0m | \u001b[0m 8.496   \u001b[0m | \u001b[0m 8.393   \u001b[0m | \u001b[0m 0.7137  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.76407\ttraining's l2: 60.2809\tvalid_1's rmse: 8.36793\tvalid_1's l2: 70.0222\n",
      "[200]\ttraining's rmse: 7.01759\ttraining's l2: 49.2466\tvalid_1's rmse: 8.15003\tvalid_1's l2: 66.423\n",
      "[300]\ttraining's rmse: 6.50741\ttraining's l2: 42.3464\tvalid_1's rmse: 8.10113\tvalid_1's l2: 65.6282\n",
      "[400]\ttraining's rmse: 6.0883\ttraining's l2: 37.0674\tvalid_1's rmse: 8.08928\tvalid_1's l2: 65.4364\n",
      "[500]\ttraining's rmse: 5.71968\ttraining's l2: 32.7148\tvalid_1's rmse: 8.08362\tvalid_1's l2: 65.3448\n",
      "[600]\ttraining's rmse: 5.39208\ttraining's l2: 29.0745\tvalid_1's rmse: 8.08634\tvalid_1's l2: 65.3889\n",
      "Early stopping, best iteration is:\n",
      "[510]\ttraining's rmse: 5.68409\ttraining's l2: 32.3089\tvalid_1's rmse: 8.08229\tvalid_1's l2: 65.3234\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 8.082   \u001b[0m | \u001b[0m 0.5543  \u001b[0m | \u001b[0m 266.6   \u001b[0m | \u001b[0m 12.65   \u001b[0m | \u001b[0m 147.4   \u001b[0m | \u001b[0m 13.2    \u001b[0m | \u001b[0m 45.91   \u001b[0m | \u001b[0m 23.86   \u001b[0m | \u001b[0m 8.469   \u001b[0m | \u001b[0m 0.9726  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.73412\ttraining's l2: 59.8166\tvalid_1's rmse: 8.36686\tvalid_1's l2: 70.0044\n",
      "[200]\ttraining's rmse: 6.96772\ttraining's l2: 48.5491\tvalid_1's rmse: 8.155\tvalid_1's l2: 66.5041\n",
      "[300]\ttraining's rmse: 6.44717\ttraining's l2: 41.5661\tvalid_1's rmse: 8.10959\tvalid_1's l2: 65.7654\n",
      "[400]\ttraining's rmse: 6.02386\ttraining's l2: 36.2869\tvalid_1's rmse: 8.09748\tvalid_1's l2: 65.5691\n",
      "[500]\ttraining's rmse: 5.66437\ttraining's l2: 32.085\tvalid_1's rmse: 8.09018\tvalid_1's l2: 65.451\n",
      "Early stopping, best iteration is:\n",
      "[465]\ttraining's rmse: 5.78644\ttraining's l2: 33.4829\tvalid_1's rmse: 8.08791\tvalid_1's l2: 65.4143\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 8.088   \u001b[0m | \u001b[0m 0.6567  \u001b[0m | \u001b[0m 433.3   \u001b[0m | \u001b[0m 9.49    \u001b[0m | \u001b[0m 18.65   \u001b[0m | \u001b[0m 34.59   \u001b[0m | \u001b[0m 40.31   \u001b[0m | \u001b[0m 9.121   \u001b[0m | \u001b[0m 5.538   \u001b[0m | \u001b[0m 0.5815  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.95043\ttraining's l2: 63.2093\tvalid_1's rmse: 8.39618\tvalid_1's l2: 70.4958\n",
      "[200]\ttraining's rmse: 7.33118\ttraining's l2: 53.7462\tvalid_1's rmse: 8.16726\tvalid_1's l2: 66.7041\n",
      "[300]\ttraining's rmse: 6.93132\ttraining's l2: 48.0432\tvalid_1's rmse: 8.10842\tvalid_1's l2: 65.7465\n",
      "[400]\ttraining's rmse: 6.59924\ttraining's l2: 43.55\tvalid_1's rmse: 8.08704\tvalid_1's l2: 65.4003\n",
      "[500]\ttraining's rmse: 6.31176\ttraining's l2: 39.8384\tvalid_1's rmse: 8.08338\tvalid_1's l2: 65.341\n",
      "Early stopping, best iteration is:\n",
      "[473]\ttraining's rmse: 6.38521\ttraining's l2: 40.771\tvalid_1's rmse: 8.08093\tvalid_1's l2: 65.3015\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 8.081   \u001b[0m | \u001b[0m 0.6299  \u001b[0m | \u001b[0m 460.8   \u001b[0m | \u001b[0m 9.51    \u001b[0m | \u001b[0m 107.5   \u001b[0m | \u001b[0m 27.24   \u001b[0m | \u001b[0m 29.0    \u001b[0m | \u001b[0m 36.78   \u001b[0m | \u001b[0m 0.7092  \u001b[0m | \u001b[0m 0.9752  \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(f=lgb_rmse_eval, pbounds=bayesian_params, random_state=1000)\n",
    "lgbBO.maximize(init_points=5, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 8.08803404194438,\n",
       "  'params': {'colsample_bytree': 0.8267947927323047,\n",
       "   'max_bin': 66.35340213095881,\n",
       "   'max_depth': 15.602262914792195,\n",
       "   'min_child_samples': 101.61636627131966,\n",
       "   'min_child_weight': 43.75125222391973,\n",
       "   'num_leaves': 32.4933072369088,\n",
       "   'reg_alpha': 2.045074142206765,\n",
       "   'reg_lambda': 3.9725474189957124,\n",
       "   'subsample': 0.61656609867419}},\n",
       " {'target': 8.098504692861185,\n",
       "  'params': {'colsample_bytree': 0.9208703621265308,\n",
       "   'max_bin': 111.47034874950597,\n",
       "   'max_depth': 13.93975626865927,\n",
       "   'min_child_samples': 84.50928428367985,\n",
       "   'min_child_weight': 9.930569477666833,\n",
       "   'num_leaves': 53.7415765836856,\n",
       "   'reg_alpha': 3.488408227688028,\n",
       "   'reg_lambda': 8.853486706603126,\n",
       "   'subsample': 0.9763221996107709}},\n",
       " {'target': 8.091588946510427,\n",
       "  'params': {'colsample_bytree': 0.9655717173387555,\n",
       "   'max_bin': 213.56116699200484,\n",
       "   'max_depth': 8.23185327509497,\n",
       "   'min_child_samples': 196.58522207365755,\n",
       "   'min_child_weight': 17.64224649812914,\n",
       "   'num_leaves': 52.26748775555215,\n",
       "   'reg_alpha': 18.100234609702014,\n",
       "   'reg_lambda': 0.35202387361566295,\n",
       "   'subsample': 0.9275291266202039}},\n",
       " {'target': 8.067112850054471,\n",
       "  'params': {'colsample_bytree': 0.8286267540702462,\n",
       "   'max_bin': 385.1846671311669,\n",
       "   'max_depth': 12.432697904035154,\n",
       "   'min_child_samples': 178.16765795601393,\n",
       "   'min_child_weight': 45.305683154470756,\n",
       "   'num_leaves': 24.416868022358166,\n",
       "   'reg_alpha': 3.737091239759974,\n",
       "   'reg_lambda': 2.447047468388093,\n",
       "   'subsample': 0.5666523762257424}},\n",
       " {'target': 8.10094979308099,\n",
       "  'params': {'colsample_bytree': 0.8489625502048597,\n",
       "   'max_bin': 205.1203929277082,\n",
       "   'max_depth': 15.064977531233142,\n",
       "   'min_child_samples': 44.39142695200357,\n",
       "   'min_child_weight': 22.19245941780866,\n",
       "   'num_leaves': 24.725728110186907,\n",
       "   'reg_alpha': 34.57497870582523,\n",
       "   'reg_lambda': 4.697436829706333,\n",
       "   'subsample': 0.5641110948268239}},\n",
       " {'target': 8.101999171451924,\n",
       "  'params': {'colsample_bytree': 0.8498121404908763,\n",
       "   'max_bin': 125.89765676034936,\n",
       "   'max_depth': 14.371988730655135,\n",
       "   'min_child_samples': 10.636912535805052,\n",
       "   'min_child_weight': 6.904405871769717,\n",
       "   'num_leaves': 39.4005053482483,\n",
       "   'reg_alpha': 41.10384736736786,\n",
       "   'reg_lambda': 7.4478867720252495,\n",
       "   'subsample': 0.5556540082998992}},\n",
       " {'target': 8.074355136069242,\n",
       "  'params': {'colsample_bytree': 0.6164036678268915,\n",
       "   'max_bin': 196.70876574127576,\n",
       "   'max_depth': 13.94258671515849,\n",
       "   'min_child_samples': 40.918893780211235,\n",
       "   'min_child_weight': 17.823696879157698,\n",
       "   'num_leaves': 27.717336993922093,\n",
       "   'reg_alpha': 37.328820883580114,\n",
       "   'reg_lambda': 9.547534827759183,\n",
       "   'subsample': 0.7087766229313908}},\n",
       " {'target': 8.084489916790085,\n",
       "  'params': {'colsample_bytree': 0.7675419859658956,\n",
       "   'max_bin': 132.0199627366569,\n",
       "   'max_depth': 14.298915241781739,\n",
       "   'min_child_samples': 40.3924686618707,\n",
       "   'min_child_weight': 44.75925548935725,\n",
       "   'num_leaves': 35.85435623811703,\n",
       "   'reg_alpha': 33.161736698845125,\n",
       "   'reg_lambda': 4.179346930104301,\n",
       "   'subsample': 0.9904558712794339}},\n",
       " {'target': 8.078596851907553,\n",
       "  'params': {'colsample_bytree': 0.5909121889605802,\n",
       "   'max_bin': 151.4451283058841,\n",
       "   'max_depth': 8.12570510974261,\n",
       "   'min_child_samples': 67.70982537785662,\n",
       "   'min_child_weight': 12.179556446382666,\n",
       "   'num_leaves': 57.97492807929662,\n",
       "   'reg_alpha': 5.11327135472758,\n",
       "   'reg_lambda': 2.9634057731939567,\n",
       "   'subsample': 0.5073924938486567}},\n",
       " {'target': 8.08048899896682,\n",
       "  'params': {'colsample_bytree': 0.9254172005439811,\n",
       "   'max_bin': 416.7208648802382,\n",
       "   'max_depth': 10.76574953773526,\n",
       "   'min_child_samples': 126.91007769267303,\n",
       "   'min_child_weight': 26.11112160742515,\n",
       "   'num_leaves': 29.613949340778454,\n",
       "   'reg_alpha': 48.70271304115722,\n",
       "   'reg_lambda': 7.307286495379972,\n",
       "   'subsample': 0.5610568992324143}},\n",
       " {'target': 8.093326415732328,\n",
       "  'params': {'colsample_bytree': 0.5141043094390911,\n",
       "   'max_bin': 254.3407418874025,\n",
       "   'max_depth': 15.332770159742921,\n",
       "   'min_child_samples': 103.21393354412879,\n",
       "   'min_child_weight': 46.90043392010393,\n",
       "   'num_leaves': 32.33623155988221,\n",
       "   'reg_alpha': 12.21846097676822,\n",
       "   'reg_lambda': 9.777330191074164,\n",
       "   'subsample': 0.6988643735876281}},\n",
       " {'target': 8.082447114986751,\n",
       "  'params': {'colsample_bytree': 0.5714645329357839,\n",
       "   'max_bin': 420.3449035602966,\n",
       "   'max_depth': 15.043879875899249,\n",
       "   'min_child_samples': 124.99880880459827,\n",
       "   'min_child_weight': 3.5244762071364786,\n",
       "   'num_leaves': 35.44420386327446,\n",
       "   'reg_alpha': 22.54827686645599,\n",
       "   'reg_lambda': 3.945893499815971,\n",
       "   'subsample': 0.9636697925128256}},\n",
       " {'target': 8.077266803182038,\n",
       "  'params': {'colsample_bytree': 0.579276254301057,\n",
       "   'max_bin': 255.18517768650602,\n",
       "   'max_depth': 13.550001654403957,\n",
       "   'min_child_samples': 12.505066102402521,\n",
       "   'min_child_weight': 29.42773011515404,\n",
       "   'num_leaves': 39.820389083540235,\n",
       "   'reg_alpha': 33.960034049410424,\n",
       "   'reg_lambda': 5.65260345331489,\n",
       "   'subsample': 0.8581227529538189}},\n",
       " {'target': 8.082993598958197,\n",
       "  'params': {'colsample_bytree': 0.6464371516415328,\n",
       "   'max_bin': 212.7951882260217,\n",
       "   'max_depth': 9.075548813868783,\n",
       "   'min_child_samples': 32.06927980062517,\n",
       "   'min_child_weight': 22.79731494793803,\n",
       "   'num_leaves': 47.67936927865554,\n",
       "   'reg_alpha': 48.938112708376934,\n",
       "   'reg_lambda': 5.882906904286742,\n",
       "   'subsample': 0.8768332875895308}},\n",
       " {'target': 8.079994589026342,\n",
       "  'params': {'colsample_bytree': 0.66587818349067,\n",
       "   'max_bin': 318.85670293585764,\n",
       "   'max_depth': 14.696083656856331,\n",
       "   'min_child_samples': 89.28919948696489,\n",
       "   'min_child_weight': 7.6786440348103335,\n",
       "   'num_leaves': 54.40354378771569,\n",
       "   'reg_alpha': 41.984699177480934,\n",
       "   'reg_lambda': 4.397204203719935,\n",
       "   'subsample': 0.6464426489126807}},\n",
       " {'target': 8.096702383960098,\n",
       "  'params': {'colsample_bytree': 0.8911768943126078,\n",
       "   'max_bin': 226.82335694733166,\n",
       "   'max_depth': 9.58652048927745,\n",
       "   'min_child_samples': 45.26117358341472,\n",
       "   'min_child_weight': 38.35804601447657,\n",
       "   'num_leaves': 58.79479371344334,\n",
       "   'reg_alpha': 48.616770778588304,\n",
       "   'reg_lambda': 2.7092744689647326,\n",
       "   'subsample': 0.9831742043197643}},\n",
       " {'target': 8.09171845239875,\n",
       "  'params': {'colsample_bytree': 0.9318807646090632,\n",
       "   'max_bin': 265.05132830154224,\n",
       "   'max_depth': 8.634833232254739,\n",
       "   'min_child_samples': 55.92302516802116,\n",
       "   'min_child_weight': 4.254390351086849,\n",
       "   'num_leaves': 32.03886139159377,\n",
       "   'reg_alpha': 37.83364228095505,\n",
       "   'reg_lambda': 6.107782167557087,\n",
       "   'subsample': 0.9043824557585871}},\n",
       " {'target': 8.094193322491927,\n",
       "  'params': {'colsample_bytree': 0.8400676823446944,\n",
       "   'max_bin': 218.03126694416892,\n",
       "   'max_depth': 10.828374957564478,\n",
       "   'min_child_samples': 18.53296578103854,\n",
       "   'min_child_weight': 44.08053706636261,\n",
       "   'num_leaves': 48.2828624584605,\n",
       "   'reg_alpha': 31.386355289971423,\n",
       "   'reg_lambda': 5.16125396023365,\n",
       "   'subsample': 0.8320839011056689}},\n",
       " {'target': 8.089885461216065,\n",
       "  'params': {'colsample_bytree': 0.7178480127649094,\n",
       "   'max_bin': 174.6944105583218,\n",
       "   'max_depth': 10.291625851974237,\n",
       "   'min_child_samples': 36.11565074404746,\n",
       "   'min_child_weight': 11.2039887326501,\n",
       "   'num_leaves': 59.424618627709016,\n",
       "   'reg_alpha': 23.53333846758369,\n",
       "   'reg_lambda': 9.779720391939048,\n",
       "   'subsample': 0.562822235810886}},\n",
       " {'target': 8.071373834717788,\n",
       "  'params': {'colsample_bytree': 0.8023267797378124,\n",
       "   'max_bin': 372.2860100070965,\n",
       "   'max_depth': 13.219571070044436,\n",
       "   'min_child_samples': 189.73023488549583,\n",
       "   'min_child_weight': 29.798620436536304,\n",
       "   'num_leaves': 29.276672554717873,\n",
       "   'reg_alpha': 46.44571088697003,\n",
       "   'reg_lambda': 6.261069677877012,\n",
       "   'subsample': 0.5583173239443255}},\n",
       " {'target': 8.068790009999715,\n",
       "  'params': {'colsample_bytree': 0.6120817815183712,\n",
       "   'max_bin': 56.0127776812391,\n",
       "   'max_depth': 13.317409740581677,\n",
       "   'min_child_samples': 86.02488861817797,\n",
       "   'min_child_weight': 2.5349663365974218,\n",
       "   'num_leaves': 43.42729499707772,\n",
       "   'reg_alpha': 12.803004993547578,\n",
       "   'reg_lambda': 3.4478154743231246,\n",
       "   'subsample': 0.5242887645884554}},\n",
       " {'target': 8.073086315835784,\n",
       "  'params': {'colsample_bytree': 0.6732251624430192,\n",
       "   'max_bin': 294.7874607558146,\n",
       "   'max_depth': 15.03557802324086,\n",
       "   'min_child_samples': 117.94571860407643,\n",
       "   'min_child_weight': 26.818627877552583,\n",
       "   'num_leaves': 46.0687492784547,\n",
       "   'reg_alpha': 13.764074735933072,\n",
       "   'reg_lambda': 3.301926621834465,\n",
       "   'subsample': 0.536326218637151}},\n",
       " {'target': 8.08935137382478,\n",
       "  'params': {'colsample_bytree': 0.8190266681526392,\n",
       "   'max_bin': 33.68191484561372,\n",
       "   'max_depth': 14.314513862874048,\n",
       "   'min_child_samples': 81.77454047856418,\n",
       "   'min_child_weight': 30.156229899215923,\n",
       "   'num_leaves': 39.26811414744852,\n",
       "   'reg_alpha': 19.79003701633323,\n",
       "   'reg_lambda': 7.492847592955431,\n",
       "   'subsample': 0.6173422050108449}},\n",
       " {'target': 8.086055804146824,\n",
       "  'params': {'colsample_bytree': 0.7313688492739636,\n",
       "   'max_bin': 322.5275403491443,\n",
       "   'max_depth': 14.673684562656568,\n",
       "   'min_child_samples': 29.114738453076193,\n",
       "   'min_child_weight': 46.030863317824036,\n",
       "   'num_leaves': 47.0053495458919,\n",
       "   'reg_alpha': 44.834265453778464,\n",
       "   'reg_lambda': 5.78718670439186,\n",
       "   'subsample': 0.6073219592234658}},\n",
       " {'target': 8.105798848386325,\n",
       "  'params': {'colsample_bytree': 0.9711690837725098,\n",
       "   'max_bin': 489.01892794129435,\n",
       "   'max_depth': 15.25460690968541,\n",
       "   'min_child_samples': 49.441701762561564,\n",
       "   'min_child_weight': 26.524651705286505,\n",
       "   'num_leaves': 47.23669174089605,\n",
       "   'reg_alpha': 39.94907265936229,\n",
       "   'reg_lambda': 2.888339333527107,\n",
       "   'subsample': 0.8058092781209045}},\n",
       " {'target': 8.082349984423548,\n",
       "  'params': {'colsample_bytree': 0.7875849687909198,\n",
       "   'max_bin': 240.73276061806476,\n",
       "   'max_depth': 13.271184231558605,\n",
       "   'min_child_samples': 133.44942208159318,\n",
       "   'min_child_weight': 33.92950087465731,\n",
       "   'num_leaves': 28.29136702239342,\n",
       "   'reg_alpha': 39.57648860320042,\n",
       "   'reg_lambda': 1.1096346827494934,\n",
       "   'subsample': 0.7514903797268531}},\n",
       " {'target': 8.082564374182928,\n",
       "  'params': {'colsample_bytree': 0.5948136651099992,\n",
       "   'max_bin': 65.54879996738464,\n",
       "   'max_depth': 13.147136974234437,\n",
       "   'min_child_samples': 102.1230118149357,\n",
       "   'min_child_weight': 8.454065086716847,\n",
       "   'num_leaves': 37.71286374411538,\n",
       "   'reg_alpha': 8.495603759047018,\n",
       "   'reg_lambda': 8.3932459613762,\n",
       "   'subsample': 0.7136850800625171}},\n",
       " {'target': 8.082286869888252,\n",
       "  'params': {'colsample_bytree': 0.5543446579385094,\n",
       "   'max_bin': 266.60902033120465,\n",
       "   'max_depth': 12.646496395874314,\n",
       "   'min_child_samples': 147.43609706902322,\n",
       "   'min_child_weight': 13.197385976374632,\n",
       "   'num_leaves': 45.91016035048342,\n",
       "   'reg_alpha': 23.860024134242312,\n",
       "   'reg_lambda': 8.46904710281589,\n",
       "   'subsample': 0.9725842699472822}},\n",
       " {'target': 8.087910424132037,\n",
       "  'params': {'colsample_bytree': 0.6566524967268413,\n",
       "   'max_bin': 433.3057760989586,\n",
       "   'max_depth': 9.490104821932347,\n",
       "   'min_child_samples': 18.647514843077314,\n",
       "   'min_child_weight': 34.592646399786794,\n",
       "   'num_leaves': 40.311724206988984,\n",
       "   'reg_alpha': 9.1208781474659,\n",
       "   'reg_lambda': 5.538063770411299,\n",
       "   'subsample': 0.5814532301163122}},\n",
       " {'target': 8.080934819935246,\n",
       "  'params': {'colsample_bytree': 0.629860556156569,\n",
       "   'max_bin': 460.82332141706166,\n",
       "   'max_depth': 9.509502228957304,\n",
       "   'min_child_samples': 107.51085863131226,\n",
       "   'min_child_weight': 27.23714172016,\n",
       "   'num_leaves': 29.000040122066785,\n",
       "   'reg_alpha': 36.779227385182146,\n",
       "   'reg_lambda': 0.7092204670193314,\n",
       "   'subsample': 0.9752444932102324}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.08803404194438, 8.098504692861185, 8.091588946510427, 8.067112850054471, 8.10094979308099, 8.101999171451924, 8.074355136069242, 8.084489916790085, 8.078596851907553, 8.08048899896682, 8.093326415732328, 8.082447114986751, 8.077266803182038, 8.082993598958197, 8.079994589026342, 8.096702383960098, 8.09171845239875, 8.094193322491927, 8.089885461216065, 8.071373834717788, 8.068790009999715, 8.073086315835784, 8.08935137382478, 8.086055804146824, 8.105798848386325, 8.082349984423548, 8.082564374182928, 8.082286869888252, 8.087910424132037, 8.080934819935246]\n",
      "maximum target index: 3\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmin(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 8.067112850054471, 'params': {'colsample_bytree': 0.8286267540702462, 'max_bin': 385.1846671311669, 'max_depth': 12.432697904035154, 'min_child_samples': 178.16765795601393, 'min_child_weight': 45.305683154470756, 'num_leaves': 24.416868022358166, 'reg_alpha': 3.737091239759974, 'reg_lambda': 2.447047468388093, 'subsample': 0.5666523762257424}}\n"
     ]
    }
   ],
   "source": [
    "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
    "max_dict = lgbBO.res[np.argmin(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = pd.DataFrame(data2[:, 1:])\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "def train_apps_all_with_oof(ftr, target, nfolds=5):\n",
    "    ftr = ftr\n",
    "    target = target\n",
    "\n",
    "    # nfolds 개의 cross validatin fold set을 가지는 KFold 생성 \n",
    "    folds = KFold(n_splits=nfolds, shuffle=True, random_state=0)\n",
    "    \n",
    "    # Out of Folds로 학습된 모델의 validation set을 예측하여 결과 확률을 담을 array 생성.\n",
    "    # validation set가 n_split갯수만큼 있으므로 크기는 ftr_app의 크기가 되어야 함. \n",
    "    oof_preds = np.zeros((ftr.shape[0],))  \n",
    "    \n",
    "    # Ouf of Folds로 학습된 모델의 test dataset을 예측하여 결과 확률을 담을 array 생성. \n",
    "    test_preds = np.zeros(((pd.DataFrame(data_te2[:,1:]).shape[0],)))\n",
    "    \n",
    "    # n_estimators를 4000까지 확대. \n",
    "    clf = LGBMRegressor(\n",
    "                nthread=4,\n",
    "                n_estimators=4000,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=12,\n",
    "                num_leaves=24,\n",
    "                colsample_bytree=0.828,\n",
    "                subsample=0.566,\n",
    "                max_bin= 385,\n",
    "                reg_alpha=3.737,\n",
    "                reg_lambda=2.447,\n",
    "                min_child_weight=45,\n",
    "                min_child_samples=178,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                )\n",
    "\n",
    "    # nfolds 번 cross validation Iteration 반복하면서 OOF 방식으로 학습 및 테스트 데이터 예측\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(ftr)):\n",
    "        print('##### iteration ', fold_idx, ' 시작')\n",
    "        # 학습용 데이터 세트의 인덱스와 검증용 데이터 세트의 인덱스 추출하여 이를 기반으로 학습/검증 데이터 추출\n",
    "        train_x = ftr.iloc[train_idx, :]\n",
    "        train_y = target.iloc[train_idx]\n",
    "        valid_x = ftr.iloc[valid_idx, :]\n",
    "        valid_y = target.iloc[valid_idx]\n",
    "        \n",
    "        # 추출된 학습/검증 데이터 세트로 모델 학습. early_stopping은 200으로 증가. \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'RMSE', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "        # 검증 데이터 세트로 예측된 확률 저장. 사용되지는 않음. \n",
    "        #oof_preds[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration_)       \n",
    "        # 학습된 모델로 테스트 데이터 세트에 예측 확률 계산. \n",
    "        # nfolds 번 반복 실행하므로 평균 확률을 구하기 위해 개별 수행시 마다 수행 횟수로 나눈 확률을 추후에 더해서 최종 평균 확률 계산. \n",
    "        test_preds += clf.predict(data_te2[:,1:], num_iteration=clf.best_iteration_)/folds.n_splits\n",
    "        \n",
    "        \n",
    "    return clf, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### iteration  0  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 8.0648\ttraining's l2: 65.041\tvalid_1's rmse: 8.46028\tvalid_1's l2: 71.5763\n",
      "[400]\ttraining's rmse: 7.52126\ttraining's l2: 56.5693\tvalid_1's rmse: 8.22472\tvalid_1's l2: 67.6461\n",
      "[600]\ttraining's rmse: 7.18741\ttraining's l2: 51.6589\tvalid_1's rmse: 8.16886\tvalid_1's l2: 66.7303\n",
      "[800]\ttraining's rmse: 6.91383\ttraining's l2: 47.801\tvalid_1's rmse: 8.14349\tvalid_1's l2: 66.3164\n",
      "[1000]\ttraining's rmse: 6.67831\ttraining's l2: 44.5999\tvalid_1's rmse: 8.13237\tvalid_1's l2: 66.1354\n",
      "[1200]\ttraining's rmse: 6.46987\ttraining's l2: 41.8593\tvalid_1's rmse: 8.12585\tvalid_1's l2: 66.0295\n",
      "[1400]\ttraining's rmse: 6.27708\ttraining's l2: 39.4017\tvalid_1's rmse: 8.12206\tvalid_1's l2: 65.9678\n",
      "[1600]\ttraining's rmse: 6.09402\ttraining's l2: 37.137\tvalid_1's rmse: 8.12003\tvalid_1's l2: 65.9349\n",
      "[1800]\ttraining's rmse: 5.92207\ttraining's l2: 35.0709\tvalid_1's rmse: 8.12013\tvalid_1's l2: 65.9366\n",
      "Early stopping, best iteration is:\n",
      "[1693]\ttraining's rmse: 6.01333\ttraining's l2: 36.1601\tvalid_1's rmse: 8.11873\tvalid_1's l2: 65.9138\n",
      "##### iteration  1  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 8.11968\ttraining's l2: 65.9292\tvalid_1's rmse: 8.30757\tvalid_1's l2: 69.0157\n",
      "[400]\ttraining's rmse: 7.57277\ttraining's l2: 57.3469\tvalid_1's rmse: 8.04383\tvalid_1's l2: 64.7031\n",
      "[600]\ttraining's rmse: 7.2357\ttraining's l2: 52.3553\tvalid_1's rmse: 7.97451\tvalid_1's l2: 63.5928\n",
      "[800]\ttraining's rmse: 6.96177\ttraining's l2: 48.4662\tvalid_1's rmse: 7.93769\tvalid_1's l2: 63.007\n",
      "[1000]\ttraining's rmse: 6.72498\ttraining's l2: 45.2254\tvalid_1's rmse: 7.91978\tvalid_1's l2: 62.7229\n",
      "[1200]\ttraining's rmse: 6.51389\ttraining's l2: 42.4308\tvalid_1's rmse: 7.91652\tvalid_1's l2: 62.6714\n",
      "[1400]\ttraining's rmse: 6.32303\ttraining's l2: 39.9808\tvalid_1's rmse: 7.91371\tvalid_1's l2: 62.6268\n",
      "[1600]\ttraining's rmse: 6.14188\ttraining's l2: 37.7227\tvalid_1's rmse: 7.91329\tvalid_1's l2: 62.6201\n",
      "[1800]\ttraining's rmse: 5.97103\ttraining's l2: 35.6531\tvalid_1's rmse: 7.91307\tvalid_1's l2: 62.6167\n",
      "Early stopping, best iteration is:\n",
      "[1686]\ttraining's rmse: 6.06741\ttraining's l2: 36.8135\tvalid_1's rmse: 7.9121\tvalid_1's l2: 62.6013\n",
      "##### iteration  2  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 8.08731\ttraining's l2: 65.4046\tvalid_1's rmse: 8.40465\tvalid_1's l2: 70.6381\n",
      "[400]\ttraining's rmse: 7.53783\ttraining's l2: 56.8189\tvalid_1's rmse: 8.16216\tvalid_1's l2: 66.6208\n",
      "[600]\ttraining's rmse: 7.20165\ttraining's l2: 51.8638\tvalid_1's rmse: 8.09844\tvalid_1's l2: 65.5848\n",
      "[800]\ttraining's rmse: 6.92803\ttraining's l2: 47.9977\tvalid_1's rmse: 8.07012\tvalid_1's l2: 65.1268\n",
      "[1000]\ttraining's rmse: 6.69297\ttraining's l2: 44.7959\tvalid_1's rmse: 8.05478\tvalid_1's l2: 64.8794\n",
      "[1200]\ttraining's rmse: 6.47976\ttraining's l2: 41.9873\tvalid_1's rmse: 8.04453\tvalid_1's l2: 64.7144\n",
      "[1400]\ttraining's rmse: 6.28346\ttraining's l2: 39.4819\tvalid_1's rmse: 8.04045\tvalid_1's l2: 64.6488\n",
      "[1600]\ttraining's rmse: 6.10254\ttraining's l2: 37.241\tvalid_1's rmse: 8.03933\tvalid_1's l2: 64.6309\n",
      "[1800]\ttraining's rmse: 5.93101\ttraining's l2: 35.1769\tvalid_1's rmse: 8.0374\tvalid_1's l2: 64.5997\n",
      "Early stopping, best iteration is:\n",
      "[1799]\ttraining's rmse: 5.93176\ttraining's l2: 35.1858\tvalid_1's rmse: 8.03734\tvalid_1's l2: 64.5988\n",
      "##### iteration  3  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 8.04284\ttraining's l2: 64.6873\tvalid_1's rmse: 8.57344\tvalid_1's l2: 73.5038\n",
      "[400]\ttraining's rmse: 7.49797\ttraining's l2: 56.2196\tvalid_1's rmse: 8.31265\tvalid_1's l2: 69.1001\n",
      "[600]\ttraining's rmse: 7.16286\ttraining's l2: 51.3065\tvalid_1's rmse: 8.23855\tvalid_1's l2: 67.8737\n",
      "[800]\ttraining's rmse: 6.8874\ttraining's l2: 47.4362\tvalid_1's rmse: 8.20227\tvalid_1's l2: 67.2772\n",
      "[1000]\ttraining's rmse: 6.65183\ttraining's l2: 44.2469\tvalid_1's rmse: 8.18565\tvalid_1's l2: 67.0049\n",
      "[1200]\ttraining's rmse: 6.43877\ttraining's l2: 41.4577\tvalid_1's rmse: 8.18024\tvalid_1's l2: 66.9164\n",
      "[1400]\ttraining's rmse: 6.24363\ttraining's l2: 38.9829\tvalid_1's rmse: 8.17911\tvalid_1's l2: 66.8978\n",
      "Early stopping, best iteration is:\n",
      "[1350]\ttraining's rmse: 6.29129\ttraining's l2: 39.5804\tvalid_1's rmse: 8.17825\tvalid_1's l2: 66.8837\n",
      "##### iteration  4  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 8.09808\ttraining's l2: 65.579\tvalid_1's rmse: 8.40859\tvalid_1's l2: 70.7044\n",
      "[400]\ttraining's rmse: 7.55439\ttraining's l2: 57.0688\tvalid_1's rmse: 8.13652\tvalid_1's l2: 66.203\n",
      "[600]\ttraining's rmse: 7.21857\ttraining's l2: 52.1078\tvalid_1's rmse: 8.06769\tvalid_1's l2: 65.0876\n",
      "[800]\ttraining's rmse: 6.94272\ttraining's l2: 48.2014\tvalid_1's rmse: 8.03405\tvalid_1's l2: 64.5459\n",
      "[1000]\ttraining's rmse: 6.70652\ttraining's l2: 44.9774\tvalid_1's rmse: 8.02344\tvalid_1's l2: 64.3756\n",
      "[1200]\ttraining's rmse: 6.49477\ttraining's l2: 42.182\tvalid_1's rmse: 8.01975\tvalid_1's l2: 64.3165\n",
      "[1400]\ttraining's rmse: 6.30041\ttraining's l2: 39.6952\tvalid_1's rmse: 8.01576\tvalid_1's l2: 64.2523\n",
      "[1600]\ttraining's rmse: 6.11867\ttraining's l2: 37.4381\tvalid_1's rmse: 8.01504\tvalid_1's l2: 64.2408\n",
      "Early stopping, best iteration is:\n",
      "[1579]\ttraining's rmse: 6.13719\ttraining's l2: 37.6651\tvalid_1's rmse: 8.0139\tvalid_1's l2: 64.2225\n"
     ]
    }
   ],
   "source": [
    "clf, test_preds = train_apps_all_with_oof(ftr, target, nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40.20381837, 40.65737366, 26.96285049, ..., 35.88597817,\n",
       "       33.02934188, 26.96044285])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDtest['age'] = test_preds ; sub = IDtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub.to_csv('submissions_0615_hyun_min_scaled_lgbm_tun.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = data2[:, 1:]\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ftr, target, test_size=0.2 ,stratify=target, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingRegressor 로그 변환된 RMSE: 8.094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.093869749309619]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rmse(model):\n",
    "    pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test , pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('{0} 로그 변환된 RMSE: {1}'.format(model.__class__.__name__,np.round(rmse, 3)))\n",
    "    return rmse\n",
    "\n",
    "def get_rmses(models):\n",
    "    rmses = [ ]\n",
    "    for model in models:\n",
    "        rmse = get_rmse(model)\n",
    "        rmses.append(rmse)\n",
    "    return rmses\n",
    "\n",
    "param_lgb =  {'colsample_bytree': 0.828, 'max_bin': 385, \n",
    " 'max_depth': 12, 'min_child_samples': 178,\n",
    " 'min_child_weight': 45.305, 'num_leaves': 24, \n",
    " 'reg_alpha': 3.737, 'reg_lambda': 2.447, 'subsample': 0.566}\n",
    "\n",
    "lgbm = LGBMRegressor(random_state = 1000 , **param_lgb )\n",
    "cat = CatBoostRegressor(random_state=1000 )\n",
    "# reg_ridge = Ridge(random_state = 1000)\n",
    "\n",
    "vr = VotingRegressor(estimators=[('lgbm', lgbm), ('cat', cat)],  n_jobs=-1)\n",
    "vr = vr.fit(X_train, y_train)\n",
    "\n",
    "models = [vr]\n",
    "get_rmses(models)\n",
    "\n",
    "# VotingRegressor 로그 변환된 RMSE: 8.099  -> lgb_tun , cat, ridge\n",
    "# [8.09932555206551]\n",
    "\n",
    "# VotingRegressor 로그 변환된 RMSE: 8.094\n",
    "# [8.093869749309619]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'submissions_0615_hyun_min_select_vr_tun.csv' is ready to submit.\n"
     ]
    }
   ],
   "source": [
    "pred = vr.predict(data_te2[:,1:])\n",
    "fname = 'submissions_0615_hyun_min_select_vr_tun.csv'\n",
    "submissions = pd.concat([pd.Series(IDtest['custid'], name=\"custid\"), pd.Series(pred, name=\"age\")] ,axis=1)\n",
    "submissions.to_csv(fname, index=False)\n",
    "print(\"'{}' is ready to submit.\" .format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30001</td>\n",
       "      <td>40.032183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30002</td>\n",
       "      <td>42.307601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30003</td>\n",
       "      <td>26.125009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30005</td>\n",
       "      <td>31.773956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30007</td>\n",
       "      <td>25.148392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>49988</td>\n",
       "      <td>35.084574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>49990</td>\n",
       "      <td>35.872768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>49992</td>\n",
       "      <td>37.117888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>49993</td>\n",
       "      <td>32.557595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>49994</td>\n",
       "      <td>26.537778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       custid        age\n",
       "0       30001  40.032183\n",
       "1       30002  42.307601\n",
       "2       30003  26.125009\n",
       "3       30005  31.773956\n",
       "4       30007  25.148392\n",
       "...       ...        ...\n",
       "14375   49988  35.084574\n",
       "14376   49990  35.872768\n",
       "14377   49992  37.117888\n",
       "14378   49993  32.557595\n",
       "14379   49994  26.537778\n",
       "\n",
       "[14380 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.read_csv('submissions_0615_hyun_min_select_vr_tun.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
