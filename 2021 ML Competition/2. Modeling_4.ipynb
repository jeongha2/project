{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family=fm.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()) # for Windows OS user\n",
    "import math\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import klib\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys, warnings\n",
    "if not sys.warnoptions: warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import ClassifierMixin\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = pd.read_csv(os.path.abspath(\"../input\")+'/X_train.csv', encoding='cp949')\n",
    "df_x_test = pd.read_csv(os.path.abspath(\"../input\")+'/X_test.csv', encoding='cp949')\n",
    "df_y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv').age\n",
    "df_y_train_mer = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv')\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949')\n",
    "IDtrain = pd.DataFrame({'custid': df_x_train.custid.unique()})\n",
    "IDtest = pd.DataFrame({'custid': df_x_test.custid.unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.abspath(\"../input\")+'/features__2rd_jinew.csv')\n",
    "dft = pd.read_csv(os.path.abspath(\"../input\")+'/features_t__2rd_jinew.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([IDtrain['custid'] , df.iloc[:,1:] ], axis=1)\n",
    "\n",
    "IDtest.index = dft.index\n",
    "data_te = pd.concat([IDtest['custid'] , dft.iloc[:,1:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>672</th>\n",
       "      <th>673</th>\n",
       "      <th>674</th>\n",
       "      <th>675</th>\n",
       "      <th>676</th>\n",
       "      <th>677</th>\n",
       "      <th>678</th>\n",
       "      <th>679</th>\n",
       "      <th>680</th>\n",
       "      <th>681</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.984931</td>\n",
       "      <td>1.458415</td>\n",
       "      <td>0.435281</td>\n",
       "      <td>0.664155</td>\n",
       "      <td>1.232289</td>\n",
       "      <td>1.453869</td>\n",
       "      <td>1.359543</td>\n",
       "      <td>0.764639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254661</td>\n",
       "      <td>0.058813</td>\n",
       "      <td>0.087943</td>\n",
       "      <td>0.281776</td>\n",
       "      <td>-0.238042</td>\n",
       "      <td>-0.028186</td>\n",
       "      <td>-0.121498</td>\n",
       "      <td>0.144626</td>\n",
       "      <td>0.024388</td>\n",
       "      <td>-0.109487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455549</td>\n",
       "      <td>2.119481</td>\n",
       "      <td>0.206223</td>\n",
       "      <td>-1.040350</td>\n",
       "      <td>-0.540205</td>\n",
       "      <td>0.130573</td>\n",
       "      <td>-2.131614</td>\n",
       "      <td>-0.067095</td>\n",
       "      <td>0.483337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151172</td>\n",
       "      <td>0.084774</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.314629</td>\n",
       "      <td>-0.150335</td>\n",
       "      <td>-0.048720</td>\n",
       "      <td>-0.057136</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>0.195636</td>\n",
       "      <td>-0.088099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.610638</td>\n",
       "      <td>1.087506</td>\n",
       "      <td>-0.204307</td>\n",
       "      <td>0.808859</td>\n",
       "      <td>-0.018503</td>\n",
       "      <td>1.245623</td>\n",
       "      <td>0.530561</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.656964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146861</td>\n",
       "      <td>-0.044022</td>\n",
       "      <td>0.062575</td>\n",
       "      <td>0.324632</td>\n",
       "      <td>-0.121978</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>-0.199320</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.150615</td>\n",
       "      <td>-0.111584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.713662</td>\n",
       "      <td>-2.247293</td>\n",
       "      <td>1.687891</td>\n",
       "      <td>-2.198441</td>\n",
       "      <td>-1.020899</td>\n",
       "      <td>-1.771180</td>\n",
       "      <td>-2.131614</td>\n",
       "      <td>-1.829412</td>\n",
       "      <td>-1.833030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108229</td>\n",
       "      <td>-0.129220</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>0.247977</td>\n",
       "      <td>-0.136481</td>\n",
       "      <td>0.098530</td>\n",
       "      <td>0.087134</td>\n",
       "      <td>0.217782</td>\n",
       "      <td>0.188581</td>\n",
       "      <td>0.106901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.401605</td>\n",
       "      <td>1.616230</td>\n",
       "      <td>1.247308</td>\n",
       "      <td>0.715465</td>\n",
       "      <td>-0.245324</td>\n",
       "      <td>0.078904</td>\n",
       "      <td>1.230937</td>\n",
       "      <td>0.067177</td>\n",
       "      <td>0.643505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202370</td>\n",
       "      <td>0.024127</td>\n",
       "      <td>0.050319</td>\n",
       "      <td>0.248327</td>\n",
       "      <td>-0.215501</td>\n",
       "      <td>-0.026992</td>\n",
       "      <td>-0.066950</td>\n",
       "      <td>0.081839</td>\n",
       "      <td>0.135557</td>\n",
       "      <td>-0.101623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>29995</td>\n",
       "      <td>0.408348</td>\n",
       "      <td>0.531171</td>\n",
       "      <td>1.143588</td>\n",
       "      <td>0.902254</td>\n",
       "      <td>-0.651595</td>\n",
       "      <td>-0.066103</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>0.184665</td>\n",
       "      <td>0.616586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179793</td>\n",
       "      <td>0.092796</td>\n",
       "      <td>0.065648</td>\n",
       "      <td>0.173723</td>\n",
       "      <td>-0.168625</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>-0.047108</td>\n",
       "      <td>0.140185</td>\n",
       "      <td>0.091426</td>\n",
       "      <td>-0.085712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>29996</td>\n",
       "      <td>0.401605</td>\n",
       "      <td>1.011767</td>\n",
       "      <td>-1.097046</td>\n",
       "      <td>-1.423267</td>\n",
       "      <td>-0.722595</td>\n",
       "      <td>-1.771180</td>\n",
       "      <td>0.172012</td>\n",
       "      <td>0.251801</td>\n",
       "      <td>-1.833030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275625</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>0.084248</td>\n",
       "      <td>0.297352</td>\n",
       "      <td>-0.094568</td>\n",
       "      <td>-0.043255</td>\n",
       "      <td>-0.095517</td>\n",
       "      <td>0.115193</td>\n",
       "      <td>0.102161</td>\n",
       "      <td>-0.045575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>29997</td>\n",
       "      <td>-0.825621</td>\n",
       "      <td>-0.765582</td>\n",
       "      <td>0.532304</td>\n",
       "      <td>-1.824863</td>\n",
       "      <td>-0.900977</td>\n",
       "      <td>-1.771180</td>\n",
       "      <td>0.190590</td>\n",
       "      <td>-1.829412</td>\n",
       "      <td>-1.833030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144915</td>\n",
       "      <td>-0.025202</td>\n",
       "      <td>0.063535</td>\n",
       "      <td>0.292798</td>\n",
       "      <td>-0.106992</td>\n",
       "      <td>-0.029885</td>\n",
       "      <td>-0.158298</td>\n",
       "      <td>0.119844</td>\n",
       "      <td>0.208488</td>\n",
       "      <td>-0.171901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>29998</td>\n",
       "      <td>0.340918</td>\n",
       "      <td>-0.124821</td>\n",
       "      <td>-0.498903</td>\n",
       "      <td>0.874235</td>\n",
       "      <td>0.425839</td>\n",
       "      <td>0.450587</td>\n",
       "      <td>0.307629</td>\n",
       "      <td>0.357540</td>\n",
       "      <td>0.212803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098237</td>\n",
       "      <td>-0.072942</td>\n",
       "      <td>0.022573</td>\n",
       "      <td>0.364855</td>\n",
       "      <td>-0.102633</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>-0.082243</td>\n",
       "      <td>0.035010</td>\n",
       "      <td>0.161887</td>\n",
       "      <td>-0.092753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21586</th>\n",
       "      <td>29999</td>\n",
       "      <td>-0.198522</td>\n",
       "      <td>1.280078</td>\n",
       "      <td>0.341511</td>\n",
       "      <td>-1.936937</td>\n",
       "      <td>-0.594596</td>\n",
       "      <td>-1.771180</td>\n",
       "      <td>0.307629</td>\n",
       "      <td>-1.829412</td>\n",
       "      <td>-1.833030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.549625</td>\n",
       "      <td>0.028859</td>\n",
       "      <td>0.098428</td>\n",
       "      <td>0.233532</td>\n",
       "      <td>-0.073496</td>\n",
       "      <td>0.074926</td>\n",
       "      <td>-0.109674</td>\n",
       "      <td>0.046636</td>\n",
       "      <td>0.300156</td>\n",
       "      <td>-0.102941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21587 rows × 683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       custid         0         1         2         3         4         5  \\\n",
       "0           0  0.522979  0.984931  1.458415  0.435281  0.664155  1.232289   \n",
       "1           2  0.455549  2.119481  0.206223 -1.040350 -0.540205  0.130573   \n",
       "2           3  0.610638  1.087506 -0.204307  0.808859 -0.018503  1.245623   \n",
       "3           4 -2.713662 -2.247293  1.687891 -2.198441 -1.020899 -1.771180   \n",
       "4           5  0.401605  1.616230  1.247308  0.715465 -0.245324  0.078904   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "21582   29995  0.408348  0.531171  1.143588  0.902254 -0.651595 -0.066103   \n",
       "21583   29996  0.401605  1.011767 -1.097046 -1.423267 -0.722595 -1.771180   \n",
       "21584   29997 -0.825621 -0.765582  0.532304 -1.824863 -0.900977 -1.771180   \n",
       "21585   29998  0.340918 -0.124821 -0.498903  0.874235  0.425839  0.450587   \n",
       "21586   29999 -0.198522  1.280078  0.341511 -1.936937 -0.594596 -1.771180   \n",
       "\n",
       "              6         7         8  ...       672       673       674  \\\n",
       "0      1.453869  1.359543  0.764639  ... -0.254661  0.058813  0.087943   \n",
       "1     -2.131614 -0.067095  0.483337  ... -0.151172  0.084774  0.080056   \n",
       "2      0.530561  0.189700  0.656964  ... -0.146861 -0.044022  0.062575   \n",
       "3     -2.131614 -1.829412 -1.833030  ... -0.108229 -0.129220 -0.106363   \n",
       "4      1.230937  0.067177  0.643505  ... -0.202370  0.024127  0.050319   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21582  0.103275  0.184665  0.616586  ... -0.179793  0.092796  0.065648   \n",
       "21583  0.172012  0.251801 -1.833030  ... -0.275625  0.081132  0.084248   \n",
       "21584  0.190590 -1.829412 -1.833030  ... -0.144915 -0.025202  0.063535   \n",
       "21585  0.307629  0.357540  0.212803  ... -0.098237 -0.072942  0.022573   \n",
       "21586  0.307629 -1.829412 -1.833030  ... -0.549625  0.028859  0.098428   \n",
       "\n",
       "            675       676       677       678       679       680       681  \n",
       "0      0.281776 -0.238042 -0.028186 -0.121498  0.144626  0.024388 -0.109487  \n",
       "1      0.314629 -0.150335 -0.048720 -0.057136  0.014636  0.195636 -0.088099  \n",
       "2      0.324632 -0.121978  0.011168 -0.199320  0.014595  0.150615 -0.111584  \n",
       "3      0.247977 -0.136481  0.098530  0.087134  0.217782  0.188581  0.106901  \n",
       "4      0.248327 -0.215501 -0.026992 -0.066950  0.081839  0.135557 -0.101623  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21582  0.173723 -0.168625  0.007521 -0.047108  0.140185  0.091426 -0.085712  \n",
       "21583  0.297352 -0.094568 -0.043255 -0.095517  0.115193  0.102161 -0.045575  \n",
       "21584  0.292798 -0.106992 -0.029885 -0.158298  0.119844  0.208488 -0.171901  \n",
       "21585  0.364855 -0.102633 -0.000469 -0.082243  0.035010  0.161887 -0.092753  \n",
       "21586  0.233532 -0.073496  0.074926 -0.109674  0.046636  0.300156 -0.102941  \n",
       "\n",
       "[21587 rows x 683 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>672</th>\n",
       "      <th>673</th>\n",
       "      <th>674</th>\n",
       "      <th>675</th>\n",
       "      <th>676</th>\n",
       "      <th>677</th>\n",
       "      <th>678</th>\n",
       "      <th>679</th>\n",
       "      <th>680</th>\n",
       "      <th>681</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.388119</td>\n",
       "      <td>-1.644922</td>\n",
       "      <td>0.686027</td>\n",
       "      <td>0.892914</td>\n",
       "      <td>0.028114</td>\n",
       "      <td>1.262291</td>\n",
       "      <td>0.939268</td>\n",
       "      <td>0.928195</td>\n",
       "      <td>0.737721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173755</td>\n",
       "      <td>0.063311</td>\n",
       "      <td>0.131041</td>\n",
       "      <td>0.283595</td>\n",
       "      <td>-0.127709</td>\n",
       "      <td>-0.031210</td>\n",
       "      <td>-0.172091</td>\n",
       "      <td>0.096424</td>\n",
       "      <td>0.107025</td>\n",
       "      <td>-0.028619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.717249</td>\n",
       "      <td>-0.268576</td>\n",
       "      <td>0.734144</td>\n",
       "      <td>-0.776009</td>\n",
       "      <td>-0.021101</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>0.050393</td>\n",
       "      <td>0.764639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150178</td>\n",
       "      <td>0.053805</td>\n",
       "      <td>0.068998</td>\n",
       "      <td>0.259828</td>\n",
       "      <td>-0.175851</td>\n",
       "      <td>-0.055302</td>\n",
       "      <td>-0.141248</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.157698</td>\n",
       "      <td>-0.065647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.430884</td>\n",
       "      <td>-1.632124</td>\n",
       "      <td>0.752822</td>\n",
       "      <td>-0.525812</td>\n",
       "      <td>0.412252</td>\n",
       "      <td>0.177586</td>\n",
       "      <td>0.520344</td>\n",
       "      <td>0.643505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262661</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.105207</td>\n",
       "      <td>0.331903</td>\n",
       "      <td>-0.063894</td>\n",
       "      <td>-0.040715</td>\n",
       "      <td>-0.091992</td>\n",
       "      <td>-0.019063</td>\n",
       "      <td>0.213268</td>\n",
       "      <td>-0.046325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30005</td>\n",
       "      <td>0.340918</td>\n",
       "      <td>-2.525086</td>\n",
       "      <td>0.516926</td>\n",
       "      <td>-2.217120</td>\n",
       "      <td>-1.062959</td>\n",
       "      <td>-1.771180</td>\n",
       "      <td>-2.131614</td>\n",
       "      <td>-1.829412</td>\n",
       "      <td>-1.833030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285517</td>\n",
       "      <td>0.111498</td>\n",
       "      <td>0.144643</td>\n",
       "      <td>0.393445</td>\n",
       "      <td>-0.022235</td>\n",
       "      <td>-0.149941</td>\n",
       "      <td>-0.118336</td>\n",
       "      <td>0.152341</td>\n",
       "      <td>0.039101</td>\n",
       "      <td>-0.074120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30007</td>\n",
       "      <td>0.543208</td>\n",
       "      <td>-0.429491</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>-1.656753</td>\n",
       "      <td>-0.513272</td>\n",
       "      <td>-1.771180</td>\n",
       "      <td>0.729341</td>\n",
       "      <td>0.928195</td>\n",
       "      <td>-1.833030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.293872</td>\n",
       "      <td>0.112471</td>\n",
       "      <td>-0.013264</td>\n",
       "      <td>0.277654</td>\n",
       "      <td>-0.048899</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>-0.088198</td>\n",
       "      <td>0.098579</td>\n",
       "      <td>0.119932</td>\n",
       "      <td>-0.097230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>49988</td>\n",
       "      <td>-0.353611</td>\n",
       "      <td>1.230923</td>\n",
       "      <td>1.232741</td>\n",
       "      <td>-1.694111</td>\n",
       "      <td>0.114726</td>\n",
       "      <td>0.262246</td>\n",
       "      <td>-2.131614</td>\n",
       "      <td>1.191703</td>\n",
       "      <td>-0.164061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137457</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.070736</td>\n",
       "      <td>0.336258</td>\n",
       "      <td>-0.135077</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>-0.069033</td>\n",
       "      <td>0.057993</td>\n",
       "      <td>0.112537</td>\n",
       "      <td>-0.178926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>49990</td>\n",
       "      <td>-2.356283</td>\n",
       "      <td>-2.525086</td>\n",
       "      <td>2.033434</td>\n",
       "      <td>-2.217120</td>\n",
       "      <td>-1.062959</td>\n",
       "      <td>-1.771180</td>\n",
       "      <td>-2.131614</td>\n",
       "      <td>0.693219</td>\n",
       "      <td>-1.833030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255262</td>\n",
       "      <td>0.182509</td>\n",
       "      <td>-0.001178</td>\n",
       "      <td>0.445767</td>\n",
       "      <td>0.017832</td>\n",
       "      <td>-0.052382</td>\n",
       "      <td>-0.053875</td>\n",
       "      <td>0.193443</td>\n",
       "      <td>0.257981</td>\n",
       "      <td>-0.235073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>49992</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>-1.472477</td>\n",
       "      <td>1.096817</td>\n",
       "      <td>0.435281</td>\n",
       "      <td>7.383497</td>\n",
       "      <td>-1.771180</td>\n",
       "      <td>1.310821</td>\n",
       "      <td>-1.829412</td>\n",
       "      <td>-1.833030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.383455</td>\n",
       "      <td>0.218011</td>\n",
       "      <td>-0.049461</td>\n",
       "      <td>0.146879</td>\n",
       "      <td>-0.156452</td>\n",
       "      <td>0.138344</td>\n",
       "      <td>-0.118741</td>\n",
       "      <td>0.093116</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>-0.070758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>49993</td>\n",
       "      <td>-0.131092</td>\n",
       "      <td>-1.412283</td>\n",
       "      <td>-0.178136</td>\n",
       "      <td>-2.217120</td>\n",
       "      <td>-1.062959</td>\n",
       "      <td>-1.771180</td>\n",
       "      <td>-2.131614</td>\n",
       "      <td>0.906376</td>\n",
       "      <td>-1.833030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210829</td>\n",
       "      <td>-0.059217</td>\n",
       "      <td>0.098295</td>\n",
       "      <td>0.433628</td>\n",
       "      <td>-0.222356</td>\n",
       "      <td>-0.083358</td>\n",
       "      <td>-0.106734</td>\n",
       "      <td>-0.171169</td>\n",
       "      <td>0.278698</td>\n",
       "      <td>-0.051114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>49994</td>\n",
       "      <td>-0.286181</td>\n",
       "      <td>-1.114755</td>\n",
       "      <td>0.333242</td>\n",
       "      <td>-2.217120</td>\n",
       "      <td>-1.062959</td>\n",
       "      <td>-1.771180</td>\n",
       "      <td>0.844522</td>\n",
       "      <td>-1.829412</td>\n",
       "      <td>-1.833030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175866</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.367945</td>\n",
       "      <td>-0.088301</td>\n",
       "      <td>0.019612</td>\n",
       "      <td>-0.133036</td>\n",
       "      <td>0.118366</td>\n",
       "      <td>0.042888</td>\n",
       "      <td>-0.257261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       custid         0         1         2         3         4         5  \\\n",
       "0       30001  0.388119 -1.644922  0.686027  0.892914  0.028114  1.262291   \n",
       "1       30002  0.522979  0.717249 -0.268576  0.734144 -0.776009 -0.021101   \n",
       "2       30003  0.522979  0.430884 -1.632124  0.752822 -0.525812  0.412252   \n",
       "3       30005  0.340918 -2.525086  0.516926 -2.217120 -1.062959 -1.771180   \n",
       "4       30007  0.543208 -0.429491  0.287521 -1.656753 -0.513272 -1.771180   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "14375   49988 -0.353611  1.230923  1.232741 -1.694111  0.114726  0.262246   \n",
       "14376   49990 -2.356283 -2.525086  2.033434 -2.217120 -1.062959 -1.771180   \n",
       "14377   49992  0.003768 -1.472477  1.096817  0.435281  7.383497 -1.771180   \n",
       "14378   49993 -0.131092 -1.412283 -0.178136 -2.217120 -1.062959 -1.771180   \n",
       "14379   49994 -0.286181 -1.114755  0.333242 -2.217120 -1.062959 -1.771180   \n",
       "\n",
       "              6         7         8  ...       672       673       674  \\\n",
       "0      0.939268  0.928195  0.737721  ... -0.173755  0.063311  0.131041   \n",
       "1      0.004814  0.050393  0.764639  ... -0.150178  0.053805  0.068998   \n",
       "2      0.177586  0.520344  0.643505  ... -0.262661  0.015304  0.105207   \n",
       "3     -2.131614 -1.829412 -1.833030  ... -0.285517  0.111498  0.144643   \n",
       "4      0.729341  0.928195 -1.833030  ... -0.293872  0.112471 -0.013264   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "14375 -2.131614  1.191703 -0.164061  ... -0.137457  0.001476  0.070736   \n",
       "14376 -2.131614  0.693219 -1.833030  ... -0.255262  0.182509 -0.001178   \n",
       "14377  1.310821 -1.829412 -1.833030  ... -0.383455  0.218011 -0.049461   \n",
       "14378 -2.131614  0.906376 -1.833030  ... -0.210829 -0.059217  0.098295   \n",
       "14379  0.844522 -1.829412 -1.833030  ... -0.175866  0.196078  0.005831   \n",
       "\n",
       "            675       676       677       678       679       680       681  \n",
       "0      0.283595 -0.127709 -0.031210 -0.172091  0.096424  0.107025 -0.028619  \n",
       "1      0.259828 -0.175851 -0.055302 -0.141248  0.057756  0.157698 -0.065647  \n",
       "2      0.331903 -0.063894 -0.040715 -0.091992 -0.019063  0.213268 -0.046325  \n",
       "3      0.393445 -0.022235 -0.149941 -0.118336  0.152341  0.039101 -0.074120  \n",
       "4      0.277654 -0.048899 -0.003701 -0.088198  0.098579  0.119932 -0.097230  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "14375  0.336258 -0.135077  0.002304 -0.069033  0.057993  0.112537 -0.178926  \n",
       "14376  0.445767  0.017832 -0.052382 -0.053875  0.193443  0.257981 -0.235073  \n",
       "14377  0.146879 -0.156452  0.138344 -0.118741  0.093116  0.009843 -0.070758  \n",
       "14378  0.433628 -0.222356 -0.083358 -0.106734 -0.171169  0.278698 -0.051114  \n",
       "14379  0.367945 -0.088301  0.019612 -0.133036  0.118366  0.042888 -0.257261  \n",
       "\n",
       "[14380 rows x 683 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( data, data_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21587, 683), (14380, 683), (21587,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "data.shape, data_te.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.astype(str)\n",
    "data_te.columns = data_te.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9]+', ' ', x))\n",
    "# data_te = data_te.rename(columns = lambda x:re.sub('[^A-Za-z0-9]+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.values\n",
    "data_te2 = data_te.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = data2[:, 1:]\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17269, 682), (4318, 682))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr, target, test_size=0.2 , stratify = target , random_state=0)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 7.80471\ttraining's l2: 60.9135\tvalid_1's rmse: 8.33026\tvalid_1's l2: 69.3932\n",
      "[200]\ttraining's rmse: 7.10587\ttraining's l2: 50.4933\tvalid_1's rmse: 8.09899\tvalid_1's l2: 65.5936\n",
      "[300]\ttraining's rmse: 6.64011\ttraining's l2: 44.091\tvalid_1's rmse: 8.03634\tvalid_1's l2: 64.5828\n",
      "[400]\ttraining's rmse: 6.26783\ttraining's l2: 39.2857\tvalid_1's rmse: 8.01784\tvalid_1's l2: 64.2858\n",
      "[500]\ttraining's rmse: 5.93851\ttraining's l2: 35.2659\tvalid_1's rmse: 8.0076\tvalid_1's l2: 64.1217\n",
      "Early stopping, best iteration is:\n",
      "[487]\ttraining's rmse: 5.9798\ttraining's l2: 35.758\tvalid_1's rmse: 8.00515\tvalid_1's l2: 64.0824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.02, max_depth=12, n_estimators=1000,\n",
       "              num_leaves=32, silent=-1, subsample=0.8, verbose=-1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "clf = LGBMRegressor(\n",
    "        n_jobs=-1,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=32,\n",
    "        subsample=0.8,\n",
    "        max_depth=12,\n",
    "        silent=-1,\n",
    "        verbose=-1\n",
    "        )\n",
    "\n",
    "clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric = 'RMSE', \n",
    "        verbose=100, early_stopping_rounds= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection & Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = data2[:, 1:]\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21587,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15110, 682), (6477, 682))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr, target, test_size=0.3, stratify = target,  random_state=1000)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.063286\n",
      "0:\tlearn: 10.2774423\ttotal: 239ms\tremaining: 3m 58s\n",
      "1:\tlearn: 10.1242283\ttotal: 339ms\tremaining: 2m 49s\n",
      "2:\tlearn: 9.9850038\ttotal: 428ms\tremaining: 2m 22s\n",
      "3:\tlearn: 9.8630392\ttotal: 521ms\tremaining: 2m 9s\n",
      "4:\tlearn: 9.7360534\ttotal: 618ms\tremaining: 2m 2s\n",
      "5:\tlearn: 9.6207404\ttotal: 721ms\tremaining: 1m 59s\n",
      "6:\tlearn: 9.5203094\ttotal: 810ms\tremaining: 1m 54s\n",
      "7:\tlearn: 9.4294217\ttotal: 906ms\tremaining: 1m 52s\n",
      "8:\tlearn: 9.3447070\ttotal: 1.01s\tremaining: 1m 50s\n",
      "9:\tlearn: 9.2617434\ttotal: 1.1s\tremaining: 1m 49s\n",
      "10:\tlearn: 9.1802752\ttotal: 1.2s\tremaining: 1m 48s\n",
      "11:\tlearn: 9.1234227\ttotal: 1.29s\tremaining: 1m 46s\n",
      "12:\tlearn: 9.0620618\ttotal: 1.39s\tremaining: 1m 45s\n",
      "13:\tlearn: 9.0082164\ttotal: 1.49s\tremaining: 1m 44s\n",
      "14:\tlearn: 8.9536446\ttotal: 1.59s\tremaining: 1m 44s\n",
      "15:\tlearn: 8.9035057\ttotal: 1.69s\tremaining: 1m 44s\n",
      "16:\tlearn: 8.8554631\ttotal: 1.79s\tremaining: 1m 43s\n",
      "17:\tlearn: 8.8071640\ttotal: 1.9s\tremaining: 1m 43s\n",
      "18:\tlearn: 8.7638906\ttotal: 2.01s\tremaining: 1m 43s\n",
      "19:\tlearn: 8.7226043\ttotal: 2.1s\tremaining: 1m 43s\n",
      "20:\tlearn: 8.6849739\ttotal: 2.21s\tremaining: 1m 42s\n",
      "21:\tlearn: 8.6498972\ttotal: 2.31s\tremaining: 1m 42s\n",
      "22:\tlearn: 8.6170473\ttotal: 2.43s\tremaining: 1m 43s\n",
      "23:\tlearn: 8.5821974\ttotal: 2.53s\tremaining: 1m 43s\n",
      "24:\tlearn: 8.5515283\ttotal: 2.64s\tremaining: 1m 43s\n",
      "25:\tlearn: 8.5266301\ttotal: 2.79s\tremaining: 1m 44s\n",
      "26:\tlearn: 8.5011915\ttotal: 2.91s\tremaining: 1m 44s\n",
      "27:\tlearn: 8.4786806\ttotal: 3.01s\tremaining: 1m 44s\n",
      "28:\tlearn: 8.4524113\ttotal: 3.15s\tremaining: 1m 45s\n",
      "29:\tlearn: 8.4310440\ttotal: 3.28s\tremaining: 1m 46s\n",
      "30:\tlearn: 8.4104799\ttotal: 3.4s\tremaining: 1m 46s\n",
      "31:\tlearn: 8.3937164\ttotal: 3.5s\tremaining: 1m 46s\n",
      "32:\tlearn: 8.3713393\ttotal: 3.6s\tremaining: 1m 45s\n",
      "33:\tlearn: 8.3524878\ttotal: 3.7s\tremaining: 1m 45s\n",
      "34:\tlearn: 8.3373822\ttotal: 3.8s\tremaining: 1m 44s\n",
      "35:\tlearn: 8.3218155\ttotal: 3.9s\tremaining: 1m 44s\n",
      "36:\tlearn: 8.3060944\ttotal: 4s\tremaining: 1m 43s\n",
      "37:\tlearn: 8.2909387\ttotal: 4.09s\tremaining: 1m 43s\n",
      "38:\tlearn: 8.2721175\ttotal: 4.19s\tremaining: 1m 43s\n",
      "39:\tlearn: 8.2604707\ttotal: 4.28s\tremaining: 1m 42s\n",
      "40:\tlearn: 8.2468749\ttotal: 4.37s\tremaining: 1m 42s\n",
      "41:\tlearn: 8.2351967\ttotal: 4.47s\tremaining: 1m 41s\n",
      "42:\tlearn: 8.2256265\ttotal: 4.55s\tremaining: 1m 41s\n",
      "43:\tlearn: 8.2095391\ttotal: 4.66s\tremaining: 1m 41s\n",
      "44:\tlearn: 8.1969791\ttotal: 4.75s\tremaining: 1m 40s\n",
      "45:\tlearn: 8.1829852\ttotal: 4.85s\tremaining: 1m 40s\n",
      "46:\tlearn: 8.1716005\ttotal: 4.97s\tremaining: 1m 40s\n",
      "47:\tlearn: 8.1603737\ttotal: 5.08s\tremaining: 1m 40s\n",
      "48:\tlearn: 8.1498209\ttotal: 5.19s\tremaining: 1m 40s\n",
      "49:\tlearn: 8.1409831\ttotal: 5.29s\tremaining: 1m 40s\n",
      "50:\tlearn: 8.1319110\ttotal: 5.4s\tremaining: 1m 40s\n",
      "51:\tlearn: 8.1203661\ttotal: 5.5s\tremaining: 1m 40s\n",
      "52:\tlearn: 8.1094647\ttotal: 5.59s\tremaining: 1m 39s\n",
      "53:\tlearn: 8.0996417\ttotal: 5.69s\tremaining: 1m 39s\n",
      "54:\tlearn: 8.0898669\ttotal: 5.79s\tremaining: 1m 39s\n",
      "55:\tlearn: 8.0816034\ttotal: 5.88s\tremaining: 1m 39s\n",
      "56:\tlearn: 8.0741536\ttotal: 5.98s\tremaining: 1m 38s\n",
      "57:\tlearn: 8.0662699\ttotal: 6.07s\tremaining: 1m 38s\n",
      "58:\tlearn: 8.0591263\ttotal: 6.17s\tremaining: 1m 38s\n",
      "59:\tlearn: 8.0519670\ttotal: 6.26s\tremaining: 1m 38s\n",
      "60:\tlearn: 8.0449984\ttotal: 6.36s\tremaining: 1m 37s\n",
      "61:\tlearn: 8.0388322\ttotal: 6.46s\tremaining: 1m 37s\n",
      "62:\tlearn: 8.0319037\ttotal: 6.56s\tremaining: 1m 37s\n",
      "63:\tlearn: 8.0228728\ttotal: 6.66s\tremaining: 1m 37s\n",
      "64:\tlearn: 8.0146851\ttotal: 6.76s\tremaining: 1m 37s\n",
      "65:\tlearn: 8.0065476\ttotal: 6.86s\tremaining: 1m 37s\n",
      "66:\tlearn: 7.9997817\ttotal: 6.97s\tremaining: 1m 37s\n",
      "67:\tlearn: 7.9918058\ttotal: 7.07s\tremaining: 1m 36s\n",
      "68:\tlearn: 7.9858194\ttotal: 7.17s\tremaining: 1m 36s\n",
      "69:\tlearn: 7.9811510\ttotal: 7.28s\tremaining: 1m 36s\n",
      "70:\tlearn: 7.9747947\ttotal: 7.41s\tremaining: 1m 36s\n",
      "71:\tlearn: 7.9676587\ttotal: 7.53s\tremaining: 1m 37s\n",
      "72:\tlearn: 7.9624218\ttotal: 7.64s\tremaining: 1m 36s\n",
      "73:\tlearn: 7.9562699\ttotal: 7.74s\tremaining: 1m 36s\n",
      "74:\tlearn: 7.9493554\ttotal: 7.83s\tremaining: 1m 36s\n",
      "75:\tlearn: 7.9440841\ttotal: 7.93s\tremaining: 1m 36s\n",
      "76:\tlearn: 7.9376678\ttotal: 8.02s\tremaining: 1m 36s\n",
      "77:\tlearn: 7.9345992\ttotal: 8.12s\tremaining: 1m 35s\n",
      "78:\tlearn: 7.9289269\ttotal: 8.2s\tremaining: 1m 35s\n",
      "79:\tlearn: 7.9242678\ttotal: 8.29s\tremaining: 1m 35s\n",
      "80:\tlearn: 7.9197047\ttotal: 8.38s\tremaining: 1m 35s\n",
      "81:\tlearn: 7.9143705\ttotal: 8.48s\tremaining: 1m 34s\n",
      "82:\tlearn: 7.9108620\ttotal: 8.57s\tremaining: 1m 34s\n",
      "83:\tlearn: 7.9066054\ttotal: 8.67s\tremaining: 1m 34s\n",
      "84:\tlearn: 7.9020990\ttotal: 8.76s\tremaining: 1m 34s\n",
      "85:\tlearn: 7.8975537\ttotal: 8.85s\tremaining: 1m 34s\n",
      "86:\tlearn: 7.8932257\ttotal: 8.94s\tremaining: 1m 33s\n",
      "87:\tlearn: 7.8882922\ttotal: 9.04s\tremaining: 1m 33s\n",
      "88:\tlearn: 7.8808579\ttotal: 9.17s\tremaining: 1m 33s\n",
      "89:\tlearn: 7.8762458\ttotal: 9.26s\tremaining: 1m 33s\n",
      "90:\tlearn: 7.8709687\ttotal: 9.36s\tremaining: 1m 33s\n",
      "91:\tlearn: 7.8673215\ttotal: 9.45s\tremaining: 1m 33s\n",
      "92:\tlearn: 7.8617731\ttotal: 9.56s\tremaining: 1m 33s\n",
      "93:\tlearn: 7.8570077\ttotal: 9.65s\tremaining: 1m 33s\n",
      "94:\tlearn: 7.8518877\ttotal: 9.75s\tremaining: 1m 32s\n",
      "95:\tlearn: 7.8486568\ttotal: 9.84s\tremaining: 1m 32s\n",
      "96:\tlearn: 7.8440896\ttotal: 9.93s\tremaining: 1m 32s\n",
      "97:\tlearn: 7.8399980\ttotal: 10s\tremaining: 1m 32s\n",
      "98:\tlearn: 7.8363560\ttotal: 10.1s\tremaining: 1m 32s\n",
      "99:\tlearn: 7.8312911\ttotal: 10.2s\tremaining: 1m 31s\n",
      "100:\tlearn: 7.8270925\ttotal: 10.3s\tremaining: 1m 31s\n",
      "101:\tlearn: 7.8222954\ttotal: 10.4s\tremaining: 1m 31s\n",
      "102:\tlearn: 7.8185430\ttotal: 10.5s\tremaining: 1m 31s\n",
      "103:\tlearn: 7.8132435\ttotal: 10.6s\tremaining: 1m 31s\n",
      "104:\tlearn: 7.8081579\ttotal: 10.7s\tremaining: 1m 31s\n",
      "105:\tlearn: 7.8042141\ttotal: 10.8s\tremaining: 1m 30s\n",
      "106:\tlearn: 7.8004258\ttotal: 10.9s\tremaining: 1m 30s\n",
      "107:\tlearn: 7.7958708\ttotal: 11s\tremaining: 1m 30s\n",
      "108:\tlearn: 7.7910297\ttotal: 11.1s\tremaining: 1m 30s\n",
      "109:\tlearn: 7.7859447\ttotal: 11.2s\tremaining: 1m 30s\n",
      "110:\tlearn: 7.7810400\ttotal: 11.3s\tremaining: 1m 30s\n",
      "111:\tlearn: 7.7766390\ttotal: 11.4s\tremaining: 1m 30s\n",
      "112:\tlearn: 7.7718058\ttotal: 11.5s\tremaining: 1m 29s\n",
      "113:\tlearn: 7.7673770\ttotal: 11.6s\tremaining: 1m 29s\n",
      "114:\tlearn: 7.7636619\ttotal: 11.7s\tremaining: 1m 29s\n",
      "115:\tlearn: 7.7600314\ttotal: 11.7s\tremaining: 1m 29s\n",
      "116:\tlearn: 7.7564702\ttotal: 11.8s\tremaining: 1m 29s\n",
      "117:\tlearn: 7.7525198\ttotal: 11.9s\tremaining: 1m 29s\n",
      "118:\tlearn: 7.7484073\ttotal: 12s\tremaining: 1m 28s\n",
      "119:\tlearn: 7.7438504\ttotal: 12.1s\tremaining: 1m 28s\n",
      "120:\tlearn: 7.7395340\ttotal: 12.2s\tremaining: 1m 28s\n",
      "121:\tlearn: 7.7338191\ttotal: 12.3s\tremaining: 1m 28s\n",
      "122:\tlearn: 7.7304628\ttotal: 12.4s\tremaining: 1m 28s\n",
      "123:\tlearn: 7.7267156\ttotal: 12.5s\tremaining: 1m 28s\n",
      "124:\tlearn: 7.7234534\ttotal: 12.6s\tremaining: 1m 27s\n",
      "125:\tlearn: 7.7198154\ttotal: 12.6s\tremaining: 1m 27s\n",
      "126:\tlearn: 7.7165553\ttotal: 12.7s\tremaining: 1m 27s\n",
      "127:\tlearn: 7.7129240\ttotal: 12.8s\tremaining: 1m 27s\n",
      "128:\tlearn: 7.7094050\ttotal: 12.9s\tremaining: 1m 27s\n",
      "129:\tlearn: 7.7049966\ttotal: 13s\tremaining: 1m 27s\n",
      "130:\tlearn: 7.7018695\ttotal: 13.1s\tremaining: 1m 26s\n",
      "131:\tlearn: 7.6983437\ttotal: 13.2s\tremaining: 1m 26s\n",
      "132:\tlearn: 7.6942676\ttotal: 13.3s\tremaining: 1m 26s\n",
      "133:\tlearn: 7.6901506\ttotal: 13.4s\tremaining: 1m 26s\n",
      "134:\tlearn: 7.6860716\ttotal: 13.5s\tremaining: 1m 26s\n",
      "135:\tlearn: 7.6791894\ttotal: 13.6s\tremaining: 1m 26s\n",
      "136:\tlearn: 7.6747789\ttotal: 13.7s\tremaining: 1m 25s\n",
      "137:\tlearn: 7.6725512\ttotal: 13.7s\tremaining: 1m 25s\n",
      "138:\tlearn: 7.6699336\ttotal: 13.8s\tremaining: 1m 25s\n",
      "139:\tlearn: 7.6658341\ttotal: 13.9s\tremaining: 1m 25s\n",
      "140:\tlearn: 7.6609039\ttotal: 14s\tremaining: 1m 25s\n",
      "141:\tlearn: 7.6571199\ttotal: 14.1s\tremaining: 1m 25s\n",
      "142:\tlearn: 7.6538280\ttotal: 14.2s\tremaining: 1m 25s\n",
      "143:\tlearn: 7.6489584\ttotal: 14.3s\tremaining: 1m 24s\n",
      "144:\tlearn: 7.6453544\ttotal: 14.4s\tremaining: 1m 24s\n",
      "145:\tlearn: 7.6420779\ttotal: 14.5s\tremaining: 1m 24s\n",
      "146:\tlearn: 7.6384244\ttotal: 14.6s\tremaining: 1m 24s\n",
      "147:\tlearn: 7.6331061\ttotal: 14.6s\tremaining: 1m 24s\n",
      "148:\tlearn: 7.6297176\ttotal: 14.7s\tremaining: 1m 24s\n",
      "149:\tlearn: 7.6255607\ttotal: 14.8s\tremaining: 1m 23s\n",
      "150:\tlearn: 7.6214834\ttotal: 14.9s\tremaining: 1m 23s\n",
      "151:\tlearn: 7.6180179\ttotal: 15s\tremaining: 1m 23s\n",
      "152:\tlearn: 7.6142829\ttotal: 15.1s\tremaining: 1m 23s\n",
      "153:\tlearn: 7.6099927\ttotal: 15.2s\tremaining: 1m 23s\n",
      "154:\tlearn: 7.6052276\ttotal: 15.3s\tremaining: 1m 23s\n",
      "155:\tlearn: 7.6021739\ttotal: 15.4s\tremaining: 1m 23s\n",
      "156:\tlearn: 7.5976414\ttotal: 15.5s\tremaining: 1m 22s\n",
      "157:\tlearn: 7.5938706\ttotal: 15.5s\tremaining: 1m 22s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 7.5915433\ttotal: 15.6s\tremaining: 1m 22s\n",
      "159:\tlearn: 7.5877600\ttotal: 15.7s\tremaining: 1m 22s\n",
      "160:\tlearn: 7.5830655\ttotal: 15.8s\tremaining: 1m 22s\n",
      "161:\tlearn: 7.5763138\ttotal: 15.9s\tremaining: 1m 22s\n",
      "162:\tlearn: 7.5696005\ttotal: 16s\tremaining: 1m 21s\n",
      "163:\tlearn: 7.5658847\ttotal: 16s\tremaining: 1m 21s\n",
      "164:\tlearn: 7.5606342\ttotal: 16.1s\tremaining: 1m 21s\n",
      "165:\tlearn: 7.5566421\ttotal: 16.2s\tremaining: 1m 21s\n",
      "166:\tlearn: 7.5531860\ttotal: 16.3s\tremaining: 1m 21s\n",
      "167:\tlearn: 7.5491086\ttotal: 16.4s\tremaining: 1m 21s\n",
      "168:\tlearn: 7.5463080\ttotal: 16.5s\tremaining: 1m 20s\n",
      "169:\tlearn: 7.5432965\ttotal: 16.6s\tremaining: 1m 20s\n",
      "170:\tlearn: 7.5424781\ttotal: 16.6s\tremaining: 1m 20s\n",
      "171:\tlearn: 7.5371865\ttotal: 16.7s\tremaining: 1m 20s\n",
      "172:\tlearn: 7.5327116\ttotal: 16.8s\tremaining: 1m 20s\n",
      "173:\tlearn: 7.5282114\ttotal: 16.9s\tremaining: 1m 20s\n",
      "174:\tlearn: 7.5218957\ttotal: 17s\tremaining: 1m 20s\n",
      "175:\tlearn: 7.5184223\ttotal: 17.1s\tremaining: 1m 19s\n",
      "176:\tlearn: 7.5145800\ttotal: 17.2s\tremaining: 1m 19s\n",
      "177:\tlearn: 7.5097650\ttotal: 17.3s\tremaining: 1m 19s\n",
      "178:\tlearn: 7.5043664\ttotal: 17.4s\tremaining: 1m 19s\n",
      "179:\tlearn: 7.5035364\ttotal: 17.4s\tremaining: 1m 19s\n",
      "180:\tlearn: 7.5002464\ttotal: 17.5s\tremaining: 1m 19s\n",
      "181:\tlearn: 7.4991938\ttotal: 17.6s\tremaining: 1m 19s\n",
      "182:\tlearn: 7.4946880\ttotal: 17.7s\tremaining: 1m 19s\n",
      "183:\tlearn: 7.4898112\ttotal: 17.8s\tremaining: 1m 18s\n",
      "184:\tlearn: 7.4857713\ttotal: 17.9s\tremaining: 1m 18s\n",
      "185:\tlearn: 7.4812702\ttotal: 18s\tremaining: 1m 18s\n",
      "186:\tlearn: 7.4754446\ttotal: 18.1s\tremaining: 1m 18s\n",
      "187:\tlearn: 7.4705544\ttotal: 18.2s\tremaining: 1m 18s\n",
      "188:\tlearn: 7.4663129\ttotal: 18.2s\tremaining: 1m 18s\n",
      "189:\tlearn: 7.4619360\ttotal: 18.3s\tremaining: 1m 18s\n",
      "190:\tlearn: 7.4579774\ttotal: 18.4s\tremaining: 1m 17s\n",
      "191:\tlearn: 7.4544128\ttotal: 18.5s\tremaining: 1m 17s\n",
      "192:\tlearn: 7.4488681\ttotal: 18.6s\tremaining: 1m 17s\n",
      "193:\tlearn: 7.4457803\ttotal: 18.7s\tremaining: 1m 17s\n",
      "194:\tlearn: 7.4450810\ttotal: 18.8s\tremaining: 1m 17s\n",
      "195:\tlearn: 7.4388497\ttotal: 18.9s\tremaining: 1m 17s\n",
      "196:\tlearn: 7.4334578\ttotal: 19s\tremaining: 1m 17s\n",
      "197:\tlearn: 7.4296627\ttotal: 19.1s\tremaining: 1m 17s\n",
      "198:\tlearn: 7.4250981\ttotal: 19.2s\tremaining: 1m 17s\n",
      "199:\tlearn: 7.4206140\ttotal: 19.3s\tremaining: 1m 17s\n",
      "200:\tlearn: 7.4172008\ttotal: 19.4s\tremaining: 1m 17s\n",
      "201:\tlearn: 7.4126613\ttotal: 19.5s\tremaining: 1m 16s\n",
      "202:\tlearn: 7.4075827\ttotal: 19.6s\tremaining: 1m 16s\n",
      "203:\tlearn: 7.4042690\ttotal: 19.7s\tremaining: 1m 16s\n",
      "204:\tlearn: 7.3994753\ttotal: 19.8s\tremaining: 1m 16s\n",
      "205:\tlearn: 7.3950631\ttotal: 19.8s\tremaining: 1m 16s\n",
      "206:\tlearn: 7.3903278\ttotal: 19.9s\tremaining: 1m 16s\n",
      "207:\tlearn: 7.3850919\ttotal: 20s\tremaining: 1m 16s\n",
      "208:\tlearn: 7.3802141\ttotal: 20.1s\tremaining: 1m 16s\n",
      "209:\tlearn: 7.3746954\ttotal: 20.2s\tremaining: 1m 16s\n",
      "210:\tlearn: 7.3702938\ttotal: 20.4s\tremaining: 1m 16s\n",
      "211:\tlearn: 7.3667948\ttotal: 20.5s\tremaining: 1m 16s\n",
      "212:\tlearn: 7.3625923\ttotal: 20.6s\tremaining: 1m 16s\n",
      "213:\tlearn: 7.3612532\ttotal: 20.7s\tremaining: 1m 15s\n",
      "214:\tlearn: 7.3567207\ttotal: 20.8s\tremaining: 1m 15s\n",
      "215:\tlearn: 7.3519516\ttotal: 20.9s\tremaining: 1m 15s\n",
      "216:\tlearn: 7.3478132\ttotal: 20.9s\tremaining: 1m 15s\n",
      "217:\tlearn: 7.3442799\ttotal: 21.1s\tremaining: 1m 15s\n",
      "218:\tlearn: 7.3400535\ttotal: 21.1s\tremaining: 1m 15s\n",
      "219:\tlearn: 7.3355434\ttotal: 21.3s\tremaining: 1m 15s\n",
      "220:\tlearn: 7.3318968\ttotal: 21.4s\tremaining: 1m 15s\n",
      "221:\tlearn: 7.3274868\ttotal: 21.5s\tremaining: 1m 15s\n",
      "222:\tlearn: 7.3232964\ttotal: 21.6s\tremaining: 1m 15s\n",
      "223:\tlearn: 7.3193596\ttotal: 21.7s\tremaining: 1m 15s\n",
      "224:\tlearn: 7.3157590\ttotal: 21.7s\tremaining: 1m 14s\n",
      "225:\tlearn: 7.3121176\ttotal: 21.9s\tremaining: 1m 14s\n",
      "226:\tlearn: 7.3091869\ttotal: 22s\tremaining: 1m 14s\n",
      "227:\tlearn: 7.3059900\ttotal: 22.1s\tremaining: 1m 14s\n",
      "228:\tlearn: 7.3024401\ttotal: 22.2s\tremaining: 1m 14s\n",
      "229:\tlearn: 7.2977398\ttotal: 22.3s\tremaining: 1m 14s\n",
      "230:\tlearn: 7.2926609\ttotal: 22.3s\tremaining: 1m 14s\n",
      "231:\tlearn: 7.2884717\ttotal: 22.4s\tremaining: 1m 14s\n",
      "232:\tlearn: 7.2847384\ttotal: 22.5s\tremaining: 1m 14s\n",
      "233:\tlearn: 7.2797661\ttotal: 22.6s\tremaining: 1m 14s\n",
      "234:\tlearn: 7.2761136\ttotal: 22.7s\tremaining: 1m 14s\n",
      "235:\tlearn: 7.2711204\ttotal: 22.9s\tremaining: 1m 14s\n",
      "236:\tlearn: 7.2667877\ttotal: 22.9s\tremaining: 1m 13s\n",
      "237:\tlearn: 7.2619264\ttotal: 23s\tremaining: 1m 13s\n",
      "238:\tlearn: 7.2577116\ttotal: 23.1s\tremaining: 1m 13s\n",
      "239:\tlearn: 7.2540094\ttotal: 23.3s\tremaining: 1m 13s\n",
      "240:\tlearn: 7.2500154\ttotal: 23.4s\tremaining: 1m 13s\n",
      "241:\tlearn: 7.2450917\ttotal: 23.5s\tremaining: 1m 13s\n",
      "242:\tlearn: 7.2409570\ttotal: 23.5s\tremaining: 1m 13s\n",
      "243:\tlearn: 7.2371143\ttotal: 23.6s\tremaining: 1m 13s\n",
      "244:\tlearn: 7.2336510\ttotal: 23.7s\tremaining: 1m 13s\n",
      "245:\tlearn: 7.2291430\ttotal: 23.8s\tremaining: 1m 13s\n",
      "246:\tlearn: 7.2249702\ttotal: 23.9s\tremaining: 1m 12s\n",
      "247:\tlearn: 7.2209908\ttotal: 24s\tremaining: 1m 12s\n",
      "248:\tlearn: 7.2177096\ttotal: 24.1s\tremaining: 1m 12s\n",
      "249:\tlearn: 7.2147782\ttotal: 24.2s\tremaining: 1m 12s\n",
      "250:\tlearn: 7.2114477\ttotal: 24.3s\tremaining: 1m 12s\n",
      "251:\tlearn: 7.2074187\ttotal: 24.4s\tremaining: 1m 12s\n",
      "252:\tlearn: 7.2028680\ttotal: 24.5s\tremaining: 1m 12s\n",
      "253:\tlearn: 7.2017238\ttotal: 24.6s\tremaining: 1m 12s\n",
      "254:\tlearn: 7.1969958\ttotal: 24.7s\tremaining: 1m 12s\n",
      "255:\tlearn: 7.1929849\ttotal: 24.8s\tremaining: 1m 12s\n",
      "256:\tlearn: 7.1884829\ttotal: 24.9s\tremaining: 1m 11s\n",
      "257:\tlearn: 7.1840934\ttotal: 25s\tremaining: 1m 11s\n",
      "258:\tlearn: 7.1800694\ttotal: 25.1s\tremaining: 1m 11s\n",
      "259:\tlearn: 7.1755647\ttotal: 25.2s\tremaining: 1m 11s\n",
      "260:\tlearn: 7.1717386\ttotal: 25.3s\tremaining: 1m 11s\n",
      "261:\tlearn: 7.1670521\ttotal: 25.4s\tremaining: 1m 11s\n",
      "262:\tlearn: 7.1626740\ttotal: 25.5s\tremaining: 1m 11s\n",
      "263:\tlearn: 7.1573363\ttotal: 25.6s\tremaining: 1m 11s\n",
      "264:\tlearn: 7.1534287\ttotal: 25.7s\tremaining: 1m 11s\n",
      "265:\tlearn: 7.1495287\ttotal: 25.7s\tremaining: 1m 11s\n",
      "266:\tlearn: 7.1456075\ttotal: 25.8s\tremaining: 1m 10s\n",
      "267:\tlearn: 7.1419561\ttotal: 25.9s\tremaining: 1m 10s\n",
      "268:\tlearn: 7.1376414\ttotal: 26s\tremaining: 1m 10s\n",
      "269:\tlearn: 7.1332031\ttotal: 26.1s\tremaining: 1m 10s\n",
      "270:\tlearn: 7.1284224\ttotal: 26.2s\tremaining: 1m 10s\n",
      "271:\tlearn: 7.1253336\ttotal: 26.3s\tremaining: 1m 10s\n",
      "272:\tlearn: 7.1226231\ttotal: 26.4s\tremaining: 1m 10s\n",
      "273:\tlearn: 7.1221906\ttotal: 26.5s\tremaining: 1m 10s\n",
      "274:\tlearn: 7.1185517\ttotal: 26.6s\tremaining: 1m 9s\n",
      "275:\tlearn: 7.1141058\ttotal: 26.6s\tremaining: 1m 9s\n",
      "276:\tlearn: 7.1088630\ttotal: 26.7s\tremaining: 1m 9s\n",
      "277:\tlearn: 7.1049744\ttotal: 26.8s\tremaining: 1m 9s\n",
      "278:\tlearn: 7.1040856\ttotal: 26.9s\tremaining: 1m 9s\n",
      "279:\tlearn: 7.0996826\ttotal: 27s\tremaining: 1m 9s\n",
      "280:\tlearn: 7.0959251\ttotal: 27.1s\tremaining: 1m 9s\n",
      "281:\tlearn: 7.0932875\ttotal: 27.2s\tremaining: 1m 9s\n",
      "282:\tlearn: 7.0885652\ttotal: 27.3s\tremaining: 1m 9s\n",
      "283:\tlearn: 7.0845100\ttotal: 27.4s\tremaining: 1m 9s\n",
      "284:\tlearn: 7.0811595\ttotal: 27.5s\tremaining: 1m 8s\n",
      "285:\tlearn: 7.0778419\ttotal: 27.6s\tremaining: 1m 8s\n",
      "286:\tlearn: 7.0738639\ttotal: 27.6s\tremaining: 1m 8s\n",
      "287:\tlearn: 7.0703882\ttotal: 27.7s\tremaining: 1m 8s\n",
      "288:\tlearn: 7.0667069\ttotal: 27.8s\tremaining: 1m 8s\n",
      "289:\tlearn: 7.0635587\ttotal: 27.9s\tremaining: 1m 8s\n",
      "290:\tlearn: 7.0590223\ttotal: 28s\tremaining: 1m 8s\n",
      "291:\tlearn: 7.0555420\ttotal: 28.1s\tremaining: 1m 8s\n",
      "292:\tlearn: 7.0523684\ttotal: 28.2s\tremaining: 1m 7s\n",
      "293:\tlearn: 7.0515507\ttotal: 28.3s\tremaining: 1m 7s\n",
      "294:\tlearn: 7.0475469\ttotal: 28.3s\tremaining: 1m 7s\n",
      "295:\tlearn: 7.0441187\ttotal: 28.4s\tremaining: 1m 7s\n",
      "296:\tlearn: 7.0406911\ttotal: 28.5s\tremaining: 1m 7s\n",
      "297:\tlearn: 7.0377172\ttotal: 28.6s\tremaining: 1m 7s\n",
      "298:\tlearn: 7.0339900\ttotal: 28.7s\tremaining: 1m 7s\n",
      "299:\tlearn: 7.0300644\ttotal: 28.8s\tremaining: 1m 7s\n",
      "300:\tlearn: 7.0265732\ttotal: 28.9s\tremaining: 1m 7s\n",
      "301:\tlearn: 7.0235058\ttotal: 29s\tremaining: 1m 7s\n",
      "302:\tlearn: 7.0189088\ttotal: 29.1s\tremaining: 1m 6s\n",
      "303:\tlearn: 7.0157060\ttotal: 29.2s\tremaining: 1m 6s\n",
      "304:\tlearn: 7.0103641\ttotal: 29.3s\tremaining: 1m 6s\n",
      "305:\tlearn: 7.0051386\ttotal: 29.4s\tremaining: 1m 6s\n",
      "306:\tlearn: 7.0011874\ttotal: 29.5s\tremaining: 1m 6s\n",
      "307:\tlearn: 6.9963847\ttotal: 29.6s\tremaining: 1m 6s\n",
      "308:\tlearn: 6.9917210\ttotal: 29.7s\tremaining: 1m 6s\n",
      "309:\tlearn: 6.9878013\ttotal: 29.8s\tremaining: 1m 6s\n",
      "310:\tlearn: 6.9831501\ttotal: 29.9s\tremaining: 1m 6s\n",
      "311:\tlearn: 6.9796308\ttotal: 30s\tremaining: 1m 6s\n",
      "312:\tlearn: 6.9767103\ttotal: 30.1s\tremaining: 1m 6s\n",
      "313:\tlearn: 6.9732255\ttotal: 30.2s\tremaining: 1m 5s\n",
      "314:\tlearn: 6.9694733\ttotal: 30.3s\tremaining: 1m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315:\tlearn: 6.9649485\ttotal: 30.4s\tremaining: 1m 5s\n",
      "316:\tlearn: 6.9623911\ttotal: 30.5s\tremaining: 1m 5s\n",
      "317:\tlearn: 6.9589458\ttotal: 30.6s\tremaining: 1m 5s\n",
      "318:\tlearn: 6.9556468\ttotal: 30.7s\tremaining: 1m 5s\n",
      "319:\tlearn: 6.9519858\ttotal: 30.8s\tremaining: 1m 5s\n",
      "320:\tlearn: 6.9491255\ttotal: 30.9s\tremaining: 1m 5s\n",
      "321:\tlearn: 6.9465859\ttotal: 31s\tremaining: 1m 5s\n",
      "322:\tlearn: 6.9427832\ttotal: 31.1s\tremaining: 1m 5s\n",
      "323:\tlearn: 6.9386595\ttotal: 31.2s\tremaining: 1m 5s\n",
      "324:\tlearn: 6.9351897\ttotal: 31.3s\tremaining: 1m 4s\n",
      "325:\tlearn: 6.9320713\ttotal: 31.4s\tremaining: 1m 4s\n",
      "326:\tlearn: 6.9268890\ttotal: 31.4s\tremaining: 1m 4s\n",
      "327:\tlearn: 6.9234112\ttotal: 31.5s\tremaining: 1m 4s\n",
      "328:\tlearn: 6.9199019\ttotal: 31.6s\tremaining: 1m 4s\n",
      "329:\tlearn: 6.9151750\ttotal: 31.7s\tremaining: 1m 4s\n",
      "330:\tlearn: 6.9126868\ttotal: 31.8s\tremaining: 1m 4s\n",
      "331:\tlearn: 6.9080644\ttotal: 31.9s\tremaining: 1m 4s\n",
      "332:\tlearn: 6.9044339\ttotal: 32s\tremaining: 1m 4s\n",
      "333:\tlearn: 6.8995465\ttotal: 32.1s\tremaining: 1m 4s\n",
      "334:\tlearn: 6.8971108\ttotal: 32.2s\tremaining: 1m 4s\n",
      "335:\tlearn: 6.8929059\ttotal: 32.3s\tremaining: 1m 3s\n",
      "336:\tlearn: 6.8891233\ttotal: 32.4s\tremaining: 1m 3s\n",
      "337:\tlearn: 6.8865415\ttotal: 32.5s\tremaining: 1m 3s\n",
      "338:\tlearn: 6.8823328\ttotal: 32.6s\tremaining: 1m 3s\n",
      "339:\tlearn: 6.8791050\ttotal: 32.7s\tremaining: 1m 3s\n",
      "340:\tlearn: 6.8752537\ttotal: 32.8s\tremaining: 1m 3s\n",
      "341:\tlearn: 6.8715097\ttotal: 32.9s\tremaining: 1m 3s\n",
      "342:\tlearn: 6.8686727\ttotal: 33s\tremaining: 1m 3s\n",
      "343:\tlearn: 6.8656202\ttotal: 33.1s\tremaining: 1m 3s\n",
      "344:\tlearn: 6.8623035\ttotal: 33.2s\tremaining: 1m 2s\n",
      "345:\tlearn: 6.8572723\ttotal: 33.3s\tremaining: 1m 2s\n",
      "346:\tlearn: 6.8528458\ttotal: 33.4s\tremaining: 1m 2s\n",
      "347:\tlearn: 6.8483942\ttotal: 33.5s\tremaining: 1m 2s\n",
      "348:\tlearn: 6.8452110\ttotal: 33.6s\tremaining: 1m 2s\n",
      "349:\tlearn: 6.8410511\ttotal: 33.7s\tremaining: 1m 2s\n",
      "350:\tlearn: 6.8381014\ttotal: 33.8s\tremaining: 1m 2s\n",
      "351:\tlearn: 6.8375568\ttotal: 33.9s\tremaining: 1m 2s\n",
      "352:\tlearn: 6.8327612\ttotal: 33.9s\tremaining: 1m 2s\n",
      "353:\tlearn: 6.8282139\ttotal: 34s\tremaining: 1m 2s\n",
      "354:\tlearn: 6.8246455\ttotal: 34.1s\tremaining: 1m 2s\n",
      "355:\tlearn: 6.8213316\ttotal: 34.2s\tremaining: 1m 1s\n",
      "356:\tlearn: 6.8172727\ttotal: 34.3s\tremaining: 1m 1s\n",
      "357:\tlearn: 6.8137497\ttotal: 34.4s\tremaining: 1m 1s\n",
      "358:\tlearn: 6.8101637\ttotal: 34.5s\tremaining: 1m 1s\n",
      "359:\tlearn: 6.8062185\ttotal: 34.6s\tremaining: 1m 1s\n",
      "360:\tlearn: 6.8031842\ttotal: 34.7s\tremaining: 1m 1s\n",
      "361:\tlearn: 6.7987772\ttotal: 34.8s\tremaining: 1m 1s\n",
      "362:\tlearn: 6.7967008\ttotal: 34.9s\tremaining: 1m 1s\n",
      "363:\tlearn: 6.7935293\ttotal: 35s\tremaining: 1m 1s\n",
      "364:\tlearn: 6.7894380\ttotal: 35.1s\tremaining: 1m 1s\n",
      "365:\tlearn: 6.7865923\ttotal: 35.2s\tremaining: 1m\n",
      "366:\tlearn: 6.7861201\ttotal: 35.3s\tremaining: 1m\n",
      "367:\tlearn: 6.7837302\ttotal: 35.4s\tremaining: 1m\n",
      "368:\tlearn: 6.7815819\ttotal: 35.5s\tremaining: 1m\n",
      "369:\tlearn: 6.7780845\ttotal: 35.5s\tremaining: 1m\n",
      "370:\tlearn: 6.7752248\ttotal: 35.6s\tremaining: 1m\n",
      "371:\tlearn: 6.7723297\ttotal: 35.7s\tremaining: 1m\n",
      "372:\tlearn: 6.7681067\ttotal: 35.8s\tremaining: 1m\n",
      "373:\tlearn: 6.7642201\ttotal: 35.9s\tremaining: 1m\n",
      "374:\tlearn: 6.7608579\ttotal: 36s\tremaining: 60s\n",
      "375:\tlearn: 6.7571907\ttotal: 36.1s\tremaining: 59.9s\n",
      "376:\tlearn: 6.7544745\ttotal: 36.2s\tremaining: 59.8s\n",
      "377:\tlearn: 6.7513313\ttotal: 36.3s\tremaining: 59.7s\n",
      "378:\tlearn: 6.7479633\ttotal: 36.3s\tremaining: 59.5s\n",
      "379:\tlearn: 6.7441248\ttotal: 36.4s\tremaining: 59.4s\n",
      "380:\tlearn: 6.7400426\ttotal: 36.5s\tremaining: 59.3s\n",
      "381:\tlearn: 6.7358595\ttotal: 36.6s\tremaining: 59.3s\n",
      "382:\tlearn: 6.7329805\ttotal: 36.7s\tremaining: 59.2s\n",
      "383:\tlearn: 6.7287928\ttotal: 36.8s\tremaining: 59.1s\n",
      "384:\tlearn: 6.7256600\ttotal: 36.9s\tremaining: 59s\n",
      "385:\tlearn: 6.7219455\ttotal: 37s\tremaining: 58.9s\n",
      "386:\tlearn: 6.7180539\ttotal: 37.1s\tremaining: 58.8s\n",
      "387:\tlearn: 6.7134870\ttotal: 37.2s\tremaining: 58.7s\n",
      "388:\tlearn: 6.7102104\ttotal: 37.3s\tremaining: 58.6s\n",
      "389:\tlearn: 6.7066834\ttotal: 37.4s\tremaining: 58.5s\n",
      "390:\tlearn: 6.7036670\ttotal: 37.5s\tremaining: 58.4s\n",
      "391:\tlearn: 6.7018998\ttotal: 37.6s\tremaining: 58.3s\n",
      "392:\tlearn: 6.6987642\ttotal: 37.7s\tremaining: 58.2s\n",
      "393:\tlearn: 6.6944675\ttotal: 37.8s\tremaining: 58.1s\n",
      "394:\tlearn: 6.6908703\ttotal: 37.8s\tremaining: 58s\n",
      "395:\tlearn: 6.6866440\ttotal: 37.9s\tremaining: 57.9s\n",
      "396:\tlearn: 6.6838128\ttotal: 38s\tremaining: 57.8s\n",
      "397:\tlearn: 6.6809305\ttotal: 38.1s\tremaining: 57.7s\n",
      "398:\tlearn: 6.6770689\ttotal: 38.2s\tremaining: 57.5s\n",
      "399:\tlearn: 6.6738930\ttotal: 38.3s\tremaining: 57.5s\n",
      "400:\tlearn: 6.6707971\ttotal: 38.4s\tremaining: 57.3s\n",
      "401:\tlearn: 6.6669119\ttotal: 38.5s\tremaining: 57.3s\n",
      "402:\tlearn: 6.6635469\ttotal: 38.6s\tremaining: 57.1s\n",
      "403:\tlearn: 6.6600870\ttotal: 38.7s\tremaining: 57s\n",
      "404:\tlearn: 6.6557082\ttotal: 38.8s\tremaining: 56.9s\n",
      "405:\tlearn: 6.6522384\ttotal: 38.8s\tremaining: 56.8s\n",
      "406:\tlearn: 6.6475366\ttotal: 38.9s\tremaining: 56.7s\n",
      "407:\tlearn: 6.6449044\ttotal: 39s\tremaining: 56.6s\n",
      "408:\tlearn: 6.6423692\ttotal: 39.1s\tremaining: 56.5s\n",
      "409:\tlearn: 6.6372871\ttotal: 39.2s\tremaining: 56.4s\n",
      "410:\tlearn: 6.6348186\ttotal: 39.3s\tremaining: 56.3s\n",
      "411:\tlearn: 6.6317030\ttotal: 39.4s\tremaining: 56.2s\n",
      "412:\tlearn: 6.6275757\ttotal: 39.5s\tremaining: 56.1s\n",
      "413:\tlearn: 6.6241545\ttotal: 39.6s\tremaining: 56s\n",
      "414:\tlearn: 6.6204320\ttotal: 39.6s\tremaining: 55.9s\n",
      "415:\tlearn: 6.6175785\ttotal: 39.7s\tremaining: 55.8s\n",
      "416:\tlearn: 6.6131792\ttotal: 39.8s\tremaining: 55.7s\n",
      "417:\tlearn: 6.6086117\ttotal: 39.9s\tremaining: 55.5s\n",
      "418:\tlearn: 6.6055207\ttotal: 40s\tremaining: 55.4s\n",
      "419:\tlearn: 6.6029399\ttotal: 40.1s\tremaining: 55.3s\n",
      "420:\tlearn: 6.5998130\ttotal: 40.1s\tremaining: 55.2s\n",
      "421:\tlearn: 6.5994113\ttotal: 40.2s\tremaining: 55.1s\n",
      "422:\tlearn: 6.5965441\ttotal: 40.3s\tremaining: 55s\n",
      "423:\tlearn: 6.5928780\ttotal: 40.4s\tremaining: 54.9s\n",
      "424:\tlearn: 6.5896084\ttotal: 40.5s\tremaining: 54.8s\n",
      "425:\tlearn: 6.5864440\ttotal: 40.6s\tremaining: 54.6s\n",
      "426:\tlearn: 6.5822259\ttotal: 40.6s\tremaining: 54.5s\n",
      "427:\tlearn: 6.5792935\ttotal: 40.7s\tremaining: 54.4s\n",
      "428:\tlearn: 6.5758652\ttotal: 40.8s\tremaining: 54.3s\n",
      "429:\tlearn: 6.5722585\ttotal: 40.9s\tremaining: 54.2s\n",
      "430:\tlearn: 6.5693048\ttotal: 41s\tremaining: 54.1s\n",
      "431:\tlearn: 6.5656558\ttotal: 41.1s\tremaining: 54s\n",
      "432:\tlearn: 6.5627544\ttotal: 41.2s\tremaining: 53.9s\n",
      "433:\tlearn: 6.5598602\ttotal: 41.3s\tremaining: 53.8s\n",
      "434:\tlearn: 6.5548258\ttotal: 41.4s\tremaining: 53.8s\n",
      "435:\tlearn: 6.5515367\ttotal: 41.5s\tremaining: 53.7s\n",
      "436:\tlearn: 6.5493131\ttotal: 41.6s\tremaining: 53.6s\n",
      "437:\tlearn: 6.5468843\ttotal: 41.7s\tremaining: 53.5s\n",
      "438:\tlearn: 6.5432541\ttotal: 41.8s\tremaining: 53.4s\n",
      "439:\tlearn: 6.5408774\ttotal: 41.9s\tremaining: 53.3s\n",
      "440:\tlearn: 6.5381931\ttotal: 41.9s\tremaining: 53.2s\n",
      "441:\tlearn: 6.5339896\ttotal: 42s\tremaining: 53.1s\n",
      "442:\tlearn: 6.5313634\ttotal: 42.1s\tremaining: 53s\n",
      "443:\tlearn: 6.5284384\ttotal: 42.2s\tremaining: 52.9s\n",
      "444:\tlearn: 6.5264248\ttotal: 42.3s\tremaining: 52.8s\n",
      "445:\tlearn: 6.5228641\ttotal: 42.4s\tremaining: 52.7s\n",
      "446:\tlearn: 6.5197763\ttotal: 42.5s\tremaining: 52.6s\n",
      "447:\tlearn: 6.5170163\ttotal: 42.6s\tremaining: 52.5s\n",
      "448:\tlearn: 6.5140709\ttotal: 42.7s\tremaining: 52.4s\n",
      "449:\tlearn: 6.5109445\ttotal: 42.8s\tremaining: 52.3s\n",
      "450:\tlearn: 6.5070066\ttotal: 42.9s\tremaining: 52.2s\n",
      "451:\tlearn: 6.5031492\ttotal: 43s\tremaining: 52.1s\n",
      "452:\tlearn: 6.5006762\ttotal: 43.1s\tremaining: 52s\n",
      "453:\tlearn: 6.4956166\ttotal: 43.2s\tremaining: 51.9s\n",
      "454:\tlearn: 6.4914895\ttotal: 43.3s\tremaining: 51.8s\n",
      "455:\tlearn: 6.4883818\ttotal: 43.4s\tremaining: 51.7s\n",
      "456:\tlearn: 6.4845461\ttotal: 43.5s\tremaining: 51.6s\n",
      "457:\tlearn: 6.4807085\ttotal: 43.6s\tremaining: 51.5s\n",
      "458:\tlearn: 6.4782015\ttotal: 43.6s\tremaining: 51.4s\n",
      "459:\tlearn: 6.4757645\ttotal: 43.7s\tremaining: 51.3s\n",
      "460:\tlearn: 6.4730492\ttotal: 43.8s\tremaining: 51.2s\n",
      "461:\tlearn: 6.4703503\ttotal: 43.9s\tremaining: 51.1s\n",
      "462:\tlearn: 6.4681830\ttotal: 44s\tremaining: 51.1s\n",
      "463:\tlearn: 6.4635377\ttotal: 44.1s\tremaining: 51s\n",
      "464:\tlearn: 6.4609702\ttotal: 44.2s\tremaining: 50.9s\n",
      "465:\tlearn: 6.4575159\ttotal: 44.3s\tremaining: 50.8s\n",
      "466:\tlearn: 6.4542648\ttotal: 44.4s\tremaining: 50.7s\n",
      "467:\tlearn: 6.4514839\ttotal: 44.5s\tremaining: 50.6s\n",
      "468:\tlearn: 6.4490619\ttotal: 44.6s\tremaining: 50.5s\n",
      "469:\tlearn: 6.4462706\ttotal: 44.7s\tremaining: 50.4s\n",
      "470:\tlearn: 6.4429795\ttotal: 44.8s\tremaining: 50.3s\n",
      "471:\tlearn: 6.4395984\ttotal: 44.9s\tremaining: 50.2s\n",
      "472:\tlearn: 6.4362032\ttotal: 45s\tremaining: 50.2s\n",
      "473:\tlearn: 6.4328128\ttotal: 45.1s\tremaining: 50.1s\n",
      "474:\tlearn: 6.4287587\ttotal: 45.2s\tremaining: 50s\n",
      "475:\tlearn: 6.4256131\ttotal: 45.3s\tremaining: 49.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476:\tlearn: 6.4212062\ttotal: 45.4s\tremaining: 49.8s\n",
      "477:\tlearn: 6.4207291\ttotal: 45.5s\tremaining: 49.7s\n",
      "478:\tlearn: 6.4179917\ttotal: 45.6s\tremaining: 49.6s\n",
      "479:\tlearn: 6.4149576\ttotal: 45.7s\tremaining: 49.5s\n",
      "480:\tlearn: 6.4122710\ttotal: 45.8s\tremaining: 49.5s\n",
      "481:\tlearn: 6.4105021\ttotal: 45.9s\tremaining: 49.4s\n",
      "482:\tlearn: 6.4083347\ttotal: 46s\tremaining: 49.3s\n",
      "483:\tlearn: 6.4045553\ttotal: 46.1s\tremaining: 49.2s\n",
      "484:\tlearn: 6.4018042\ttotal: 46.2s\tremaining: 49.1s\n",
      "485:\tlearn: 6.3993758\ttotal: 46.3s\tremaining: 49s\n",
      "486:\tlearn: 6.3953072\ttotal: 46.4s\tremaining: 48.9s\n",
      "487:\tlearn: 6.3929632\ttotal: 46.5s\tremaining: 48.8s\n",
      "488:\tlearn: 6.3890341\ttotal: 46.6s\tremaining: 48.7s\n",
      "489:\tlearn: 6.3865454\ttotal: 46.7s\tremaining: 48.6s\n",
      "490:\tlearn: 6.3834215\ttotal: 46.8s\tremaining: 48.5s\n",
      "491:\tlearn: 6.3795081\ttotal: 46.9s\tremaining: 48.4s\n",
      "492:\tlearn: 6.3769560\ttotal: 47s\tremaining: 48.3s\n",
      "493:\tlearn: 6.3742020\ttotal: 47.1s\tremaining: 48.2s\n",
      "494:\tlearn: 6.3714135\ttotal: 47.2s\tremaining: 48.1s\n",
      "495:\tlearn: 6.3672140\ttotal: 47.3s\tremaining: 48s\n",
      "496:\tlearn: 6.3630212\ttotal: 47.4s\tremaining: 47.9s\n",
      "497:\tlearn: 6.3593463\ttotal: 47.5s\tremaining: 47.8s\n",
      "498:\tlearn: 6.3559850\ttotal: 47.5s\tremaining: 47.7s\n",
      "499:\tlearn: 6.3530814\ttotal: 47.6s\tremaining: 47.6s\n",
      "500:\tlearn: 6.3500120\ttotal: 47.7s\tremaining: 47.5s\n",
      "501:\tlearn: 6.3479534\ttotal: 47.8s\tremaining: 47.4s\n",
      "502:\tlearn: 6.3440269\ttotal: 47.9s\tremaining: 47.3s\n",
      "503:\tlearn: 6.3437039\ttotal: 48s\tremaining: 47.2s\n",
      "504:\tlearn: 6.3398862\ttotal: 48.1s\tremaining: 47.1s\n",
      "505:\tlearn: 6.3361956\ttotal: 48.2s\tremaining: 47s\n",
      "506:\tlearn: 6.3332287\ttotal: 48.3s\tremaining: 46.9s\n",
      "507:\tlearn: 6.3300001\ttotal: 48.3s\tremaining: 46.8s\n",
      "508:\tlearn: 6.3278965\ttotal: 48.4s\tremaining: 46.7s\n",
      "509:\tlearn: 6.3244909\ttotal: 48.5s\tremaining: 46.6s\n",
      "510:\tlearn: 6.3212761\ttotal: 48.6s\tremaining: 46.5s\n",
      "511:\tlearn: 6.3193832\ttotal: 48.7s\tremaining: 46.4s\n",
      "512:\tlearn: 6.3160888\ttotal: 48.8s\tremaining: 46.3s\n",
      "513:\tlearn: 6.3133285\ttotal: 48.9s\tremaining: 46.2s\n",
      "514:\tlearn: 6.3097936\ttotal: 49s\tremaining: 46.1s\n",
      "515:\tlearn: 6.3067334\ttotal: 49.1s\tremaining: 46s\n",
      "516:\tlearn: 6.3036750\ttotal: 49.1s\tremaining: 45.9s\n",
      "517:\tlearn: 6.3025825\ttotal: 49.2s\tremaining: 45.8s\n",
      "518:\tlearn: 6.2994445\ttotal: 49.3s\tremaining: 45.7s\n",
      "519:\tlearn: 6.2954172\ttotal: 49.4s\tremaining: 45.6s\n",
      "520:\tlearn: 6.2930568\ttotal: 49.5s\tremaining: 45.5s\n",
      "521:\tlearn: 6.2911937\ttotal: 49.6s\tremaining: 45.4s\n",
      "522:\tlearn: 6.2881374\ttotal: 49.7s\tremaining: 45.3s\n",
      "523:\tlearn: 6.2841850\ttotal: 49.8s\tremaining: 45.2s\n",
      "524:\tlearn: 6.2821920\ttotal: 49.9s\tremaining: 45.1s\n",
      "525:\tlearn: 6.2793774\ttotal: 49.9s\tremaining: 45s\n",
      "526:\tlearn: 6.2760856\ttotal: 50s\tremaining: 44.9s\n",
      "527:\tlearn: 6.2735766\ttotal: 50.1s\tremaining: 44.8s\n",
      "528:\tlearn: 6.2699722\ttotal: 50.2s\tremaining: 44.7s\n",
      "529:\tlearn: 6.2671738\ttotal: 50.3s\tremaining: 44.6s\n",
      "530:\tlearn: 6.2638701\ttotal: 50.4s\tremaining: 44.5s\n",
      "531:\tlearn: 6.2601640\ttotal: 50.5s\tremaining: 44.4s\n",
      "532:\tlearn: 6.2577611\ttotal: 50.6s\tremaining: 44.3s\n",
      "533:\tlearn: 6.2549490\ttotal: 50.7s\tremaining: 44.2s\n",
      "534:\tlearn: 6.2517498\ttotal: 50.8s\tremaining: 44.1s\n",
      "535:\tlearn: 6.2493241\ttotal: 50.9s\tremaining: 44s\n",
      "536:\tlearn: 6.2457660\ttotal: 51s\tremaining: 43.9s\n",
      "537:\tlearn: 6.2427674\ttotal: 51s\tremaining: 43.8s\n",
      "538:\tlearn: 6.2395088\ttotal: 51.1s\tremaining: 43.7s\n",
      "539:\tlearn: 6.2363809\ttotal: 51.2s\tremaining: 43.6s\n",
      "540:\tlearn: 6.2336546\ttotal: 51.3s\tremaining: 43.5s\n",
      "541:\tlearn: 6.2317416\ttotal: 51.4s\tremaining: 43.4s\n",
      "542:\tlearn: 6.2273691\ttotal: 51.5s\tremaining: 43.3s\n",
      "543:\tlearn: 6.2246233\ttotal: 51.6s\tremaining: 43.2s\n",
      "544:\tlearn: 6.2216667\ttotal: 51.6s\tremaining: 43.1s\n",
      "545:\tlearn: 6.2187641\ttotal: 51.7s\tremaining: 43s\n",
      "546:\tlearn: 6.2153953\ttotal: 51.8s\tremaining: 42.9s\n",
      "547:\tlearn: 6.2118604\ttotal: 51.9s\tremaining: 42.8s\n",
      "548:\tlearn: 6.2078284\ttotal: 52s\tremaining: 42.7s\n",
      "549:\tlearn: 6.2041737\ttotal: 52.1s\tremaining: 42.6s\n",
      "550:\tlearn: 6.2018129\ttotal: 52.1s\tremaining: 42.5s\n",
      "551:\tlearn: 6.1988216\ttotal: 52.2s\tremaining: 42.4s\n",
      "552:\tlearn: 6.1952306\ttotal: 52.3s\tremaining: 42.3s\n",
      "553:\tlearn: 6.1928387\ttotal: 52.4s\tremaining: 42.2s\n",
      "554:\tlearn: 6.1914561\ttotal: 52.5s\tremaining: 42.1s\n",
      "555:\tlearn: 6.1888934\ttotal: 52.6s\tremaining: 42s\n",
      "556:\tlearn: 6.1845480\ttotal: 52.7s\tremaining: 41.9s\n",
      "557:\tlearn: 6.1807686\ttotal: 52.8s\tremaining: 41.8s\n",
      "558:\tlearn: 6.1764267\ttotal: 52.9s\tremaining: 41.7s\n",
      "559:\tlearn: 6.1734071\ttotal: 52.9s\tremaining: 41.6s\n",
      "560:\tlearn: 6.1709508\ttotal: 53s\tremaining: 41.5s\n",
      "561:\tlearn: 6.1677312\ttotal: 53.1s\tremaining: 41.4s\n",
      "562:\tlearn: 6.1641021\ttotal: 53.2s\tremaining: 41.3s\n",
      "563:\tlearn: 6.1609107\ttotal: 53.3s\tremaining: 41.2s\n",
      "564:\tlearn: 6.1581647\ttotal: 53.4s\tremaining: 41.1s\n",
      "565:\tlearn: 6.1554241\ttotal: 53.5s\tremaining: 41s\n",
      "566:\tlearn: 6.1518991\ttotal: 53.6s\tremaining: 40.9s\n",
      "567:\tlearn: 6.1486806\ttotal: 53.7s\tremaining: 40.8s\n",
      "568:\tlearn: 6.1458003\ttotal: 53.8s\tremaining: 40.7s\n",
      "569:\tlearn: 6.1433505\ttotal: 53.8s\tremaining: 40.6s\n",
      "570:\tlearn: 6.1416692\ttotal: 53.9s\tremaining: 40.5s\n",
      "571:\tlearn: 6.1383665\ttotal: 54s\tremaining: 40.4s\n",
      "572:\tlearn: 6.1343925\ttotal: 54.1s\tremaining: 40.3s\n",
      "573:\tlearn: 6.1321618\ttotal: 54.2s\tremaining: 40.2s\n",
      "574:\tlearn: 6.1300342\ttotal: 54.3s\tremaining: 40.1s\n",
      "575:\tlearn: 6.1257590\ttotal: 54.4s\tremaining: 40s\n",
      "576:\tlearn: 6.1229235\ttotal: 54.5s\tremaining: 39.9s\n",
      "577:\tlearn: 6.1198948\ttotal: 54.6s\tremaining: 39.8s\n",
      "578:\tlearn: 6.1156652\ttotal: 54.6s\tremaining: 39.7s\n",
      "579:\tlearn: 6.1129006\ttotal: 54.7s\tremaining: 39.6s\n",
      "580:\tlearn: 6.1107770\ttotal: 54.8s\tremaining: 39.5s\n",
      "581:\tlearn: 6.1065613\ttotal: 54.9s\tremaining: 39.4s\n",
      "582:\tlearn: 6.1032708\ttotal: 55s\tremaining: 39.3s\n",
      "583:\tlearn: 6.1003366\ttotal: 55.1s\tremaining: 39.2s\n",
      "584:\tlearn: 6.0974757\ttotal: 55.2s\tremaining: 39.1s\n",
      "585:\tlearn: 6.0945571\ttotal: 55.3s\tremaining: 39s\n",
      "586:\tlearn: 6.0917579\ttotal: 55.4s\tremaining: 39s\n",
      "587:\tlearn: 6.0886633\ttotal: 55.5s\tremaining: 38.9s\n",
      "588:\tlearn: 6.0848970\ttotal: 55.5s\tremaining: 38.8s\n",
      "589:\tlearn: 6.0825760\ttotal: 55.6s\tremaining: 38.7s\n",
      "590:\tlearn: 6.0799078\ttotal: 55.7s\tremaining: 38.6s\n",
      "591:\tlearn: 6.0767682\ttotal: 55.8s\tremaining: 38.4s\n",
      "592:\tlearn: 6.0741115\ttotal: 55.9s\tremaining: 38.3s\n",
      "593:\tlearn: 6.0736936\ttotal: 55.9s\tremaining: 38.2s\n",
      "594:\tlearn: 6.0710667\ttotal: 56s\tremaining: 38.1s\n",
      "595:\tlearn: 6.0686605\ttotal: 56.1s\tremaining: 38s\n",
      "596:\tlearn: 6.0667463\ttotal: 56.2s\tremaining: 37.9s\n",
      "597:\tlearn: 6.0643700\ttotal: 56.3s\tremaining: 37.8s\n",
      "598:\tlearn: 6.0600702\ttotal: 56.4s\tremaining: 37.7s\n",
      "599:\tlearn: 6.0573062\ttotal: 56.5s\tremaining: 37.6s\n",
      "600:\tlearn: 6.0542122\ttotal: 56.5s\tremaining: 37.5s\n",
      "601:\tlearn: 6.0515532\ttotal: 56.6s\tremaining: 37.4s\n",
      "602:\tlearn: 6.0487295\ttotal: 56.7s\tremaining: 37.3s\n",
      "603:\tlearn: 6.0462901\ttotal: 56.8s\tremaining: 37.2s\n",
      "604:\tlearn: 6.0459751\ttotal: 56.9s\tremaining: 37.1s\n",
      "605:\tlearn: 6.0424963\ttotal: 57s\tremaining: 37.1s\n",
      "606:\tlearn: 6.0398995\ttotal: 57.1s\tremaining: 37s\n",
      "607:\tlearn: 6.0369489\ttotal: 57.2s\tremaining: 36.9s\n",
      "608:\tlearn: 6.0344611\ttotal: 57.2s\tremaining: 36.8s\n",
      "609:\tlearn: 6.0341623\ttotal: 57.3s\tremaining: 36.7s\n",
      "610:\tlearn: 6.0304061\ttotal: 57.4s\tremaining: 36.6s\n",
      "611:\tlearn: 6.0272333\ttotal: 57.5s\tremaining: 36.5s\n",
      "612:\tlearn: 6.0230495\ttotal: 57.6s\tremaining: 36.4s\n",
      "613:\tlearn: 6.0210635\ttotal: 57.7s\tremaining: 36.3s\n",
      "614:\tlearn: 6.0180327\ttotal: 57.8s\tremaining: 36.2s\n",
      "615:\tlearn: 6.0158065\ttotal: 57.9s\tremaining: 36.1s\n",
      "616:\tlearn: 6.0119041\ttotal: 58s\tremaining: 36s\n",
      "617:\tlearn: 6.0082555\ttotal: 58s\tremaining: 35.9s\n",
      "618:\tlearn: 6.0040671\ttotal: 58.1s\tremaining: 35.8s\n",
      "619:\tlearn: 6.0022360\ttotal: 58.2s\tremaining: 35.7s\n",
      "620:\tlearn: 5.9998814\ttotal: 58.3s\tremaining: 35.6s\n",
      "621:\tlearn: 5.9968083\ttotal: 58.4s\tremaining: 35.5s\n",
      "622:\tlearn: 5.9930932\ttotal: 58.5s\tremaining: 35.4s\n",
      "623:\tlearn: 5.9891383\ttotal: 58.6s\tremaining: 35.3s\n",
      "624:\tlearn: 5.9861201\ttotal: 58.8s\tremaining: 35.3s\n",
      "625:\tlearn: 5.9833425\ttotal: 58.9s\tremaining: 35.2s\n",
      "626:\tlearn: 5.9806878\ttotal: 59s\tremaining: 35.1s\n",
      "627:\tlearn: 5.9784231\ttotal: 59.1s\tremaining: 35s\n",
      "628:\tlearn: 5.9763258\ttotal: 59.1s\tremaining: 34.9s\n",
      "629:\tlearn: 5.9732610\ttotal: 59.2s\tremaining: 34.8s\n",
      "630:\tlearn: 5.9701270\ttotal: 59.3s\tremaining: 34.7s\n",
      "631:\tlearn: 5.9669900\ttotal: 59.4s\tremaining: 34.6s\n",
      "632:\tlearn: 5.9645540\ttotal: 59.5s\tremaining: 34.5s\n",
      "633:\tlearn: 5.9607672\ttotal: 59.6s\tremaining: 34.4s\n",
      "634:\tlearn: 5.9572713\ttotal: 59.6s\tremaining: 34.3s\n",
      "635:\tlearn: 5.9549354\ttotal: 59.7s\tremaining: 34.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636:\tlearn: 5.9524665\ttotal: 59.8s\tremaining: 34.1s\n",
      "637:\tlearn: 5.9487807\ttotal: 59.9s\tremaining: 34s\n",
      "638:\tlearn: 5.9461459\ttotal: 1m\tremaining: 33.9s\n",
      "639:\tlearn: 5.9427553\ttotal: 1m\tremaining: 33.8s\n",
      "640:\tlearn: 5.9400352\ttotal: 1m\tremaining: 33.7s\n",
      "641:\tlearn: 5.9374960\ttotal: 1m\tremaining: 33.6s\n",
      "642:\tlearn: 5.9347389\ttotal: 1m\tremaining: 33.5s\n",
      "643:\tlearn: 5.9324276\ttotal: 1m\tremaining: 33.4s\n",
      "644:\tlearn: 5.9300968\ttotal: 1m\tremaining: 33.3s\n",
      "645:\tlearn: 5.9272460\ttotal: 1m\tremaining: 33.2s\n",
      "646:\tlearn: 5.9247758\ttotal: 1m\tremaining: 33.1s\n",
      "647:\tlearn: 5.9208817\ttotal: 1m\tremaining: 33s\n",
      "648:\tlearn: 5.9186455\ttotal: 1m\tremaining: 32.9s\n",
      "649:\tlearn: 5.9164092\ttotal: 1m\tremaining: 32.8s\n",
      "650:\tlearn: 5.9122255\ttotal: 1m 1s\tremaining: 32.7s\n",
      "651:\tlearn: 5.9096309\ttotal: 1m 1s\tremaining: 32.6s\n",
      "652:\tlearn: 5.9068327\ttotal: 1m 1s\tremaining: 32.5s\n",
      "653:\tlearn: 5.9041607\ttotal: 1m 1s\tremaining: 32.4s\n",
      "654:\tlearn: 5.9018786\ttotal: 1m 1s\tremaining: 32.3s\n",
      "655:\tlearn: 5.8980798\ttotal: 1m 1s\tremaining: 32.2s\n",
      "656:\tlearn: 5.8961829\ttotal: 1m 1s\tremaining: 32.1s\n",
      "657:\tlearn: 5.8940974\ttotal: 1m 1s\tremaining: 32s\n",
      "658:\tlearn: 5.8915782\ttotal: 1m 1s\tremaining: 31.9s\n",
      "659:\tlearn: 5.8893935\ttotal: 1m 1s\tremaining: 31.8s\n",
      "660:\tlearn: 5.8867734\ttotal: 1m 1s\tremaining: 31.7s\n",
      "661:\tlearn: 5.8836068\ttotal: 1m 1s\tremaining: 31.6s\n",
      "662:\tlearn: 5.8808458\ttotal: 1m 2s\tremaining: 31.5s\n",
      "663:\tlearn: 5.8785067\ttotal: 1m 2s\tremaining: 31.4s\n",
      "664:\tlearn: 5.8761427\ttotal: 1m 2s\tremaining: 31.3s\n",
      "665:\tlearn: 5.8746653\ttotal: 1m 2s\tremaining: 31.3s\n",
      "666:\tlearn: 5.8713789\ttotal: 1m 2s\tremaining: 31.2s\n",
      "667:\tlearn: 5.8688343\ttotal: 1m 2s\tremaining: 31.1s\n",
      "668:\tlearn: 5.8686660\ttotal: 1m 2s\tremaining: 31s\n",
      "669:\tlearn: 5.8665933\ttotal: 1m 2s\tremaining: 30.9s\n",
      "670:\tlearn: 5.8637251\ttotal: 1m 2s\tremaining: 30.8s\n",
      "671:\tlearn: 5.8610031\ttotal: 1m 2s\tremaining: 30.7s\n",
      "672:\tlearn: 5.8587141\ttotal: 1m 2s\tremaining: 30.6s\n",
      "673:\tlearn: 5.8560266\ttotal: 1m 3s\tremaining: 30.5s\n",
      "674:\tlearn: 5.8529722\ttotal: 1m 3s\tremaining: 30.4s\n",
      "675:\tlearn: 5.8506062\ttotal: 1m 3s\tremaining: 30.3s\n",
      "676:\tlearn: 5.8476944\ttotal: 1m 3s\tremaining: 30.2s\n",
      "677:\tlearn: 5.8457614\ttotal: 1m 3s\tremaining: 30.1s\n",
      "678:\tlearn: 5.8426149\ttotal: 1m 3s\tremaining: 30s\n",
      "679:\tlearn: 5.8387438\ttotal: 1m 3s\tremaining: 29.9s\n",
      "680:\tlearn: 5.8363726\ttotal: 1m 3s\tremaining: 29.8s\n",
      "681:\tlearn: 5.8328457\ttotal: 1m 3s\tremaining: 29.7s\n",
      "682:\tlearn: 5.8307448\ttotal: 1m 3s\tremaining: 29.6s\n",
      "683:\tlearn: 5.8279391\ttotal: 1m 3s\tremaining: 29.5s\n",
      "684:\tlearn: 5.8258639\ttotal: 1m 3s\tremaining: 29.4s\n",
      "685:\tlearn: 5.8233356\ttotal: 1m 4s\tremaining: 29.3s\n",
      "686:\tlearn: 5.8207018\ttotal: 1m 4s\tremaining: 29.2s\n",
      "687:\tlearn: 5.8180503\ttotal: 1m 4s\tremaining: 29.1s\n",
      "688:\tlearn: 5.8151956\ttotal: 1m 4s\tremaining: 29s\n",
      "689:\tlearn: 5.8131188\ttotal: 1m 4s\tremaining: 28.9s\n",
      "690:\tlearn: 5.8110812\ttotal: 1m 4s\tremaining: 28.8s\n",
      "691:\tlearn: 5.8092582\ttotal: 1m 4s\tremaining: 28.7s\n",
      "692:\tlearn: 5.8061283\ttotal: 1m 4s\tremaining: 28.6s\n",
      "693:\tlearn: 5.8026625\ttotal: 1m 4s\tremaining: 28.5s\n",
      "694:\tlearn: 5.8000946\ttotal: 1m 4s\tremaining: 28.4s\n",
      "695:\tlearn: 5.7971865\ttotal: 1m 4s\tremaining: 28.3s\n",
      "696:\tlearn: 5.7948108\ttotal: 1m 4s\tremaining: 28.2s\n",
      "697:\tlearn: 5.7920004\ttotal: 1m 5s\tremaining: 28.1s\n",
      "698:\tlearn: 5.7901382\ttotal: 1m 5s\tremaining: 28s\n",
      "699:\tlearn: 5.7873898\ttotal: 1m 5s\tremaining: 27.9s\n",
      "700:\tlearn: 5.7853448\ttotal: 1m 5s\tremaining: 27.8s\n",
      "701:\tlearn: 5.7828559\ttotal: 1m 5s\tremaining: 27.8s\n",
      "702:\tlearn: 5.7791970\ttotal: 1m 5s\tremaining: 27.7s\n",
      "703:\tlearn: 5.7763617\ttotal: 1m 5s\tremaining: 27.6s\n",
      "704:\tlearn: 5.7725647\ttotal: 1m 5s\tremaining: 27.5s\n",
      "705:\tlearn: 5.7696011\ttotal: 1m 5s\tremaining: 27.4s\n",
      "706:\tlearn: 5.7673275\ttotal: 1m 5s\tremaining: 27.3s\n",
      "707:\tlearn: 5.7642056\ttotal: 1m 5s\tremaining: 27.2s\n",
      "708:\tlearn: 5.7607424\ttotal: 1m 5s\tremaining: 27.1s\n",
      "709:\tlearn: 5.7571550\ttotal: 1m 6s\tremaining: 27s\n",
      "710:\tlearn: 5.7550970\ttotal: 1m 6s\tremaining: 26.9s\n",
      "711:\tlearn: 5.7516908\ttotal: 1m 6s\tremaining: 26.8s\n",
      "712:\tlearn: 5.7480767\ttotal: 1m 6s\tremaining: 26.7s\n",
      "713:\tlearn: 5.7449319\ttotal: 1m 6s\tremaining: 26.6s\n",
      "714:\tlearn: 5.7432865\ttotal: 1m 6s\tremaining: 26.5s\n",
      "715:\tlearn: 5.7402982\ttotal: 1m 6s\tremaining: 26.4s\n",
      "716:\tlearn: 5.7370381\ttotal: 1m 6s\tremaining: 26.3s\n",
      "717:\tlearn: 5.7343680\ttotal: 1m 6s\tremaining: 26.2s\n",
      "718:\tlearn: 5.7317736\ttotal: 1m 6s\tremaining: 26.1s\n",
      "719:\tlearn: 5.7279365\ttotal: 1m 6s\tremaining: 26s\n",
      "720:\tlearn: 5.7244440\ttotal: 1m 6s\tremaining: 25.9s\n",
      "721:\tlearn: 5.7208630\ttotal: 1m 7s\tremaining: 25.8s\n",
      "722:\tlearn: 5.7171630\ttotal: 1m 7s\tremaining: 25.7s\n",
      "723:\tlearn: 5.7143305\ttotal: 1m 7s\tremaining: 25.6s\n",
      "724:\tlearn: 5.7109682\ttotal: 1m 7s\tremaining: 25.5s\n",
      "725:\tlearn: 5.7080180\ttotal: 1m 7s\tremaining: 25.4s\n",
      "726:\tlearn: 5.7057575\ttotal: 1m 7s\tremaining: 25.3s\n",
      "727:\tlearn: 5.7028593\ttotal: 1m 7s\tremaining: 25.2s\n",
      "728:\tlearn: 5.6999380\ttotal: 1m 7s\tremaining: 25.1s\n",
      "729:\tlearn: 5.6963918\ttotal: 1m 7s\tremaining: 25s\n",
      "730:\tlearn: 5.6941217\ttotal: 1m 7s\tremaining: 24.9s\n",
      "731:\tlearn: 5.6907807\ttotal: 1m 7s\tremaining: 24.9s\n",
      "732:\tlearn: 5.6884226\ttotal: 1m 7s\tremaining: 24.8s\n",
      "733:\tlearn: 5.6858285\ttotal: 1m 8s\tremaining: 24.7s\n",
      "734:\tlearn: 5.6838362\ttotal: 1m 8s\tremaining: 24.6s\n",
      "735:\tlearn: 5.6819486\ttotal: 1m 8s\tremaining: 24.5s\n",
      "736:\tlearn: 5.6795563\ttotal: 1m 8s\tremaining: 24.4s\n",
      "737:\tlearn: 5.6767650\ttotal: 1m 8s\tremaining: 24.3s\n",
      "738:\tlearn: 5.6766092\ttotal: 1m 8s\tremaining: 24.2s\n",
      "739:\tlearn: 5.6735029\ttotal: 1m 8s\tremaining: 24.1s\n",
      "740:\tlearn: 5.6699753\ttotal: 1m 8s\tremaining: 24s\n",
      "741:\tlearn: 5.6678186\ttotal: 1m 8s\tremaining: 23.9s\n",
      "742:\tlearn: 5.6648482\ttotal: 1m 8s\tremaining: 23.8s\n",
      "743:\tlearn: 5.6619695\ttotal: 1m 9s\tremaining: 23.8s\n",
      "744:\tlearn: 5.6593517\ttotal: 1m 9s\tremaining: 23.7s\n",
      "745:\tlearn: 5.6568034\ttotal: 1m 9s\tremaining: 23.6s\n",
      "746:\tlearn: 5.6542816\ttotal: 1m 9s\tremaining: 23.5s\n",
      "747:\tlearn: 5.6526204\ttotal: 1m 9s\tremaining: 23.4s\n",
      "748:\tlearn: 5.6499545\ttotal: 1m 9s\tremaining: 23.3s\n",
      "749:\tlearn: 5.6478094\ttotal: 1m 9s\tremaining: 23.2s\n",
      "750:\tlearn: 5.6444514\ttotal: 1m 9s\tremaining: 23.1s\n",
      "751:\tlearn: 5.6428806\ttotal: 1m 9s\tremaining: 23s\n",
      "752:\tlearn: 5.6410880\ttotal: 1m 9s\tremaining: 22.9s\n",
      "753:\tlearn: 5.6386173\ttotal: 1m 9s\tremaining: 22.8s\n",
      "754:\tlearn: 5.6364321\ttotal: 1m 10s\tremaining: 22.7s\n",
      "755:\tlearn: 5.6344329\ttotal: 1m 10s\tremaining: 22.6s\n",
      "756:\tlearn: 5.6319422\ttotal: 1m 10s\tremaining: 22.5s\n",
      "757:\tlearn: 5.6284085\ttotal: 1m 10s\tremaining: 22.4s\n",
      "758:\tlearn: 5.6259522\ttotal: 1m 10s\tremaining: 22.3s\n",
      "759:\tlearn: 5.6233243\ttotal: 1m 10s\tremaining: 22.3s\n",
      "760:\tlearn: 5.6207789\ttotal: 1m 10s\tremaining: 22.2s\n",
      "761:\tlearn: 5.6175051\ttotal: 1m 10s\tremaining: 22.1s\n",
      "762:\tlearn: 5.6144009\ttotal: 1m 10s\tremaining: 22s\n",
      "763:\tlearn: 5.6113980\ttotal: 1m 10s\tremaining: 21.9s\n",
      "764:\tlearn: 5.6088313\ttotal: 1m 10s\tremaining: 21.8s\n",
      "765:\tlearn: 5.6068404\ttotal: 1m 11s\tremaining: 21.7s\n",
      "766:\tlearn: 5.6048046\ttotal: 1m 11s\tremaining: 21.6s\n",
      "767:\tlearn: 5.6020323\ttotal: 1m 11s\tremaining: 21.5s\n",
      "768:\tlearn: 5.5989439\ttotal: 1m 11s\tremaining: 21.4s\n",
      "769:\tlearn: 5.5962754\ttotal: 1m 11s\tremaining: 21.3s\n",
      "770:\tlearn: 5.5936191\ttotal: 1m 11s\tremaining: 21.2s\n",
      "771:\tlearn: 5.5908190\ttotal: 1m 11s\tremaining: 21.1s\n",
      "772:\tlearn: 5.5878969\ttotal: 1m 11s\tremaining: 21s\n",
      "773:\tlearn: 5.5847156\ttotal: 1m 11s\tremaining: 20.9s\n",
      "774:\tlearn: 5.5818181\ttotal: 1m 11s\tremaining: 20.8s\n",
      "775:\tlearn: 5.5781365\ttotal: 1m 11s\tremaining: 20.7s\n",
      "776:\tlearn: 5.5754708\ttotal: 1m 11s\tremaining: 20.7s\n",
      "777:\tlearn: 5.5725273\ttotal: 1m 12s\tremaining: 20.6s\n",
      "778:\tlearn: 5.5704598\ttotal: 1m 12s\tremaining: 20.5s\n",
      "779:\tlearn: 5.5703049\ttotal: 1m 12s\tremaining: 20.4s\n",
      "780:\tlearn: 5.5680252\ttotal: 1m 12s\tremaining: 20.3s\n",
      "781:\tlearn: 5.5647879\ttotal: 1m 12s\tremaining: 20.2s\n",
      "782:\tlearn: 5.5627169\ttotal: 1m 12s\tremaining: 20.1s\n",
      "783:\tlearn: 5.5607144\ttotal: 1m 12s\tremaining: 20s\n",
      "784:\tlearn: 5.5577124\ttotal: 1m 12s\tremaining: 19.9s\n",
      "785:\tlearn: 5.5547157\ttotal: 1m 12s\tremaining: 19.8s\n",
      "786:\tlearn: 5.5521990\ttotal: 1m 12s\tremaining: 19.7s\n",
      "787:\tlearn: 5.5504888\ttotal: 1m 12s\tremaining: 19.6s\n",
      "788:\tlearn: 5.5487436\ttotal: 1m 12s\tremaining: 19.5s\n",
      "789:\tlearn: 5.5459897\ttotal: 1m 13s\tremaining: 19.4s\n",
      "790:\tlearn: 5.5429782\ttotal: 1m 13s\tremaining: 19.3s\n",
      "791:\tlearn: 5.5417680\ttotal: 1m 13s\tremaining: 19.2s\n",
      "792:\tlearn: 5.5382048\ttotal: 1m 13s\tremaining: 19.1s\n",
      "793:\tlearn: 5.5354740\ttotal: 1m 13s\tremaining: 19s\n",
      "794:\tlearn: 5.5327844\ttotal: 1m 13s\tremaining: 19s\n",
      "795:\tlearn: 5.5300656\ttotal: 1m 13s\tremaining: 18.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796:\tlearn: 5.5272702\ttotal: 1m 13s\tremaining: 18.8s\n",
      "797:\tlearn: 5.5240169\ttotal: 1m 13s\tremaining: 18.7s\n",
      "798:\tlearn: 5.5215010\ttotal: 1m 13s\tremaining: 18.6s\n",
      "799:\tlearn: 5.5193812\ttotal: 1m 13s\tremaining: 18.5s\n",
      "800:\tlearn: 5.5163209\ttotal: 1m 14s\tremaining: 18.4s\n",
      "801:\tlearn: 5.5136109\ttotal: 1m 14s\tremaining: 18.3s\n",
      "802:\tlearn: 5.5110011\ttotal: 1m 14s\tremaining: 18.2s\n",
      "803:\tlearn: 5.5090389\ttotal: 1m 14s\tremaining: 18.1s\n",
      "804:\tlearn: 5.5059910\ttotal: 1m 14s\tremaining: 18s\n",
      "805:\tlearn: 5.5031230\ttotal: 1m 14s\tremaining: 17.9s\n",
      "806:\tlearn: 5.5018731\ttotal: 1m 14s\tremaining: 17.8s\n",
      "807:\tlearn: 5.5001121\ttotal: 1m 14s\tremaining: 17.7s\n",
      "808:\tlearn: 5.4982194\ttotal: 1m 14s\tremaining: 17.6s\n",
      "809:\tlearn: 5.4957984\ttotal: 1m 14s\tremaining: 17.5s\n",
      "810:\tlearn: 5.4929473\ttotal: 1m 14s\tremaining: 17.4s\n",
      "811:\tlearn: 5.4895663\ttotal: 1m 14s\tremaining: 17.3s\n",
      "812:\tlearn: 5.4874060\ttotal: 1m 14s\tremaining: 17.2s\n",
      "813:\tlearn: 5.4847126\ttotal: 1m 15s\tremaining: 17.2s\n",
      "814:\tlearn: 5.4807150\ttotal: 1m 15s\tremaining: 17.1s\n",
      "815:\tlearn: 5.4775638\ttotal: 1m 15s\tremaining: 17s\n",
      "816:\tlearn: 5.4754213\ttotal: 1m 15s\tremaining: 16.9s\n",
      "817:\tlearn: 5.4752130\ttotal: 1m 15s\tremaining: 16.8s\n",
      "818:\tlearn: 5.4722882\ttotal: 1m 15s\tremaining: 16.7s\n",
      "819:\tlearn: 5.4704563\ttotal: 1m 15s\tremaining: 16.6s\n",
      "820:\tlearn: 5.4681722\ttotal: 1m 15s\tremaining: 16.5s\n",
      "821:\tlearn: 5.4655935\ttotal: 1m 15s\tremaining: 16.4s\n",
      "822:\tlearn: 5.4633636\ttotal: 1m 15s\tremaining: 16.3s\n",
      "823:\tlearn: 5.4612732\ttotal: 1m 16s\tremaining: 16.2s\n",
      "824:\tlearn: 5.4581891\ttotal: 1m 16s\tremaining: 16.1s\n",
      "825:\tlearn: 5.4558169\ttotal: 1m 16s\tremaining: 16.1s\n",
      "826:\tlearn: 5.4522606\ttotal: 1m 16s\tremaining: 16s\n",
      "827:\tlearn: 5.4491261\ttotal: 1m 16s\tremaining: 15.9s\n",
      "828:\tlearn: 5.4488565\ttotal: 1m 16s\tremaining: 15.8s\n",
      "829:\tlearn: 5.4472088\ttotal: 1m 16s\tremaining: 15.7s\n",
      "830:\tlearn: 5.4449305\ttotal: 1m 16s\tremaining: 15.6s\n",
      "831:\tlearn: 5.4425956\ttotal: 1m 16s\tremaining: 15.5s\n",
      "832:\tlearn: 5.4405751\ttotal: 1m 16s\tremaining: 15.4s\n",
      "833:\tlearn: 5.4381933\ttotal: 1m 17s\tremaining: 15.3s\n",
      "834:\tlearn: 5.4364810\ttotal: 1m 17s\tremaining: 15.2s\n",
      "835:\tlearn: 5.4341039\ttotal: 1m 17s\tremaining: 15.2s\n",
      "836:\tlearn: 5.4313624\ttotal: 1m 17s\tremaining: 15.1s\n",
      "837:\tlearn: 5.4281802\ttotal: 1m 17s\tremaining: 15s\n",
      "838:\tlearn: 5.4253123\ttotal: 1m 17s\tremaining: 14.9s\n",
      "839:\tlearn: 5.4227004\ttotal: 1m 17s\tremaining: 14.8s\n",
      "840:\tlearn: 5.4208630\ttotal: 1m 17s\tremaining: 14.7s\n",
      "841:\tlearn: 5.4179836\ttotal: 1m 17s\tremaining: 14.6s\n",
      "842:\tlearn: 5.4163628\ttotal: 1m 18s\tremaining: 14.5s\n",
      "843:\tlearn: 5.4140454\ttotal: 1m 18s\tremaining: 14.4s\n",
      "844:\tlearn: 5.4117140\ttotal: 1m 18s\tremaining: 14.3s\n",
      "845:\tlearn: 5.4099858\ttotal: 1m 18s\tremaining: 14.2s\n",
      "846:\tlearn: 5.4077854\ttotal: 1m 18s\tremaining: 14.2s\n",
      "847:\tlearn: 5.4038952\ttotal: 1m 18s\tremaining: 14.1s\n",
      "848:\tlearn: 5.4016649\ttotal: 1m 18s\tremaining: 14s\n",
      "849:\tlearn: 5.3995202\ttotal: 1m 18s\tremaining: 13.9s\n",
      "850:\tlearn: 5.3973881\ttotal: 1m 18s\tremaining: 13.8s\n",
      "851:\tlearn: 5.3945591\ttotal: 1m 18s\tremaining: 13.7s\n",
      "852:\tlearn: 5.3924126\ttotal: 1m 18s\tremaining: 13.6s\n",
      "853:\tlearn: 5.3904713\ttotal: 1m 19s\tremaining: 13.5s\n",
      "854:\tlearn: 5.3878072\ttotal: 1m 19s\tremaining: 13.4s\n",
      "855:\tlearn: 5.3866082\ttotal: 1m 19s\tremaining: 13.3s\n",
      "856:\tlearn: 5.3840785\ttotal: 1m 19s\tremaining: 13.2s\n",
      "857:\tlearn: 5.3811288\ttotal: 1m 19s\tremaining: 13.2s\n",
      "858:\tlearn: 5.3792031\ttotal: 1m 19s\tremaining: 13.1s\n",
      "859:\tlearn: 5.3777215\ttotal: 1m 19s\tremaining: 13s\n",
      "860:\tlearn: 5.3753125\ttotal: 1m 19s\tremaining: 12.9s\n",
      "861:\tlearn: 5.3736707\ttotal: 1m 19s\tremaining: 12.8s\n",
      "862:\tlearn: 5.3708764\ttotal: 1m 19s\tremaining: 12.7s\n",
      "863:\tlearn: 5.3672759\ttotal: 1m 20s\tremaining: 12.6s\n",
      "864:\tlearn: 5.3647754\ttotal: 1m 20s\tremaining: 12.5s\n",
      "865:\tlearn: 5.3627701\ttotal: 1m 20s\tremaining: 12.4s\n",
      "866:\tlearn: 5.3584013\ttotal: 1m 20s\tremaining: 12.3s\n",
      "867:\tlearn: 5.3554097\ttotal: 1m 20s\tremaining: 12.2s\n",
      "868:\tlearn: 5.3533726\ttotal: 1m 20s\tremaining: 12.1s\n",
      "869:\tlearn: 5.3513237\ttotal: 1m 20s\tremaining: 12s\n",
      "870:\tlearn: 5.3493885\ttotal: 1m 20s\tremaining: 12s\n",
      "871:\tlearn: 5.3468508\ttotal: 1m 20s\tremaining: 11.9s\n",
      "872:\tlearn: 5.3439441\ttotal: 1m 20s\tremaining: 11.8s\n",
      "873:\tlearn: 5.3409661\ttotal: 1m 20s\tremaining: 11.7s\n",
      "874:\tlearn: 5.3387762\ttotal: 1m 21s\tremaining: 11.6s\n",
      "875:\tlearn: 5.3360783\ttotal: 1m 21s\tremaining: 11.5s\n",
      "876:\tlearn: 5.3339155\ttotal: 1m 21s\tremaining: 11.4s\n",
      "877:\tlearn: 5.3337238\ttotal: 1m 21s\tremaining: 11.3s\n",
      "878:\tlearn: 5.3314943\ttotal: 1m 21s\tremaining: 11.2s\n",
      "879:\tlearn: 5.3305108\ttotal: 1m 21s\tremaining: 11.1s\n",
      "880:\tlearn: 5.3292472\ttotal: 1m 21s\tremaining: 11s\n",
      "881:\tlearn: 5.3279323\ttotal: 1m 21s\tremaining: 10.9s\n",
      "882:\tlearn: 5.3260148\ttotal: 1m 21s\tremaining: 10.8s\n",
      "883:\tlearn: 5.3227522\ttotal: 1m 21s\tremaining: 10.7s\n",
      "884:\tlearn: 5.3204706\ttotal: 1m 21s\tremaining: 10.7s\n",
      "885:\tlearn: 5.3182806\ttotal: 1m 22s\tremaining: 10.6s\n",
      "886:\tlearn: 5.3157887\ttotal: 1m 22s\tremaining: 10.5s\n",
      "887:\tlearn: 5.3131764\ttotal: 1m 22s\tremaining: 10.4s\n",
      "888:\tlearn: 5.3112977\ttotal: 1m 22s\tremaining: 10.3s\n",
      "889:\tlearn: 5.3094619\ttotal: 1m 22s\tremaining: 10.2s\n",
      "890:\tlearn: 5.3064018\ttotal: 1m 22s\tremaining: 10.1s\n",
      "891:\tlearn: 5.3041343\ttotal: 1m 22s\tremaining: 10s\n",
      "892:\tlearn: 5.3020788\ttotal: 1m 22s\tremaining: 9.91s\n",
      "893:\tlearn: 5.3000829\ttotal: 1m 22s\tremaining: 9.82s\n",
      "894:\tlearn: 5.2977910\ttotal: 1m 22s\tremaining: 9.73s\n",
      "895:\tlearn: 5.2953929\ttotal: 1m 23s\tremaining: 9.63s\n",
      "896:\tlearn: 5.2928267\ttotal: 1m 23s\tremaining: 9.54s\n",
      "897:\tlearn: 5.2904091\ttotal: 1m 23s\tremaining: 9.45s\n",
      "898:\tlearn: 5.2882024\ttotal: 1m 23s\tremaining: 9.36s\n",
      "899:\tlearn: 5.2856593\ttotal: 1m 23s\tremaining: 9.26s\n",
      "900:\tlearn: 5.2830483\ttotal: 1m 23s\tremaining: 9.17s\n",
      "901:\tlearn: 5.2807764\ttotal: 1m 23s\tremaining: 9.08s\n",
      "902:\tlearn: 5.2784174\ttotal: 1m 23s\tremaining: 8.98s\n",
      "903:\tlearn: 5.2762770\ttotal: 1m 23s\tremaining: 8.89s\n",
      "904:\tlearn: 5.2727078\ttotal: 1m 23s\tremaining: 8.8s\n",
      "905:\tlearn: 5.2691441\ttotal: 1m 23s\tremaining: 8.71s\n",
      "906:\tlearn: 5.2665112\ttotal: 1m 24s\tremaining: 8.62s\n",
      "907:\tlearn: 5.2638686\ttotal: 1m 24s\tremaining: 8.52s\n",
      "908:\tlearn: 5.2612741\ttotal: 1m 24s\tremaining: 8.43s\n",
      "909:\tlearn: 5.2592803\ttotal: 1m 24s\tremaining: 8.34s\n",
      "910:\tlearn: 5.2576827\ttotal: 1m 24s\tremaining: 8.25s\n",
      "911:\tlearn: 5.2546382\ttotal: 1m 24s\tremaining: 8.15s\n",
      "912:\tlearn: 5.2521436\ttotal: 1m 24s\tremaining: 8.06s\n",
      "913:\tlearn: 5.2492118\ttotal: 1m 24s\tremaining: 7.97s\n",
      "914:\tlearn: 5.2468606\ttotal: 1m 24s\tremaining: 7.88s\n",
      "915:\tlearn: 5.2445908\ttotal: 1m 24s\tremaining: 7.79s\n",
      "916:\tlearn: 5.2423935\ttotal: 1m 25s\tremaining: 7.69s\n",
      "917:\tlearn: 5.2389424\ttotal: 1m 25s\tremaining: 7.6s\n",
      "918:\tlearn: 5.2369051\ttotal: 1m 25s\tremaining: 7.51s\n",
      "919:\tlearn: 5.2344544\ttotal: 1m 25s\tremaining: 7.42s\n",
      "920:\tlearn: 5.2318541\ttotal: 1m 25s\tremaining: 7.33s\n",
      "921:\tlearn: 5.2297110\ttotal: 1m 25s\tremaining: 7.24s\n",
      "922:\tlearn: 5.2263560\ttotal: 1m 25s\tremaining: 7.14s\n",
      "923:\tlearn: 5.2230094\ttotal: 1m 25s\tremaining: 7.05s\n",
      "924:\tlearn: 5.2201701\ttotal: 1m 25s\tremaining: 6.96s\n",
      "925:\tlearn: 5.2182704\ttotal: 1m 25s\tremaining: 6.87s\n",
      "926:\tlearn: 5.2163379\ttotal: 1m 26s\tremaining: 6.77s\n",
      "927:\tlearn: 5.2158652\ttotal: 1m 26s\tremaining: 6.68s\n",
      "928:\tlearn: 5.2134628\ttotal: 1m 26s\tremaining: 6.59s\n",
      "929:\tlearn: 5.2116685\ttotal: 1m 26s\tremaining: 6.5s\n",
      "930:\tlearn: 5.2088975\ttotal: 1m 26s\tremaining: 6.4s\n",
      "931:\tlearn: 5.2063189\ttotal: 1m 26s\tremaining: 6.31s\n",
      "932:\tlearn: 5.2032881\ttotal: 1m 26s\tremaining: 6.22s\n",
      "933:\tlearn: 5.2009883\ttotal: 1m 26s\tremaining: 6.13s\n",
      "934:\tlearn: 5.1988048\ttotal: 1m 26s\tremaining: 6.03s\n",
      "935:\tlearn: 5.1956971\ttotal: 1m 26s\tremaining: 5.94s\n",
      "936:\tlearn: 5.1930570\ttotal: 1m 26s\tremaining: 5.85s\n",
      "937:\tlearn: 5.1902945\ttotal: 1m 27s\tremaining: 5.76s\n",
      "938:\tlearn: 5.1881181\ttotal: 1m 27s\tremaining: 5.66s\n",
      "939:\tlearn: 5.1853030\ttotal: 1m 27s\tremaining: 5.57s\n",
      "940:\tlearn: 5.1835423\ttotal: 1m 27s\tremaining: 5.48s\n",
      "941:\tlearn: 5.1806115\ttotal: 1m 27s\tremaining: 5.39s\n",
      "942:\tlearn: 5.1772465\ttotal: 1m 27s\tremaining: 5.29s\n",
      "943:\tlearn: 5.1745198\ttotal: 1m 27s\tremaining: 5.2s\n",
      "944:\tlearn: 5.1730412\ttotal: 1m 27s\tremaining: 5.11s\n",
      "945:\tlearn: 5.1711369\ttotal: 1m 27s\tremaining: 5.01s\n",
      "946:\tlearn: 5.1688543\ttotal: 1m 27s\tremaining: 4.92s\n",
      "947:\tlearn: 5.1666405\ttotal: 1m 28s\tremaining: 4.83s\n",
      "948:\tlearn: 5.1643017\ttotal: 1m 28s\tremaining: 4.74s\n",
      "949:\tlearn: 5.1625790\ttotal: 1m 28s\tremaining: 4.64s\n",
      "950:\tlearn: 5.1603527\ttotal: 1m 28s\tremaining: 4.55s\n",
      "951:\tlearn: 5.1601309\ttotal: 1m 28s\tremaining: 4.46s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952:\tlearn: 5.1573619\ttotal: 1m 28s\tremaining: 4.37s\n",
      "953:\tlearn: 5.1545138\ttotal: 1m 28s\tremaining: 4.27s\n",
      "954:\tlearn: 5.1530274\ttotal: 1m 28s\tremaining: 4.18s\n",
      "955:\tlearn: 5.1509880\ttotal: 1m 28s\tremaining: 4.09s\n",
      "956:\tlearn: 5.1479257\ttotal: 1m 28s\tremaining: 4s\n",
      "957:\tlearn: 5.1453993\ttotal: 1m 29s\tremaining: 3.9s\n",
      "958:\tlearn: 5.1432930\ttotal: 1m 29s\tremaining: 3.81s\n",
      "959:\tlearn: 5.1416407\ttotal: 1m 29s\tremaining: 3.72s\n",
      "960:\tlearn: 5.1394702\ttotal: 1m 29s\tremaining: 3.62s\n",
      "961:\tlearn: 5.1375318\ttotal: 1m 29s\tremaining: 3.53s\n",
      "962:\tlearn: 5.1346003\ttotal: 1m 29s\tremaining: 3.44s\n",
      "963:\tlearn: 5.1318714\ttotal: 1m 29s\tremaining: 3.34s\n",
      "964:\tlearn: 5.1295887\ttotal: 1m 29s\tremaining: 3.25s\n",
      "965:\tlearn: 5.1275966\ttotal: 1m 29s\tremaining: 3.16s\n",
      "966:\tlearn: 5.1245045\ttotal: 1m 29s\tremaining: 3.07s\n",
      "967:\tlearn: 5.1221568\ttotal: 1m 29s\tremaining: 2.97s\n",
      "968:\tlearn: 5.1198632\ttotal: 1m 30s\tremaining: 2.88s\n",
      "969:\tlearn: 5.1164091\ttotal: 1m 30s\tremaining: 2.79s\n",
      "970:\tlearn: 5.1149901\ttotal: 1m 30s\tremaining: 2.69s\n",
      "971:\tlearn: 5.1127020\ttotal: 1m 30s\tremaining: 2.6s\n",
      "972:\tlearn: 5.1110586\ttotal: 1m 30s\tremaining: 2.51s\n",
      "973:\tlearn: 5.1080068\ttotal: 1m 30s\tremaining: 2.42s\n",
      "974:\tlearn: 5.1055527\ttotal: 1m 30s\tremaining: 2.32s\n",
      "975:\tlearn: 5.1029831\ttotal: 1m 30s\tremaining: 2.23s\n",
      "976:\tlearn: 5.0996647\ttotal: 1m 30s\tremaining: 2.14s\n",
      "977:\tlearn: 5.0974668\ttotal: 1m 30s\tremaining: 2.04s\n",
      "978:\tlearn: 5.0949137\ttotal: 1m 31s\tremaining: 1.95s\n",
      "979:\tlearn: 5.0919133\ttotal: 1m 31s\tremaining: 1.86s\n",
      "980:\tlearn: 5.0884620\ttotal: 1m 31s\tremaining: 1.77s\n",
      "981:\tlearn: 5.0861861\ttotal: 1m 31s\tremaining: 1.67s\n",
      "982:\tlearn: 5.0840940\ttotal: 1m 31s\tremaining: 1.58s\n",
      "983:\tlearn: 5.0809604\ttotal: 1m 31s\tremaining: 1.49s\n",
      "984:\tlearn: 5.0791742\ttotal: 1m 31s\tremaining: 1.39s\n",
      "985:\tlearn: 5.0780010\ttotal: 1m 31s\tremaining: 1.3s\n",
      "986:\tlearn: 5.0755510\ttotal: 1m 31s\tremaining: 1.21s\n",
      "987:\tlearn: 5.0733607\ttotal: 1m 31s\tremaining: 1.11s\n",
      "988:\tlearn: 5.0707576\ttotal: 1m 31s\tremaining: 1.02s\n",
      "989:\tlearn: 5.0669428\ttotal: 1m 32s\tremaining: 930ms\n",
      "990:\tlearn: 5.0646902\ttotal: 1m 32s\tremaining: 837ms\n",
      "991:\tlearn: 5.0625793\ttotal: 1m 32s\tremaining: 744ms\n",
      "992:\tlearn: 5.0600421\ttotal: 1m 32s\tremaining: 651ms\n",
      "993:\tlearn: 5.0582238\ttotal: 1m 32s\tremaining: 558ms\n",
      "994:\tlearn: 5.0560772\ttotal: 1m 32s\tremaining: 465ms\n",
      "995:\tlearn: 5.0535642\ttotal: 1m 32s\tremaining: 372ms\n",
      "996:\tlearn: 5.0516920\ttotal: 1m 32s\tremaining: 279ms\n",
      "997:\tlearn: 5.0486668\ttotal: 1m 32s\tremaining: 186ms\n",
      "998:\tlearn: 5.0460360\ttotal: 1m 32s\tremaining: 93ms\n",
      "999:\tlearn: 5.0440367\ttotal: 1m 33s\tremaining: 0us\n",
      "LGBMRegressor 로그 변환된 RMSE: 8.078\n",
      "CatBoostRegressor 로그 변환된 RMSE: 8.031\n",
      "XGBRegressor 로그 변환된 RMSE: 8.539\n",
      "Ridge 로그 변환된 RMSE: 8.347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.078426224830515, 8.03091632403072, 8.539231880714672, 8.34740983377776]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rmse(model):\n",
    "    pred = model.predict(valid_x)\n",
    "    mse = mean_squared_error(valid_y , pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('{0} 로그 변환된 RMSE: {1}'.format(model.__class__.__name__,np.round(rmse, 3)))\n",
    "    return rmse\n",
    "\n",
    "def get_rmses(models):\n",
    "    rmses = [ ]\n",
    "    for model in models:\n",
    "        rmse = get_rmse(model)\n",
    "        rmses.append(rmse)\n",
    "    return rmses\n",
    "\n",
    "\n",
    "\n",
    "lgbm = LGBMRegressor(random_state = 1000  )\n",
    "lgbm = lgbm.fit(train_x , train_y)\n",
    "\n",
    "cat = CatBoostRegressor(random_state=1000 )\n",
    "cat = cat.fit(train_x , train_y)\n",
    "\n",
    "xgb = XGBRegressor(random_state = 1000 )\n",
    "xgb.fit(train_x , train_y )\n",
    "\n",
    "reg_ridge = Ridge(random_state = 1000)\n",
    "reg_ridge.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "models = [lgbm, cat, xgb, reg_ridge ]\n",
    "get_rmses(models)\n",
    "\n",
    "\n",
    "# LGBMRegressor 로그 변환된 RMSE: 8.078\n",
    "# CatBoostRegressor 로그 변환된 RMSE: 8.031\n",
    "# XGBRegressor 로그 변환된 RMSE: 8.539\n",
    "# Ridge 로그 변환된 RMSE: 8.347\n",
    "# [8.078426224830515, 8.03091632403072, 8.539231880714672, 8.34740983377776]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_params = {\n",
    "    'max_depth':(8, 16),\n",
    "    'num_leaves':(24, 64),\n",
    "    'min_child_samples':(10, 200),\n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1),\n",
    "    'colsample_bytree':(0.5, 1),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha':(0.01, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_rmse_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree, max_bin, reg_lambda, reg_alpha):\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\":2000, \n",
    "        \"learning_rate\":0.02,\n",
    "        'max_depth':int(round(max_depth)),\n",
    "        'num_leaves':int(round(num_leaves)),\n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample':max(min(subsample, 1), 0),\n",
    "        'colsample_bytree':max(min(colsample_bytree, 1), 0),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0)\n",
    "    }\n",
    "    \n",
    "    lgb_model = LGBMRegressor(**params)\n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'RMSE', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    valid_pred = lgb_model.predict(valid_x)\n",
    "    RMSE = np.sqrt(mean_squared_error(valid_y, valid_pred))\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.80217\ttraining's l2: 60.8739\tvalid_1's rmse: 8.30377\tvalid_1's l2: 68.9525\n",
      "[200]\ttraining's rmse: 7.11662\ttraining's l2: 50.6462\tvalid_1's rmse: 8.09701\tvalid_1's l2: 65.5615\n",
      "[300]\ttraining's rmse: 6.66188\ttraining's l2: 44.3806\tvalid_1's rmse: 8.0476\tvalid_1's l2: 64.7638\n",
      "[400]\ttraining's rmse: 6.28801\ttraining's l2: 39.5391\tvalid_1's rmse: 8.02105\tvalid_1's l2: 64.3373\n",
      "[500]\ttraining's rmse: 5.96171\ttraining's l2: 35.5419\tvalid_1's rmse: 8.01521\tvalid_1's l2: 64.2436\n",
      "[600]\ttraining's rmse: 5.66419\ttraining's l2: 32.0831\tvalid_1's rmse: 8.01302\tvalid_1's l2: 64.2085\n",
      "[700]\ttraining's rmse: 5.39373\ttraining's l2: 29.0924\tvalid_1's rmse: 8.01293\tvalid_1's l2: 64.207\n",
      "Early stopping, best iteration is:\n",
      "[668]\ttraining's rmse: 5.47812\ttraining's l2: 30.0098\tvalid_1's rmse: 8.01074\tvalid_1's l2: 64.1719\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 8.011   \u001b[0m | \u001b[0m 0.8268  \u001b[0m | \u001b[0m 66.35   \u001b[0m | \u001b[0m 15.6    \u001b[0m | \u001b[0m 101.6   \u001b[0m | \u001b[0m 43.75   \u001b[0m | \u001b[0m 32.49   \u001b[0m | \u001b[0m 2.045   \u001b[0m | \u001b[0m 3.973   \u001b[0m | \u001b[0m 0.6166  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.46949\ttraining's l2: 55.7933\tvalid_1's rmse: 8.26689\tvalid_1's l2: 68.3415\n",
      "[200]\ttraining's rmse: 6.57341\ttraining's l2: 43.2098\tvalid_1's rmse: 8.0749\tvalid_1's l2: 65.2039\n",
      "[300]\ttraining's rmse: 5.95208\ttraining's l2: 35.4272\tvalid_1's rmse: 8.03241\tvalid_1's l2: 64.5196\n",
      "[400]\ttraining's rmse: 5.44258\ttraining's l2: 29.6217\tvalid_1's rmse: 8.01868\tvalid_1's l2: 64.2992\n",
      "[500]\ttraining's rmse: 4.99095\ttraining's l2: 24.9096\tvalid_1's rmse: 8.01803\tvalid_1's l2: 64.2888\n",
      "Early stopping, best iteration is:\n",
      "[457]\ttraining's rmse: 5.17994\ttraining's l2: 26.8318\tvalid_1's rmse: 8.01532\tvalid_1's l2: 64.2453\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 8.015   \u001b[0m | \u001b[95m 0.9209  \u001b[0m | \u001b[95m 111.5   \u001b[0m | \u001b[95m 13.94   \u001b[0m | \u001b[95m 84.51   \u001b[0m | \u001b[95m 9.931   \u001b[0m | \u001b[95m 53.74   \u001b[0m | \u001b[95m 3.488   \u001b[0m | \u001b[95m 8.853   \u001b[0m | \u001b[95m 0.9763  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.67277\ttraining's l2: 58.8714\tvalid_1's rmse: 8.27093\tvalid_1's l2: 68.4083\n",
      "[200]\ttraining's rmse: 7.03424\ttraining's l2: 49.4805\tvalid_1's rmse: 8.07794\tvalid_1's l2: 65.253\n",
      "[300]\ttraining's rmse: 6.68431\ttraining's l2: 44.6799\tvalid_1's rmse: 8.04321\tvalid_1's l2: 64.6932\n",
      "[400]\ttraining's rmse: 6.37013\ttraining's l2: 40.5785\tvalid_1's rmse: 8.02092\tvalid_1's l2: 64.3352\n",
      "[500]\ttraining's rmse: 6.10519\ttraining's l2: 37.2734\tvalid_1's rmse: 8.01677\tvalid_1's l2: 64.2685\n",
      "[600]\ttraining's rmse: 5.8661\ttraining's l2: 34.4112\tvalid_1's rmse: 8.01422\tvalid_1's l2: 64.2277\n",
      "[700]\ttraining's rmse: 5.63852\ttraining's l2: 31.793\tvalid_1's rmse: 8.01297\tvalid_1's l2: 64.2077\n",
      "Early stopping, best iteration is:\n",
      "[653]\ttraining's rmse: 5.7463\ttraining's l2: 33.02\tvalid_1's rmse: 8.01182\tvalid_1's l2: 64.1893\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 8.012   \u001b[0m | \u001b[0m 0.9656  \u001b[0m | \u001b[0m 213.6   \u001b[0m | \u001b[0m 8.232   \u001b[0m | \u001b[0m 196.6   \u001b[0m | \u001b[0m 17.64   \u001b[0m | \u001b[0m 52.27   \u001b[0m | \u001b[0m 18.1    \u001b[0m | \u001b[0m 0.352   \u001b[0m | \u001b[0m 0.9275  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.9733\ttraining's l2: 63.5736\tvalid_1's rmse: 8.32929\tvalid_1's l2: 69.3771\n",
      "[200]\ttraining's rmse: 7.39007\ttraining's l2: 54.6132\tvalid_1's rmse: 8.10711\tvalid_1's l2: 65.7252\n",
      "[300]\ttraining's rmse: 7.03539\ttraining's l2: 49.4968\tvalid_1's rmse: 8.0568\tvalid_1's l2: 64.9121\n",
      "[400]\ttraining's rmse: 6.73734\ttraining's l2: 45.3917\tvalid_1's rmse: 8.02858\tvalid_1's l2: 64.4581\n",
      "[500]\ttraining's rmse: 6.47441\ttraining's l2: 41.918\tvalid_1's rmse: 8.02584\tvalid_1's l2: 64.4142\n",
      "[600]\ttraining's rmse: 6.2335\ttraining's l2: 38.8565\tvalid_1's rmse: 8.02222\tvalid_1's l2: 64.3561\n",
      "[700]\ttraining's rmse: 6.01383\ttraining's l2: 36.1662\tvalid_1's rmse: 8.01958\tvalid_1's l2: 64.3137\n",
      "[800]\ttraining's rmse: 5.80703\ttraining's l2: 33.7216\tvalid_1's rmse: 8.01992\tvalid_1's l2: 64.3192\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's rmse: 5.92158\ttraining's l2: 35.0651\tvalid_1's rmse: 8.0186\tvalid_1's l2: 64.298\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 8.019   \u001b[0m | \u001b[95m 0.8286  \u001b[0m | \u001b[95m 385.2   \u001b[0m | \u001b[95m 12.43   \u001b[0m | \u001b[95m 178.2   \u001b[0m | \u001b[95m 45.31   \u001b[0m | \u001b[95m 24.42   \u001b[0m | \u001b[95m 3.737   \u001b[0m | \u001b[95m 2.447   \u001b[0m | \u001b[95m 0.5667  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.95198\ttraining's l2: 63.2339\tvalid_1's rmse: 8.34303\tvalid_1's l2: 69.6061\n",
      "[200]\ttraining's rmse: 7.3426\ttraining's l2: 53.9137\tvalid_1's rmse: 8.12195\tvalid_1's l2: 65.966\n",
      "[300]\ttraining's rmse: 6.95746\ttraining's l2: 48.4062\tvalid_1's rmse: 8.06814\tvalid_1's l2: 65.0949\n",
      "[400]\ttraining's rmse: 6.63871\ttraining's l2: 44.0725\tvalid_1's rmse: 8.0394\tvalid_1's l2: 64.632\n",
      "[500]\ttraining's rmse: 6.35935\ttraining's l2: 40.4413\tvalid_1's rmse: 8.02637\tvalid_1's l2: 64.4226\n",
      "[600]\ttraining's rmse: 6.10392\ttraining's l2: 37.2579\tvalid_1's rmse: 8.02125\tvalid_1's l2: 64.3404\n",
      "[700]\ttraining's rmse: 5.86503\ttraining's l2: 34.3986\tvalid_1's rmse: 8.01613\tvalid_1's l2: 64.2584\n",
      "[800]\ttraining's rmse: 5.64719\ttraining's l2: 31.8907\tvalid_1's rmse: 8.0131\tvalid_1's l2: 64.2099\n",
      "[900]\ttraining's rmse: 5.44298\ttraining's l2: 29.6261\tvalid_1's rmse: 8.01081\tvalid_1's l2: 64.1731\n",
      "[1000]\ttraining's rmse: 5.25006\ttraining's l2: 27.5631\tvalid_1's rmse: 8.0075\tvalid_1's l2: 64.12\n",
      "[1100]\ttraining's rmse: 5.06702\ttraining's l2: 25.6747\tvalid_1's rmse: 8.00835\tvalid_1's l2: 64.1337\n",
      "Early stopping, best iteration is:\n",
      "[1063]\ttraining's rmse: 5.13285\ttraining's l2: 26.3461\tvalid_1's rmse: 8.00646\tvalid_1's l2: 64.1034\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 8.006   \u001b[0m | \u001b[0m 0.849   \u001b[0m | \u001b[0m 205.1   \u001b[0m | \u001b[0m 15.06   \u001b[0m | \u001b[0m 44.39   \u001b[0m | \u001b[0m 22.19   \u001b[0m | \u001b[0m 24.73   \u001b[0m | \u001b[0m 34.57   \u001b[0m | \u001b[0m 4.697   \u001b[0m | \u001b[0m 0.5641  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.91313\ttraining's l2: 62.6176\tvalid_1's rmse: 8.30972\tvalid_1's l2: 69.0514\n",
      "[200]\ttraining's rmse: 7.30013\ttraining's l2: 53.2919\tvalid_1's rmse: 8.09444\tvalid_1's l2: 65.52\n",
      "[300]\ttraining's rmse: 6.90902\ttraining's l2: 47.7345\tvalid_1's rmse: 8.04186\tvalid_1's l2: 64.6715\n",
      "[400]\ttraining's rmse: 6.57618\ttraining's l2: 43.2462\tvalid_1's rmse: 8.01948\tvalid_1's l2: 64.312\n",
      "[500]\ttraining's rmse: 6.28282\ttraining's l2: 39.4738\tvalid_1's rmse: 8.01229\tvalid_1's l2: 64.1969\n",
      "[600]\ttraining's rmse: 6.01569\ttraining's l2: 36.1885\tvalid_1's rmse: 8.0079\tvalid_1's l2: 64.1264\n",
      "[700]\ttraining's rmse: 5.76775\ttraining's l2: 33.2669\tvalid_1's rmse: 8.00639\tvalid_1's l2: 64.1023\n",
      "Early stopping, best iteration is:\n",
      "[621]\ttraining's rmse: 5.96165\ttraining's l2: 35.5412\tvalid_1's rmse: 8.00525\tvalid_1's l2: 64.0841\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 8.005   \u001b[0m | \u001b[0m 0.5139  \u001b[0m | \u001b[0m 381.6   \u001b[0m | \u001b[0m 13.72   \u001b[0m | \u001b[0m 184.8   \u001b[0m | \u001b[0m 39.84   \u001b[0m | \u001b[0m 28.96   \u001b[0m | \u001b[0m 7.24    \u001b[0m | \u001b[0m 0.6002  \u001b[0m | \u001b[0m 0.9406  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.67048\ttraining's l2: 58.8363\tvalid_1's rmse: 8.27459\tvalid_1's l2: 68.4688\n",
      "[200]\ttraining's rmse: 6.92348\ttraining's l2: 47.9346\tvalid_1's rmse: 8.07549\tvalid_1's l2: 65.2135\n",
      "[300]\ttraining's rmse: 6.45137\ttraining's l2: 41.6202\tvalid_1's rmse: 8.03391\tvalid_1's l2: 64.5437\n",
      "[400]\ttraining's rmse: 6.0542\ttraining's l2: 36.6533\tvalid_1's rmse: 8.01647\tvalid_1's l2: 64.2638\n",
      "[500]\ttraining's rmse: 5.70844\ttraining's l2: 32.5863\tvalid_1's rmse: 8.00889\tvalid_1's l2: 64.1423\n",
      "[600]\ttraining's rmse: 5.39903\ttraining's l2: 29.1495\tvalid_1's rmse: 8.00476\tvalid_1's l2: 64.0762\n",
      "[700]\ttraining's rmse: 5.11573\ttraining's l2: 26.1707\tvalid_1's rmse: 8.01011\tvalid_1's l2: 64.1618\n",
      "Early stopping, best iteration is:\n",
      "[603]\ttraining's rmse: 5.38843\ttraining's l2: 29.0352\tvalid_1's rmse: 8.00383\tvalid_1's l2: 64.0613\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 8.004   \u001b[0m | \u001b[0m 0.6842  \u001b[0m | \u001b[0m 25.21   \u001b[0m | \u001b[0m 10.86   \u001b[0m | \u001b[0m 168.4   \u001b[0m | \u001b[0m 24.29   \u001b[0m | \u001b[0m 44.84   \u001b[0m | \u001b[0m 7.394   \u001b[0m | \u001b[0m 2.342   \u001b[0m | \u001b[0m 0.736   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.74403\ttraining's l2: 59.97\tvalid_1's rmse: 8.29337\tvalid_1's l2: 68.78\n",
      "[200]\ttraining's rmse: 7.01588\ttraining's l2: 49.2225\tvalid_1's rmse: 8.08813\tvalid_1's l2: 65.4178\n",
      "[300]\ttraining's rmse: 6.52709\ttraining's l2: 42.6029\tvalid_1's rmse: 8.0406\tvalid_1's l2: 64.6512\n",
      "[400]\ttraining's rmse: 6.1144\ttraining's l2: 37.3859\tvalid_1's rmse: 8.01505\tvalid_1's l2: 64.241\n",
      "[500]\ttraining's rmse: 5.76097\ttraining's l2: 33.1888\tvalid_1's rmse: 8.00873\tvalid_1's l2: 64.1398\n",
      "[600]\ttraining's rmse: 5.4418\ttraining's l2: 29.6132\tvalid_1's rmse: 8.00567\tvalid_1's l2: 64.0908\n",
      "[700]\ttraining's rmse: 5.15079\ttraining's l2: 26.5306\tvalid_1's rmse: 8.00134\tvalid_1's l2: 64.0214\n",
      "[800]\ttraining's rmse: 4.88649\ttraining's l2: 23.8778\tvalid_1's rmse: 8.0021\tvalid_1's l2: 64.0335\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's rmse: 5.13952\ttraining's l2: 26.4146\tvalid_1's rmse: 8.00067\tvalid_1's l2: 64.0106\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 8.001   \u001b[0m | \u001b[0m 0.7675  \u001b[0m | \u001b[0m 132.0   \u001b[0m | \u001b[0m 14.3    \u001b[0m | \u001b[0m 40.39   \u001b[0m | \u001b[0m 44.76   \u001b[0m | \u001b[0m 35.85   \u001b[0m | \u001b[0m 33.16   \u001b[0m | \u001b[0m 4.179   \u001b[0m | \u001b[0m 0.9905  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.41133\ttraining's l2: 54.9279\tvalid_1's rmse: 8.24866\tvalid_1's l2: 68.0403\n",
      "[200]\ttraining's rmse: 6.57943\ttraining's l2: 43.2889\tvalid_1's rmse: 8.07207\tvalid_1's l2: 65.1583\n",
      "[300]\ttraining's rmse: 6.11546\ttraining's l2: 37.3988\tvalid_1's rmse: 8.03023\tvalid_1's l2: 64.4846\n",
      "[400]\ttraining's rmse: 5.75421\ttraining's l2: 33.111\tvalid_1's rmse: 8.01756\tvalid_1's l2: 64.2813\n",
      "[500]\ttraining's rmse: 5.40042\ttraining's l2: 29.1646\tvalid_1's rmse: 8.01392\tvalid_1's l2: 64.223\n",
      "[600]\ttraining's rmse: 5.07924\ttraining's l2: 25.7987\tvalid_1's rmse: 8.00869\tvalid_1's l2: 64.1391\n",
      "[700]\ttraining's rmse: 4.8062\ttraining's l2: 23.0996\tvalid_1's rmse: 8.0064\tvalid_1's l2: 64.1025\n",
      "[800]\ttraining's rmse: 4.52295\ttraining's l2: 20.4571\tvalid_1's rmse: 8.00756\tvalid_1's l2: 64.1211\n",
      "Early stopping, best iteration is:\n",
      "[714]\ttraining's rmse: 4.76762\ttraining's l2: 22.7302\tvalid_1's rmse: 8.00549\tvalid_1's l2: 64.0879\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 8.005   \u001b[0m | \u001b[0m 0.5909  \u001b[0m | \u001b[0m 151.4   \u001b[0m | \u001b[0m 8.126   \u001b[0m | \u001b[0m 67.71   \u001b[0m | \u001b[0m 12.18   \u001b[0m | \u001b[0m 57.97   \u001b[0m | \u001b[0m 5.113   \u001b[0m | \u001b[0m 2.963   \u001b[0m | \u001b[0m 0.5074  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.88429\ttraining's l2: 62.162\tvalid_1's rmse: 8.3272\tvalid_1's l2: 69.3422\n",
      "[200]\ttraining's rmse: 7.25101\ttraining's l2: 52.5772\tvalid_1's rmse: 8.10994\tvalid_1's l2: 65.7711\n",
      "[300]\ttraining's rmse: 6.84151\ttraining's l2: 46.8063\tvalid_1's rmse: 8.05566\tvalid_1's l2: 64.8937\n",
      "[400]\ttraining's rmse: 6.49715\ttraining's l2: 42.2129\tvalid_1's rmse: 8.03123\tvalid_1's l2: 64.5006\n",
      "[500]\ttraining's rmse: 6.19318\ttraining's l2: 38.3555\tvalid_1's rmse: 8.02373\tvalid_1's l2: 64.3803\n",
      "[600]\ttraining's rmse: 5.91896\ttraining's l2: 35.0341\tvalid_1's rmse: 8.01881\tvalid_1's l2: 64.3014\n",
      "[700]\ttraining's rmse: 5.66486\ttraining's l2: 32.0906\tvalid_1's rmse: 8.01345\tvalid_1's l2: 64.2154\n",
      "[800]\ttraining's rmse: 5.43432\ttraining's l2: 29.5319\tvalid_1's rmse: 8.00884\tvalid_1's l2: 64.1415\n",
      "[900]\ttraining's rmse: 5.21632\ttraining's l2: 27.21\tvalid_1's rmse: 8.00703\tvalid_1's l2: 64.1125\n",
      "[1000]\ttraining's rmse: 5.0126\ttraining's l2: 25.1261\tvalid_1's rmse: 8.00734\tvalid_1's l2: 64.1175\n",
      "Early stopping, best iteration is:\n",
      "[938]\ttraining's rmse: 5.13684\ttraining's l2: 26.3871\tvalid_1's rmse: 8.00603\tvalid_1's l2: 64.0966\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 8.006   \u001b[0m | \u001b[0m 0.9254  \u001b[0m | \u001b[0m 416.7   \u001b[0m | \u001b[0m 10.77   \u001b[0m | \u001b[0m 126.9   \u001b[0m | \u001b[0m 26.11   \u001b[0m | \u001b[0m 29.61   \u001b[0m | \u001b[0m 48.7    \u001b[0m | \u001b[0m 7.307   \u001b[0m | \u001b[0m 0.5611  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.85124\ttraining's l2: 61.642\tvalid_1's rmse: 8.30157\tvalid_1's l2: 68.916\n",
      "[200]\ttraining's rmse: 7.19434\ttraining's l2: 51.7585\tvalid_1's rmse: 8.08651\tvalid_1's l2: 65.3916\n",
      "[300]\ttraining's rmse: 6.76806\ttraining's l2: 45.8066\tvalid_1's rmse: 8.03559\tvalid_1's l2: 64.5707\n",
      "[400]\ttraining's rmse: 6.40659\ttraining's l2: 41.0443\tvalid_1's rmse: 8.01225\tvalid_1's l2: 64.1961\n",
      "[500]\ttraining's rmse: 6.08988\ttraining's l2: 37.0867\tvalid_1's rmse: 8.00594\tvalid_1's l2: 64.095\n",
      "[600]\ttraining's rmse: 5.80462\ttraining's l2: 33.6936\tvalid_1's rmse: 8.00333\tvalid_1's l2: 64.0532\n",
      "[700]\ttraining's rmse: 5.54436\ttraining's l2: 30.7399\tvalid_1's rmse: 8.00094\tvalid_1's l2: 64.015\n",
      "[800]\ttraining's rmse: 5.30126\ttraining's l2: 28.1033\tvalid_1's rmse: 7.99897\tvalid_1's l2: 63.9835\n",
      "[900]\ttraining's rmse: 5.07559\ttraining's l2: 25.7616\tvalid_1's rmse: 7.99996\tvalid_1's l2: 63.9993\n",
      "Early stopping, best iteration is:\n",
      "[842]\ttraining's rmse: 5.20309\ttraining's l2: 27.0721\tvalid_1's rmse: 7.99843\tvalid_1's l2: 63.9749\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 7.998   \u001b[0m | \u001b[0m 0.5141  \u001b[0m | \u001b[0m 254.3   \u001b[0m | \u001b[0m 15.33   \u001b[0m | \u001b[0m 103.2   \u001b[0m | \u001b[0m 46.9    \u001b[0m | \u001b[0m 32.34   \u001b[0m | \u001b[0m 12.22   \u001b[0m | \u001b[0m 9.777   \u001b[0m | \u001b[0m 0.6989  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.80021\ttraining's l2: 60.8433\tvalid_1's rmse: 8.30068\tvalid_1's l2: 68.9013\n",
      "[200]\ttraining's rmse: 7.11886\ttraining's l2: 50.6782\tvalid_1's rmse: 8.08575\tvalid_1's l2: 65.3793\n",
      "[300]\ttraining's rmse: 6.66713\ttraining's l2: 44.4507\tvalid_1's rmse: 8.03912\tvalid_1's l2: 64.6274\n",
      "[400]\ttraining's rmse: 6.2812\ttraining's l2: 39.4535\tvalid_1's rmse: 8.01604\tvalid_1's l2: 64.257\n",
      "[500]\ttraining's rmse: 5.94225\ttraining's l2: 35.3103\tvalid_1's rmse: 8.00591\tvalid_1's l2: 64.0945\n",
      "[600]\ttraining's rmse: 5.63813\ttraining's l2: 31.7885\tvalid_1's rmse: 8.00675\tvalid_1's l2: 64.1081\n",
      "Early stopping, best iteration is:\n",
      "[503]\ttraining's rmse: 5.93305\ttraining's l2: 35.2011\tvalid_1's rmse: 8.00523\tvalid_1's l2: 64.0837\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 8.005   \u001b[0m | \u001b[0m 0.5715  \u001b[0m | \u001b[0m 420.3   \u001b[0m | \u001b[0m 15.04   \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 3.524   \u001b[0m | \u001b[0m 35.44   \u001b[0m | \u001b[0m 22.55   \u001b[0m | \u001b[0m 3.946   \u001b[0m | \u001b[0m 0.9637  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.69731\ttraining's l2: 59.2486\tvalid_1's rmse: 8.28114\tvalid_1's l2: 68.5772\n",
      "[200]\ttraining's rmse: 6.93817\ttraining's l2: 48.1383\tvalid_1's rmse: 8.0745\tvalid_1's l2: 65.1975\n",
      "[300]\ttraining's rmse: 6.42294\ttraining's l2: 41.2541\tvalid_1's rmse: 8.02382\tvalid_1's l2: 64.3817\n",
      "[400]\ttraining's rmse: 5.99172\ttraining's l2: 35.9007\tvalid_1's rmse: 8.0057\tvalid_1's l2: 64.0912\n",
      "[500]\ttraining's rmse: 5.61789\ttraining's l2: 31.5607\tvalid_1's rmse: 7.99399\tvalid_1's l2: 63.9038\n",
      "[600]\ttraining's rmse: 5.28188\ttraining's l2: 27.8982\tvalid_1's rmse: 7.99523\tvalid_1's l2: 63.9237\n",
      "Early stopping, best iteration is:\n",
      "[521]\ttraining's rmse: 5.54454\ttraining's l2: 30.7419\tvalid_1's rmse: 7.99358\tvalid_1's l2: 63.8973\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 7.994   \u001b[0m | \u001b[0m 0.5793  \u001b[0m | \u001b[0m 255.2   \u001b[0m | \u001b[0m 13.55   \u001b[0m | \u001b[0m 12.51   \u001b[0m | \u001b[0m 29.43   \u001b[0m | \u001b[0m 39.82   \u001b[0m | \u001b[0m 33.96   \u001b[0m | \u001b[0m 5.653   \u001b[0m | \u001b[0m 0.8581  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.59104\ttraining's l2: 57.6239\tvalid_1's rmse: 8.28494\tvalid_1's l2: 68.6402\n",
      "[200]\ttraining's rmse: 6.79393\ttraining's l2: 46.1575\tvalid_1's rmse: 8.07936\tvalid_1's l2: 65.276\n",
      "[300]\ttraining's rmse: 6.26694\ttraining's l2: 39.2746\tvalid_1's rmse: 8.03973\tvalid_1's l2: 64.6372\n",
      "[400]\ttraining's rmse: 5.82483\ttraining's l2: 33.9286\tvalid_1's rmse: 8.0196\tvalid_1's l2: 64.3139\n",
      "[500]\ttraining's rmse: 5.42721\ttraining's l2: 29.4546\tvalid_1's rmse: 8.00913\tvalid_1's l2: 64.1462\n",
      "[600]\ttraining's rmse: 5.0641\ttraining's l2: 25.6451\tvalid_1's rmse: 8.00886\tvalid_1's l2: 64.1418\n",
      "[700]\ttraining's rmse: 4.74516\ttraining's l2: 22.5165\tvalid_1's rmse: 8.00436\tvalid_1's l2: 64.0697\n",
      "[800]\ttraining's rmse: 4.4553\ttraining's l2: 19.8497\tvalid_1's rmse: 8.01016\tvalid_1's l2: 64.1626\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's rmse: 4.74516\ttraining's l2: 22.5165\tvalid_1's rmse: 8.00436\tvalid_1's l2: 64.0697\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 8.004   \u001b[0m | \u001b[0m 0.6464  \u001b[0m | \u001b[0m 212.8   \u001b[0m | \u001b[0m 9.076   \u001b[0m | \u001b[0m 32.07   \u001b[0m | \u001b[0m 22.8    \u001b[0m | \u001b[0m 47.68   \u001b[0m | \u001b[0m 48.94   \u001b[0m | \u001b[0m 5.883   \u001b[0m | \u001b[0m 0.8768  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.53759\ttraining's l2: 56.8152\tvalid_1's rmse: 8.26821\tvalid_1's l2: 68.3633\n",
      "[200]\ttraining's rmse: 6.68556\ttraining's l2: 44.6968\tvalid_1's rmse: 8.06945\tvalid_1's l2: 65.116\n",
      "[300]\ttraining's rmse: 6.091\ttraining's l2: 37.1002\tvalid_1's rmse: 8.03166\tvalid_1's l2: 64.5076\n",
      "[400]\ttraining's rmse: 5.59104\ttraining's l2: 31.2597\tvalid_1's rmse: 8.01772\tvalid_1's l2: 64.2838\n",
      "[500]\ttraining's rmse: 5.15352\ttraining's l2: 26.5588\tvalid_1's rmse: 8.01839\tvalid_1's l2: 64.2946\n",
      "Early stopping, best iteration is:\n",
      "[433]\ttraining's rmse: 5.43925\ttraining's l2: 29.5854\tvalid_1's rmse: 8.0165\tvalid_1's l2: 64.2643\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 8.016   \u001b[0m | \u001b[0m 0.6659  \u001b[0m | \u001b[0m 318.9   \u001b[0m | \u001b[0m 14.7    \u001b[0m | \u001b[0m 89.29   \u001b[0m | \u001b[0m 7.679   \u001b[0m | \u001b[0m 54.4    \u001b[0m | \u001b[0m 41.98   \u001b[0m | \u001b[0m 4.397   \u001b[0m | \u001b[0m 0.6464  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.4068\ttraining's l2: 54.8608\tvalid_1's rmse: 8.25708\tvalid_1's l2: 68.1794\n",
      "[200]\ttraining's rmse: 6.49745\ttraining's l2: 42.2169\tvalid_1's rmse: 8.06912\tvalid_1's l2: 65.1106\n",
      "[300]\ttraining's rmse: 5.88189\ttraining's l2: 34.5967\tvalid_1's rmse: 8.02928\tvalid_1's l2: 64.4694\n",
      "[400]\ttraining's rmse: 5.36492\ttraining's l2: 28.7824\tvalid_1's rmse: 8.01339\tvalid_1's l2: 64.2143\n",
      "[500]\ttraining's rmse: 4.90597\ttraining's l2: 24.0686\tvalid_1's rmse: 8.0092\tvalid_1's l2: 64.1473\n",
      "[600]\ttraining's rmse: 4.50675\ttraining's l2: 20.3108\tvalid_1's rmse: 8.00917\tvalid_1's l2: 64.1468\n",
      "[700]\ttraining's rmse: 4.15786\ttraining's l2: 17.2878\tvalid_1's rmse: 8.00885\tvalid_1's l2: 64.1417\n",
      "Early stopping, best iteration is:\n",
      "[675]\ttraining's rmse: 4.24248\ttraining's l2: 17.9986\tvalid_1's rmse: 8.00635\tvalid_1's l2: 64.1016\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 8.006   \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 226.8   \u001b[0m | \u001b[0m 9.587   \u001b[0m | \u001b[0m 45.26   \u001b[0m | \u001b[0m 38.36   \u001b[0m | \u001b[0m 58.79   \u001b[0m | \u001b[0m 48.62   \u001b[0m | \u001b[0m 2.709   \u001b[0m | \u001b[0m 0.9832  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.82082\ttraining's l2: 61.1653\tvalid_1's rmse: 8.3173\tvalid_1's l2: 69.1775\n",
      "[200]\ttraining's rmse: 7.14777\ttraining's l2: 51.0906\tvalid_1's rmse: 8.10907\tvalid_1's l2: 65.757\n",
      "[300]\ttraining's rmse: 6.71111\ttraining's l2: 45.039\tvalid_1's rmse: 8.05939\tvalid_1's l2: 64.9537\n",
      "[400]\ttraining's rmse: 6.3431\ttraining's l2: 40.2349\tvalid_1's rmse: 8.0341\tvalid_1's l2: 64.5468\n",
      "[500]\ttraining's rmse: 6.02175\ttraining's l2: 36.2615\tvalid_1's rmse: 8.02503\tvalid_1's l2: 64.401\n",
      "[600]\ttraining's rmse: 5.73077\ttraining's l2: 32.8418\tvalid_1's rmse: 8.01724\tvalid_1's l2: 64.2762\n",
      "Early stopping, best iteration is:\n",
      "[594]\ttraining's rmse: 5.74722\ttraining's l2: 33.0306\tvalid_1's rmse: 8.01707\tvalid_1's l2: 64.2734\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 8.017   \u001b[0m | \u001b[0m 0.9319  \u001b[0m | \u001b[0m 265.1   \u001b[0m | \u001b[0m 8.635   \u001b[0m | \u001b[0m 55.92   \u001b[0m | \u001b[0m 4.254   \u001b[0m | \u001b[0m 32.04   \u001b[0m | \u001b[0m 37.83   \u001b[0m | \u001b[0m 6.108   \u001b[0m | \u001b[0m 0.9044  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.54829\ttraining's l2: 56.9766\tvalid_1's rmse: 8.27782\tvalid_1's l2: 68.5223\n",
      "[200]\ttraining's rmse: 6.70842\ttraining's l2: 45.0029\tvalid_1's rmse: 8.08021\tvalid_1's l2: 65.2897\n",
      "[300]\ttraining's rmse: 6.13278\ttraining's l2: 37.611\tvalid_1's rmse: 8.03375\tvalid_1's l2: 64.5412\n",
      "[400]\ttraining's rmse: 5.65065\ttraining's l2: 31.9298\tvalid_1's rmse: 8.01978\tvalid_1's l2: 64.3169\n",
      "[500]\ttraining's rmse: 5.23464\ttraining's l2: 27.4015\tvalid_1's rmse: 8.01144\tvalid_1's l2: 64.1831\n",
      "[600]\ttraining's rmse: 4.86422\ttraining's l2: 23.6607\tvalid_1's rmse: 8.00646\tvalid_1's l2: 64.1034\n",
      "[700]\ttraining's rmse: 4.53233\ttraining's l2: 20.542\tvalid_1's rmse: 8.00792\tvalid_1's l2: 64.1268\n",
      "Early stopping, best iteration is:\n",
      "[655]\ttraining's rmse: 4.67833\ttraining's l2: 21.8868\tvalid_1's rmse: 8.0052\tvalid_1's l2: 64.0832\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 8.005   \u001b[0m | \u001b[0m 0.8401  \u001b[0m | \u001b[0m 218.0   \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 18.53   \u001b[0m | \u001b[0m 44.08   \u001b[0m | \u001b[0m 48.28   \u001b[0m | \u001b[0m 31.39   \u001b[0m | \u001b[0m 5.161   \u001b[0m | \u001b[0m 0.8321  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.41479\ttraining's l2: 54.9791\tvalid_1's rmse: 8.26054\tvalid_1's l2: 68.2365\n",
      "[200]\ttraining's rmse: 6.49782\ttraining's l2: 42.2217\tvalid_1's rmse: 8.07834\tvalid_1's l2: 65.2596\n",
      "[300]\ttraining's rmse: 5.88372\ttraining's l2: 34.6181\tvalid_1's rmse: 8.04244\tvalid_1's l2: 64.6808\n",
      "[400]\ttraining's rmse: 5.37082\ttraining's l2: 28.8457\tvalid_1's rmse: 8.02811\tvalid_1's l2: 64.4506\n",
      "[500]\ttraining's rmse: 4.92882\ttraining's l2: 24.2933\tvalid_1's rmse: 8.02211\tvalid_1's l2: 64.3542\n",
      "[600]\ttraining's rmse: 4.52411\ttraining's l2: 20.4676\tvalid_1's rmse: 8.01984\tvalid_1's l2: 64.3178\n",
      "[700]\ttraining's rmse: 4.16464\ttraining's l2: 17.3443\tvalid_1's rmse: 8.02097\tvalid_1's l2: 64.3359\n",
      "Early stopping, best iteration is:\n",
      "[645]\ttraining's rmse: 4.35818\ttraining's l2: 18.9938\tvalid_1's rmse: 8.01809\tvalid_1's l2: 64.2897\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 8.018   \u001b[0m | \u001b[0m 0.7178  \u001b[0m | \u001b[0m 174.7   \u001b[0m | \u001b[0m 10.29   \u001b[0m | \u001b[0m 36.12   \u001b[0m | \u001b[0m 11.2    \u001b[0m | \u001b[0m 59.42   \u001b[0m | \u001b[0m 23.53   \u001b[0m | \u001b[0m 9.78    \u001b[0m | \u001b[0m 0.5628  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.92595\ttraining's l2: 62.8207\tvalid_1's rmse: 8.32887\tvalid_1's l2: 69.3702\n",
      "[200]\ttraining's rmse: 7.31832\ttraining's l2: 53.5579\tvalid_1's rmse: 8.10824\tvalid_1's l2: 65.7436\n",
      "[300]\ttraining's rmse: 6.92707\ttraining's l2: 47.9843\tvalid_1's rmse: 8.05684\tvalid_1's l2: 64.9126\n",
      "[400]\ttraining's rmse: 6.60042\ttraining's l2: 43.5655\tvalid_1's rmse: 8.02956\tvalid_1's l2: 64.4738\n",
      "[500]\ttraining's rmse: 6.3093\ttraining's l2: 39.8073\tvalid_1's rmse: 8.01618\tvalid_1's l2: 64.2591\n",
      "[600]\ttraining's rmse: 6.04188\ttraining's l2: 36.5043\tvalid_1's rmse: 8.00551\tvalid_1's l2: 64.0881\n",
      "[700]\ttraining's rmse: 5.79675\ttraining's l2: 33.6023\tvalid_1's rmse: 8.00377\tvalid_1's l2: 64.0604\n",
      "[800]\ttraining's rmse: 5.56828\ttraining's l2: 31.0057\tvalid_1's rmse: 8.00255\tvalid_1's l2: 64.0408\n",
      "[900]\ttraining's rmse: 5.3551\ttraining's l2: 28.6771\tvalid_1's rmse: 8.00099\tvalid_1's l2: 64.0158\n",
      "Early stopping, best iteration is:\n",
      "[857]\ttraining's rmse: 5.44428\ttraining's l2: 29.6401\tvalid_1's rmse: 7.99981\tvalid_1's l2: 63.997\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 0.8023  \u001b[0m | \u001b[0m 372.3   \u001b[0m | \u001b[0m 13.22   \u001b[0m | \u001b[0m 189.7   \u001b[0m | \u001b[0m 29.8    \u001b[0m | \u001b[0m 29.28   \u001b[0m | \u001b[0m 46.45   \u001b[0m | \u001b[0m 6.261   \u001b[0m | \u001b[0m 0.5583  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.63752\ttraining's l2: 58.3317\tvalid_1's rmse: 8.268\tvalid_1's l2: 68.3598\n",
      "[200]\ttraining's rmse: 6.85382\ttraining's l2: 46.9749\tvalid_1's rmse: 8.06702\tvalid_1's l2: 65.0768\n",
      "[300]\ttraining's rmse: 6.3206\ttraining's l2: 39.95\tvalid_1's rmse: 8.01652\tvalid_1's l2: 64.2646\n",
      "[400]\ttraining's rmse: 5.87379\ttraining's l2: 34.5014\tvalid_1's rmse: 8.00157\tvalid_1's l2: 64.0251\n",
      "[500]\ttraining's rmse: 5.4837\ttraining's l2: 30.071\tvalid_1's rmse: 7.98899\tvalid_1's l2: 63.824\n",
      "[600]\ttraining's rmse: 5.13312\ttraining's l2: 26.3489\tvalid_1's rmse: 7.98837\tvalid_1's l2: 63.814\n",
      "[700]\ttraining's rmse: 4.81646\ttraining's l2: 23.1983\tvalid_1's rmse: 7.98766\tvalid_1's l2: 63.8027\n",
      "[800]\ttraining's rmse: 4.53153\ttraining's l2: 20.5348\tvalid_1's rmse: 7.98514\tvalid_1's l2: 63.7625\n",
      "Early stopping, best iteration is:\n",
      "[796]\ttraining's rmse: 4.54193\ttraining's l2: 20.6291\tvalid_1's rmse: 7.98441\tvalid_1's l2: 63.7508\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 7.984   \u001b[0m | \u001b[0m 0.6121  \u001b[0m | \u001b[0m 56.01   \u001b[0m | \u001b[0m 13.32   \u001b[0m | \u001b[0m 86.02   \u001b[0m | \u001b[0m 2.535   \u001b[0m | \u001b[0m 43.43   \u001b[0m | \u001b[0m 12.8    \u001b[0m | \u001b[0m 3.448   \u001b[0m | \u001b[0m 0.5243  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.61686\ttraining's l2: 58.0165\tvalid_1's rmse: 8.26509\tvalid_1's l2: 68.3118\n",
      "[200]\ttraining's rmse: 6.82519\ttraining's l2: 46.5833\tvalid_1's rmse: 8.06964\tvalid_1's l2: 65.119\n",
      "[300]\ttraining's rmse: 6.27547\ttraining's l2: 39.3815\tvalid_1's rmse: 8.02105\tvalid_1's l2: 64.3372\n",
      "[400]\ttraining's rmse: 5.81478\ttraining's l2: 33.8116\tvalid_1's rmse: 8.00795\tvalid_1's l2: 64.1272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 5.40386\ttraining's l2: 29.2017\tvalid_1's rmse: 8.00498\tvalid_1's l2: 64.0797\n",
      "[600]\ttraining's rmse: 5.03651\ttraining's l2: 25.3664\tvalid_1's rmse: 8.00454\tvalid_1's l2: 64.0727\n",
      "Early stopping, best iteration is:\n",
      "[543]\ttraining's rmse: 5.24101\ttraining's l2: 27.4682\tvalid_1's rmse: 8.00015\tvalid_1's l2: 64.0024\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 0.6732  \u001b[0m | \u001b[0m 294.8   \u001b[0m | \u001b[0m 15.04   \u001b[0m | \u001b[0m 117.9   \u001b[0m | \u001b[0m 26.82   \u001b[0m | \u001b[0m 46.07   \u001b[0m | \u001b[0m 13.76   \u001b[0m | \u001b[0m 3.302   \u001b[0m | \u001b[0m 0.5363  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.70548\ttraining's l2: 59.3744\tvalid_1's rmse: 8.29344\tvalid_1's l2: 68.7811\n",
      "[200]\ttraining's rmse: 6.95446\ttraining's l2: 48.3645\tvalid_1's rmse: 8.08783\tvalid_1's l2: 65.413\n",
      "[300]\ttraining's rmse: 6.44613\ttraining's l2: 41.5526\tvalid_1's rmse: 8.03776\tvalid_1's l2: 64.6055\n",
      "[400]\ttraining's rmse: 6.01897\ttraining's l2: 36.2279\tvalid_1's rmse: 8.01473\tvalid_1's l2: 64.2358\n",
      "[500]\ttraining's rmse: 5.64804\ttraining's l2: 31.9003\tvalid_1's rmse: 8.00673\tvalid_1's l2: 64.1078\n",
      "[600]\ttraining's rmse: 5.31508\ttraining's l2: 28.2501\tvalid_1's rmse: 8.00562\tvalid_1's l2: 64.09\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's rmse: 5.46772\ttraining's l2: 29.896\tvalid_1's rmse: 8.00421\tvalid_1's l2: 64.0674\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 8.004   \u001b[0m | \u001b[0m 0.819   \u001b[0m | \u001b[0m 33.68   \u001b[0m | \u001b[0m 14.31   \u001b[0m | \u001b[0m 81.77   \u001b[0m | \u001b[0m 30.16   \u001b[0m | \u001b[0m 39.27   \u001b[0m | \u001b[0m 19.79   \u001b[0m | \u001b[0m 7.493   \u001b[0m | \u001b[0m 0.6173  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.5981\ttraining's l2: 57.7312\tvalid_1's rmse: 8.27643\tvalid_1's l2: 68.4992\n",
      "[200]\ttraining's rmse: 6.77783\ttraining's l2: 45.939\tvalid_1's rmse: 8.0765\tvalid_1's l2: 65.2299\n",
      "[300]\ttraining's rmse: 6.21283\ttraining's l2: 38.5993\tvalid_1's rmse: 8.03393\tvalid_1's l2: 64.5441\n",
      "[400]\ttraining's rmse: 5.73873\ttraining's l2: 32.933\tvalid_1's rmse: 8.0153\tvalid_1's l2: 64.245\n",
      "[500]\ttraining's rmse: 5.33034\ttraining's l2: 28.4125\tvalid_1's rmse: 8.01242\tvalid_1's l2: 64.1989\n",
      "[600]\ttraining's rmse: 4.96791\ttraining's l2: 24.6801\tvalid_1's rmse: 8.00989\tvalid_1's l2: 64.1583\n",
      "Early stopping, best iteration is:\n",
      "[556]\ttraining's rmse: 5.12217\ttraining's l2: 26.2366\tvalid_1's rmse: 8.00576\tvalid_1's l2: 64.0922\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 8.006   \u001b[0m | \u001b[0m 0.7314  \u001b[0m | \u001b[0m 322.5   \u001b[0m | \u001b[0m 14.67   \u001b[0m | \u001b[0m 29.11   \u001b[0m | \u001b[0m 46.03   \u001b[0m | \u001b[0m 47.01   \u001b[0m | \u001b[0m 44.83   \u001b[0m | \u001b[0m 5.787   \u001b[0m | \u001b[0m 0.6073  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.551\ttraining's l2: 57.0176\tvalid_1's rmse: 8.27674\tvalid_1's l2: 68.5044\n",
      "[200]\ttraining's rmse: 6.70902\ttraining's l2: 45.011\tvalid_1's rmse: 8.08886\tvalid_1's l2: 65.4297\n",
      "[300]\ttraining's rmse: 6.12386\ttraining's l2: 37.5017\tvalid_1's rmse: 8.04271\tvalid_1's l2: 64.6853\n",
      "[400]\ttraining's rmse: 5.63727\ttraining's l2: 31.7788\tvalid_1's rmse: 8.02494\tvalid_1's l2: 64.3996\n",
      "[500]\ttraining's rmse: 5.22053\ttraining's l2: 27.2539\tvalid_1's rmse: 8.01459\tvalid_1's l2: 64.2337\n",
      "[600]\ttraining's rmse: 4.85437\ttraining's l2: 23.5649\tvalid_1's rmse: 8.01572\tvalid_1's l2: 64.2517\n",
      "Early stopping, best iteration is:\n",
      "[539]\ttraining's rmse: 5.07194\ttraining's l2: 25.7245\tvalid_1's rmse: 8.01253\tvalid_1's l2: 64.2007\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 8.013   \u001b[0m | \u001b[0m 0.9712  \u001b[0m | \u001b[0m 489.0   \u001b[0m | \u001b[0m 15.25   \u001b[0m | \u001b[0m 49.44   \u001b[0m | \u001b[0m 26.52   \u001b[0m | \u001b[0m 47.24   \u001b[0m | \u001b[0m 39.95   \u001b[0m | \u001b[0m 2.888   \u001b[0m | \u001b[0m 0.8058  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.9091\ttraining's l2: 62.5539\tvalid_1's rmse: 8.32167\tvalid_1's l2: 69.2501\n",
      "[200]\ttraining's rmse: 7.2936\ttraining's l2: 53.1966\tvalid_1's rmse: 8.10291\tvalid_1's l2: 65.6572\n",
      "[300]\ttraining's rmse: 6.8971\ttraining's l2: 47.57\tvalid_1's rmse: 8.05178\tvalid_1's l2: 64.8312\n",
      "[400]\ttraining's rmse: 6.56334\ttraining's l2: 43.0775\tvalid_1's rmse: 8.02231\tvalid_1's l2: 64.3575\n",
      "[500]\ttraining's rmse: 6.26881\ttraining's l2: 39.298\tvalid_1's rmse: 8.00755\tvalid_1's l2: 64.1209\n",
      "[600]\ttraining's rmse: 6.00026\ttraining's l2: 36.0032\tvalid_1's rmse: 8.00077\tvalid_1's l2: 64.0123\n",
      "[700]\ttraining's rmse: 5.75333\ttraining's l2: 33.1009\tvalid_1's rmse: 7.99338\tvalid_1's l2: 63.8941\n",
      "[800]\ttraining's rmse: 5.52468\ttraining's l2: 30.5221\tvalid_1's rmse: 7.99372\tvalid_1's l2: 63.8995\n",
      "Early stopping, best iteration is:\n",
      "[764]\ttraining's rmse: 5.60556\ttraining's l2: 31.4223\tvalid_1's rmse: 7.99256\tvalid_1's l2: 63.881\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 7.993   \u001b[0m | \u001b[0m 0.7876  \u001b[0m | \u001b[0m 240.7   \u001b[0m | \u001b[0m 13.27   \u001b[0m | \u001b[0m 133.4   \u001b[0m | \u001b[0m 33.93   \u001b[0m | \u001b[0m 28.29   \u001b[0m | \u001b[0m 39.58   \u001b[0m | \u001b[0m 1.11    \u001b[0m | \u001b[0m 0.7515  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.73887\ttraining's l2: 59.8902\tvalid_1's rmse: 8.29099\tvalid_1's l2: 68.7406\n",
      "[200]\ttraining's rmse: 7.01691\ttraining's l2: 49.237\tvalid_1's rmse: 8.07949\tvalid_1's l2: 65.2782\n",
      "[300]\ttraining's rmse: 6.53369\ttraining's l2: 42.6891\tvalid_1's rmse: 8.03175\tvalid_1's l2: 64.5089\n",
      "[400]\ttraining's rmse: 6.12798\ttraining's l2: 37.5522\tvalid_1's rmse: 8.01313\tvalid_1's l2: 64.2102\n",
      "[500]\ttraining's rmse: 5.76526\ttraining's l2: 33.2382\tvalid_1's rmse: 8.00618\tvalid_1's l2: 64.099\n",
      "[600]\ttraining's rmse: 5.43652\ttraining's l2: 29.5558\tvalid_1's rmse: 8.00239\tvalid_1's l2: 64.0383\n",
      "Early stopping, best iteration is:\n",
      "[569]\ttraining's rmse: 5.53384\ttraining's l2: 30.6233\tvalid_1's rmse: 8.00172\tvalid_1's l2: 64.0275\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 8.002   \u001b[0m | \u001b[0m 0.5948  \u001b[0m | \u001b[0m 65.55   \u001b[0m | \u001b[0m 13.15   \u001b[0m | \u001b[0m 102.1   \u001b[0m | \u001b[0m 8.454   \u001b[0m | \u001b[0m 37.71   \u001b[0m | \u001b[0m 8.496   \u001b[0m | \u001b[0m 8.393   \u001b[0m | \u001b[0m 0.7137  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.68845\ttraining's l2: 59.1123\tvalid_1's rmse: 8.26972\tvalid_1's l2: 68.3883\n",
      "[200]\ttraining's rmse: 6.93432\ttraining's l2: 48.0848\tvalid_1's rmse: 8.06273\tvalid_1's l2: 65.0077\n",
      "[300]\ttraining's rmse: 6.42798\ttraining's l2: 41.319\tvalid_1's rmse: 8.01596\tvalid_1's l2: 64.2556\n",
      "[400]\ttraining's rmse: 5.99386\ttraining's l2: 35.9264\tvalid_1's rmse: 8.00113\tvalid_1's l2: 64.018\n",
      "[500]\ttraining's rmse: 5.61162\ttraining's l2: 31.4903\tvalid_1's rmse: 7.99274\tvalid_1's l2: 63.8839\n",
      "[600]\ttraining's rmse: 5.26328\ttraining's l2: 27.7021\tvalid_1's rmse: 7.99035\tvalid_1's l2: 63.8457\n",
      "Early stopping, best iteration is:\n",
      "[590]\ttraining's rmse: 5.29665\ttraining's l2: 28.0545\tvalid_1's rmse: 7.98826\tvalid_1's l2: 63.8123\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 7.988   \u001b[0m | \u001b[0m 0.5543  \u001b[0m | \u001b[0m 266.6   \u001b[0m | \u001b[0m 12.65   \u001b[0m | \u001b[0m 147.4   \u001b[0m | \u001b[0m 13.2    \u001b[0m | \u001b[0m 45.91   \u001b[0m | \u001b[0m 23.86   \u001b[0m | \u001b[0m 8.469   \u001b[0m | \u001b[0m 0.9726  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.94077\ttraining's l2: 63.0558\tvalid_1's rmse: 8.327\tvalid_1's l2: 69.339\n",
      "[200]\ttraining's rmse: 7.34076\ttraining's l2: 53.8867\tvalid_1's rmse: 8.10459\tvalid_1's l2: 65.6844\n",
      "[300]\ttraining's rmse: 6.96029\ttraining's l2: 48.4456\tvalid_1's rmse: 8.04868\tvalid_1's l2: 64.7813\n",
      "[400]\ttraining's rmse: 6.64651\ttraining's l2: 44.1761\tvalid_1's rmse: 8.0245\tvalid_1's l2: 64.3926\n",
      "[500]\ttraining's rmse: 6.36965\ttraining's l2: 40.5725\tvalid_1's rmse: 8.01572\tvalid_1's l2: 64.2518\n",
      "[600]\ttraining's rmse: 6.11574\ttraining's l2: 37.4022\tvalid_1's rmse: 8.01327\tvalid_1's l2: 64.2124\n",
      "[700]\ttraining's rmse: 5.88024\ttraining's l2: 34.5772\tvalid_1's rmse: 8.01132\tvalid_1's l2: 64.1813\n",
      "[800]\ttraining's rmse: 5.66029\ttraining's l2: 32.0389\tvalid_1's rmse: 8.00874\tvalid_1's l2: 64.14\n",
      "[900]\ttraining's rmse: 5.45525\ttraining's l2: 29.7597\tvalid_1's rmse: 8.00722\tvalid_1's l2: 64.1156\n",
      "Early stopping, best iteration is:\n",
      "[869]\ttraining's rmse: 5.51739\ttraining's l2: 30.4415\tvalid_1's rmse: 8.00679\tvalid_1's l2: 64.1087\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 8.007   \u001b[0m | \u001b[0m 0.9163  \u001b[0m | \u001b[0m 384.0   \u001b[0m | \u001b[0m 13.91   \u001b[0m | \u001b[0m 185.3   \u001b[0m | \u001b[0m 47.65   \u001b[0m | \u001b[0m 25.9    \u001b[0m | \u001b[0m 8.361   \u001b[0m | \u001b[0m 4.478   \u001b[0m | \u001b[0m 0.9917  \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.85494\ttraining's l2: 61.7\tvalid_1's rmse: 8.30623\tvalid_1's l2: 68.9935\n",
      "[200]\ttraining's rmse: 7.20665\ttraining's l2: 51.9358\tvalid_1's rmse: 8.09238\tvalid_1's l2: 65.4866\n",
      "[300]\ttraining's rmse: 6.77994\ttraining's l2: 45.9676\tvalid_1's rmse: 8.04875\tvalid_1's l2: 64.7824\n",
      "[400]\ttraining's rmse: 6.42206\ttraining's l2: 41.2428\tvalid_1's rmse: 8.02412\tvalid_1's l2: 64.3864\n",
      "[500]\ttraining's rmse: 6.1068\ttraining's l2: 37.2931\tvalid_1's rmse: 8.01389\tvalid_1's l2: 64.2224\n",
      "[600]\ttraining's rmse: 5.81728\ttraining's l2: 33.8407\tvalid_1's rmse: 8.01374\tvalid_1's l2: 64.22\n",
      "[700]\ttraining's rmse: 5.55222\ttraining's l2: 30.8271\tvalid_1's rmse: 8.01119\tvalid_1's l2: 64.1791\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's rmse: 5.71465\ttraining's l2: 32.6572\tvalid_1's rmse: 8.00982\tvalid_1's l2: 64.1573\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 8.01    \u001b[0m | \u001b[0m 0.8589  \u001b[0m | \u001b[0m 387.4   \u001b[0m | \u001b[0m 14.1    \u001b[0m | \u001b[0m 173.6   \u001b[0m | \u001b[0m 44.01   \u001b[0m | \u001b[0m 31.4    \u001b[0m | \u001b[0m 4.522   \u001b[0m | \u001b[0m 5.429   \u001b[0m | \u001b[0m 0.6041  \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(f=lgb_rmse_eval, pbounds=bayesian_params, random_state=1000)\n",
    "lgbBO.maximize(init_points=5, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 8.010737395246808,\n",
       "  'params': {'colsample_bytree': 0.8267947927323047,\n",
       "   'max_bin': 66.35340213095881,\n",
       "   'max_depth': 15.602262914792195,\n",
       "   'min_child_samples': 101.61636627131966,\n",
       "   'min_child_weight': 43.75125222391973,\n",
       "   'num_leaves': 32.4933072369088,\n",
       "   'reg_alpha': 2.045074142206765,\n",
       "   'reg_lambda': 3.9725474189957124,\n",
       "   'subsample': 0.61656609867419}},\n",
       " {'target': 8.015319043537328,\n",
       "  'params': {'colsample_bytree': 0.9208703621265308,\n",
       "   'max_bin': 111.47034874950597,\n",
       "   'max_depth': 13.93975626865927,\n",
       "   'min_child_samples': 84.50928428367985,\n",
       "   'min_child_weight': 9.930569477666833,\n",
       "   'num_leaves': 53.7415765836856,\n",
       "   'reg_alpha': 3.488408227688028,\n",
       "   'reg_lambda': 8.853486706603126,\n",
       "   'subsample': 0.9763221996107709}},\n",
       " {'target': 8.011820908059523,\n",
       "  'params': {'colsample_bytree': 0.9655717173387555,\n",
       "   'max_bin': 213.56116699200484,\n",
       "   'max_depth': 8.23185327509497,\n",
       "   'min_child_samples': 196.58522207365755,\n",
       "   'min_child_weight': 17.64224649812914,\n",
       "   'num_leaves': 52.26748775555215,\n",
       "   'reg_alpha': 18.100234609702014,\n",
       "   'reg_lambda': 0.35202387361566295,\n",
       "   'subsample': 0.9275291266202039}},\n",
       " {'target': 8.018604435513682,\n",
       "  'params': {'colsample_bytree': 0.8286267540702462,\n",
       "   'max_bin': 385.1846671311669,\n",
       "   'max_depth': 12.432697904035154,\n",
       "   'min_child_samples': 178.16765795601393,\n",
       "   'min_child_weight': 45.305683154470756,\n",
       "   'num_leaves': 24.416868022358166,\n",
       "   'reg_alpha': 3.737091239759974,\n",
       "   'reg_lambda': 2.447047468388093,\n",
       "   'subsample': 0.5666523762257424}},\n",
       " {'target': 8.006457954912083,\n",
       "  'params': {'colsample_bytree': 0.8489625502048597,\n",
       "   'max_bin': 205.1203929277082,\n",
       "   'max_depth': 15.064977531233142,\n",
       "   'min_child_samples': 44.39142695200357,\n",
       "   'min_child_weight': 22.19245941780866,\n",
       "   'num_leaves': 24.725728110186907,\n",
       "   'reg_alpha': 34.57497870582523,\n",
       "   'reg_lambda': 4.697436829706333,\n",
       "   'subsample': 0.5641110948268239}},\n",
       " {'target': 8.005254556729838,\n",
       "  'params': {'colsample_bytree': 0.5138539751871029,\n",
       "   'max_bin': 381.5696516923507,\n",
       "   'max_depth': 13.716016020044616,\n",
       "   'min_child_samples': 184.83226208225145,\n",
       "   'min_child_weight': 39.84380556109519,\n",
       "   'num_leaves': 28.957700334894714,\n",
       "   'reg_alpha': 7.240381210585427,\n",
       "   'reg_lambda': 0.6001870359150129,\n",
       "   'subsample': 0.940582229628937}},\n",
       " {'target': 8.003830039117222,\n",
       "  'params': {'colsample_bytree': 0.684242198017279,\n",
       "   'max_bin': 25.210162988456304,\n",
       "   'max_depth': 10.86227380741599,\n",
       "   'min_child_samples': 168.36821974494066,\n",
       "   'min_child_weight': 24.29033031493233,\n",
       "   'num_leaves': 44.837188494255855,\n",
       "   'reg_alpha': 7.394401788129303,\n",
       "   'reg_lambda': 2.3419398516773966,\n",
       "   'subsample': 0.7360379914074062}},\n",
       " {'target': 8.00066530555751,\n",
       "  'params': {'colsample_bytree': 0.7675419859658956,\n",
       "   'max_bin': 132.0199627366569,\n",
       "   'max_depth': 14.298915241781739,\n",
       "   'min_child_samples': 40.3924686618707,\n",
       "   'min_child_weight': 44.75925548935725,\n",
       "   'num_leaves': 35.85435623811703,\n",
       "   'reg_alpha': 33.161736698845125,\n",
       "   'reg_lambda': 4.179346930104301,\n",
       "   'subsample': 0.9904558712794339}},\n",
       " {'target': 8.00549356360302,\n",
       "  'params': {'colsample_bytree': 0.5909121889605802,\n",
       "   'max_bin': 151.4451283058841,\n",
       "   'max_depth': 8.12570510974261,\n",
       "   'min_child_samples': 67.70982537785662,\n",
       "   'min_child_weight': 12.179556446382666,\n",
       "   'num_leaves': 57.97492807929662,\n",
       "   'reg_alpha': 5.11327135472758,\n",
       "   'reg_lambda': 2.9634057731939567,\n",
       "   'subsample': 0.5073924938486567}},\n",
       " {'target': 8.00603240169169,\n",
       "  'params': {'colsample_bytree': 0.9254172005439811,\n",
       "   'max_bin': 416.7208648802382,\n",
       "   'max_depth': 10.76574953773526,\n",
       "   'min_child_samples': 126.91007769267303,\n",
       "   'min_child_weight': 26.11112160742515,\n",
       "   'num_leaves': 29.613949340778454,\n",
       "   'reg_alpha': 48.70271304115722,\n",
       "   'reg_lambda': 7.307286495379972,\n",
       "   'subsample': 0.5610568992324143}},\n",
       " {'target': 7.998430870313294,\n",
       "  'params': {'colsample_bytree': 0.5141043094390911,\n",
       "   'max_bin': 254.3407418874025,\n",
       "   'max_depth': 15.332770159742921,\n",
       "   'min_child_samples': 103.21393354412879,\n",
       "   'min_child_weight': 46.90043392010393,\n",
       "   'num_leaves': 32.33623155988221,\n",
       "   'reg_alpha': 12.21846097676822,\n",
       "   'reg_lambda': 9.777330191074164,\n",
       "   'subsample': 0.6988643735876281}},\n",
       " {'target': 8.005231582678464,\n",
       "  'params': {'colsample_bytree': 0.5714645329357839,\n",
       "   'max_bin': 420.3449035602966,\n",
       "   'max_depth': 15.043879875899249,\n",
       "   'min_child_samples': 124.99880880459827,\n",
       "   'min_child_weight': 3.5244762071364786,\n",
       "   'num_leaves': 35.44420386327446,\n",
       "   'reg_alpha': 22.54827686645599,\n",
       "   'reg_lambda': 3.945893499815971,\n",
       "   'subsample': 0.9636697925128256}},\n",
       " {'target': 7.993579495234434,\n",
       "  'params': {'colsample_bytree': 0.579276254301057,\n",
       "   'max_bin': 255.18517768650602,\n",
       "   'max_depth': 13.550001654403957,\n",
       "   'min_child_samples': 12.505066102402521,\n",
       "   'min_child_weight': 29.42773011515404,\n",
       "   'num_leaves': 39.820389083540235,\n",
       "   'reg_alpha': 33.960034049410424,\n",
       "   'reg_lambda': 5.65260345331489,\n",
       "   'subsample': 0.8581227529538189}},\n",
       " {'target': 8.004355417239335,\n",
       "  'params': {'colsample_bytree': 0.6464371516415328,\n",
       "   'max_bin': 212.7951882260217,\n",
       "   'max_depth': 9.075548813868783,\n",
       "   'min_child_samples': 32.06927980062517,\n",
       "   'min_child_weight': 22.79731494793803,\n",
       "   'num_leaves': 47.67936927865554,\n",
       "   'reg_alpha': 48.938112708376934,\n",
       "   'reg_lambda': 5.882906904286742,\n",
       "   'subsample': 0.8768332875895308}},\n",
       " {'target': 8.01649992695361,\n",
       "  'params': {'colsample_bytree': 0.66587818349067,\n",
       "   'max_bin': 318.85670293585764,\n",
       "   'max_depth': 14.696083656856331,\n",
       "   'min_child_samples': 89.28919948696489,\n",
       "   'min_child_weight': 7.6786440348103335,\n",
       "   'num_leaves': 54.40354378771569,\n",
       "   'reg_alpha': 41.984699177480934,\n",
       "   'reg_lambda': 4.397204203719935,\n",
       "   'subsample': 0.6464426489126807}},\n",
       " {'target': 8.006346291004983,\n",
       "  'params': {'colsample_bytree': 0.8911768943126078,\n",
       "   'max_bin': 226.82335694733166,\n",
       "   'max_depth': 9.58652048927745,\n",
       "   'min_child_samples': 45.26117358341472,\n",
       "   'min_child_weight': 38.35804601447657,\n",
       "   'num_leaves': 58.79479371344334,\n",
       "   'reg_alpha': 48.616770778588304,\n",
       "   'reg_lambda': 2.7092744689647326,\n",
       "   'subsample': 0.9831742043197643}},\n",
       " {'target': 8.017071822402563,\n",
       "  'params': {'colsample_bytree': 0.9318807646090632,\n",
       "   'max_bin': 265.05132830154224,\n",
       "   'max_depth': 8.634833232254739,\n",
       "   'min_child_samples': 55.92302516802116,\n",
       "   'min_child_weight': 4.254390351086849,\n",
       "   'num_leaves': 32.03886139159377,\n",
       "   'reg_alpha': 37.83364228095505,\n",
       "   'reg_lambda': 6.107782167557087,\n",
       "   'subsample': 0.9043824557585871}},\n",
       " {'target': 8.005196440539098,\n",
       "  'params': {'colsample_bytree': 0.8400676823446944,\n",
       "   'max_bin': 218.03126694416892,\n",
       "   'max_depth': 10.828374957564478,\n",
       "   'min_child_samples': 18.53296578103854,\n",
       "   'min_child_weight': 44.08053706636261,\n",
       "   'num_leaves': 48.2828624584605,\n",
       "   'reg_alpha': 31.386355289971423,\n",
       "   'reg_lambda': 5.16125396023365,\n",
       "   'subsample': 0.8320839011056689}},\n",
       " {'target': 8.018086456419457,\n",
       "  'params': {'colsample_bytree': 0.7178480127649094,\n",
       "   'max_bin': 174.6944105583218,\n",
       "   'max_depth': 10.291625851974237,\n",
       "   'min_child_samples': 36.11565074404746,\n",
       "   'min_child_weight': 11.2039887326501,\n",
       "   'num_leaves': 59.424618627709016,\n",
       "   'reg_alpha': 23.53333846758369,\n",
       "   'reg_lambda': 9.779720391939048,\n",
       "   'subsample': 0.562822235810886}},\n",
       " {'target': 7.999811763442329,\n",
       "  'params': {'colsample_bytree': 0.8023267797378124,\n",
       "   'max_bin': 372.2860100070965,\n",
       "   'max_depth': 13.219571070044436,\n",
       "   'min_child_samples': 189.73023488549583,\n",
       "   'min_child_weight': 29.798620436536304,\n",
       "   'num_leaves': 29.276672554717873,\n",
       "   'reg_alpha': 46.44571088697003,\n",
       "   'reg_lambda': 6.261069677877012,\n",
       "   'subsample': 0.5583173239443255}},\n",
       " {'target': 7.984408369711788,\n",
       "  'params': {'colsample_bytree': 0.6120817815183712,\n",
       "   'max_bin': 56.0127776812391,\n",
       "   'max_depth': 13.317409740581677,\n",
       "   'min_child_samples': 86.02488861817797,\n",
       "   'min_child_weight': 2.5349663365974218,\n",
       "   'num_leaves': 43.42729499707772,\n",
       "   'reg_alpha': 12.803004993547578,\n",
       "   'reg_lambda': 3.4478154743231246,\n",
       "   'subsample': 0.5242887645884554}},\n",
       " {'target': 8.00014788247321,\n",
       "  'params': {'colsample_bytree': 0.6732251624430192,\n",
       "   'max_bin': 294.7874607558146,\n",
       "   'max_depth': 15.03557802324086,\n",
       "   'min_child_samples': 117.94571860407643,\n",
       "   'min_child_weight': 26.818627877552583,\n",
       "   'num_leaves': 46.0687492784547,\n",
       "   'reg_alpha': 13.764074735933072,\n",
       "   'reg_lambda': 3.301926621834465,\n",
       "   'subsample': 0.536326218637151}},\n",
       " {'target': 8.004212773373062,\n",
       "  'params': {'colsample_bytree': 0.8190266681526392,\n",
       "   'max_bin': 33.68191484561372,\n",
       "   'max_depth': 14.314513862874048,\n",
       "   'min_child_samples': 81.77454047856418,\n",
       "   'min_child_weight': 30.156229899215923,\n",
       "   'num_leaves': 39.26811414744852,\n",
       "   'reg_alpha': 19.79003701633323,\n",
       "   'reg_lambda': 7.492847592955431,\n",
       "   'subsample': 0.6173422050108449}},\n",
       " {'target': 8.005763289509728,\n",
       "  'params': {'colsample_bytree': 0.7313688492739636,\n",
       "   'max_bin': 322.5275403491443,\n",
       "   'max_depth': 14.673684562656568,\n",
       "   'min_child_samples': 29.114738453076193,\n",
       "   'min_child_weight': 46.030863317824036,\n",
       "   'num_leaves': 47.0053495458919,\n",
       "   'reg_alpha': 44.834265453778464,\n",
       "   'reg_lambda': 5.78718670439186,\n",
       "   'subsample': 0.6073219592234658}},\n",
       " {'target': 8.01253156517642,\n",
       "  'params': {'colsample_bytree': 0.9711690837725098,\n",
       "   'max_bin': 489.01892794129435,\n",
       "   'max_depth': 15.25460690968541,\n",
       "   'min_child_samples': 49.441701762561564,\n",
       "   'min_child_weight': 26.524651705286505,\n",
       "   'num_leaves': 47.23669174089605,\n",
       "   'reg_alpha': 39.94907265936229,\n",
       "   'reg_lambda': 2.888339333527107,\n",
       "   'subsample': 0.8058092781209045}},\n",
       " {'target': 7.992561551442956,\n",
       "  'params': {'colsample_bytree': 0.7875849687909198,\n",
       "   'max_bin': 240.73276061806476,\n",
       "   'max_depth': 13.271184231558605,\n",
       "   'min_child_samples': 133.44942208159318,\n",
       "   'min_child_weight': 33.92950087465731,\n",
       "   'num_leaves': 28.29136702239342,\n",
       "   'reg_alpha': 39.57648860320042,\n",
       "   'reg_lambda': 1.1096346827494934,\n",
       "   'subsample': 0.7514903797268531}},\n",
       " {'target': 8.001716936171547,\n",
       "  'params': {'colsample_bytree': 0.5948136651099992,\n",
       "   'max_bin': 65.54879996738464,\n",
       "   'max_depth': 13.147136974234437,\n",
       "   'min_child_samples': 102.1230118149357,\n",
       "   'min_child_weight': 8.454065086716847,\n",
       "   'num_leaves': 37.71286374411538,\n",
       "   'reg_alpha': 8.495603759047018,\n",
       "   'reg_lambda': 8.3932459613762,\n",
       "   'subsample': 0.7136850800625171}},\n",
       " {'target': 7.9882610429086975,\n",
       "  'params': {'colsample_bytree': 0.5543446579385094,\n",
       "   'max_bin': 266.60902033120465,\n",
       "   'max_depth': 12.646496395874314,\n",
       "   'min_child_samples': 147.43609706902322,\n",
       "   'min_child_weight': 13.197385976374632,\n",
       "   'num_leaves': 45.91016035048342,\n",
       "   'reg_alpha': 23.860024134242312,\n",
       "   'reg_lambda': 8.46904710281589,\n",
       "   'subsample': 0.9725842699472822}},\n",
       " {'target': 8.00679364364367,\n",
       "  'params': {'colsample_bytree': 0.9162703348962282,\n",
       "   'max_bin': 384.04924095355176,\n",
       "   'max_depth': 13.91262134347572,\n",
       "   'min_child_samples': 185.3200960028081,\n",
       "   'min_child_weight': 47.649556749573165,\n",
       "   'num_leaves': 25.90492144495778,\n",
       "   'reg_alpha': 8.361256055676304,\n",
       "   'reg_lambda': 4.4779496750050605,\n",
       "   'subsample': 0.9917165049169472}},\n",
       " {'target': 8.009822479568427,\n",
       "  'params': {'colsample_bytree': 0.8589494014982919,\n",
       "   'max_bin': 387.4376025280827,\n",
       "   'max_depth': 14.098927349774781,\n",
       "   'min_child_samples': 173.60673641389954,\n",
       "   'min_child_weight': 44.00722552434488,\n",
       "   'num_leaves': 31.401002440131418,\n",
       "   'reg_alpha': 4.52208802797327,\n",
       "   'reg_lambda': 5.42879801554507,\n",
       "   'subsample': 0.6040700539125308}}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.010737395246808, 8.015319043537328, 8.011820908059523, 8.018604435513682, 8.006457954912083, 8.005254556729838, 8.003830039117222, 8.00066530555751, 8.00549356360302, 8.00603240169169, 7.998430870313294, 8.005231582678464, 7.993579495234434, 8.004355417239335, 8.01649992695361, 8.006346291004983, 8.017071822402563, 8.005196440539098, 8.018086456419457, 7.999811763442329, 7.984408369711788, 8.00014788247321, 8.004212773373062, 8.005763289509728, 8.01253156517642, 7.992561551442956, 8.001716936171547, 7.9882610429086975, 8.00679364364367, 8.009822479568427]\n",
      "maximum target index: 20\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmin(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 7.984408369711788, 'params': {'colsample_bytree': 0.6120817815183712, 'max_bin': 56.0127776812391, 'max_depth': 13.317409740581677, 'min_child_samples': 86.02488861817797, 'min_child_weight': 2.5349663365974218, 'num_leaves': 43.42729499707772, 'reg_alpha': 12.803004993547578, 'reg_lambda': 3.4478154743231246, 'subsample': 0.5242887645884554}}\n"
     ]
    }
   ],
   "source": [
    "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
    "max_dict = lgbBO.res[np.argmin(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = pd.DataFrame(data2[:, 1:])\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "def train_apps_all_with_oof(ftr, target, nfolds=5):\n",
    "    ftr = ftr\n",
    "    target = target\n",
    "\n",
    "    # nfolds 개의 cross validatin fold set을 가지는 KFold 생성 \n",
    "    folds = KFold(n_splits=nfolds, shuffle=True, random_state=0)\n",
    "    \n",
    "    # Out of Folds로 학습된 모델의 validation set을 예측하여 결과 확률을 담을 array 생성.\n",
    "    # validation set가 n_split갯수만큼 있으므로 크기는 ftr_app의 크기가 되어야 함. \n",
    "    oof_preds = np.zeros((ftr.shape[0],))  \n",
    "    \n",
    "    # Ouf of Folds로 학습된 모델의 test dataset을 예측하여 결과 확률을 담을 array 생성. \n",
    "    test_preds = np.zeros(((pd.DataFrame(data_te2[:,1:]).shape[0],)))\n",
    "    \n",
    "    # n_estimators를 4000까지 확대. \n",
    "    clf = LGBMRegressor(\n",
    "                nthread=4,\n",
    "                n_estimators=4000,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=13,\n",
    "                num_leaves=43,\n",
    "                colsample_bytree=0.612,\n",
    "                subsample=0.524,\n",
    "                max_bin= 56,\n",
    "                reg_alpha=12.803,\n",
    "                reg_lambda=8.393,\n",
    "                min_child_weight=8,\n",
    "                min_child_samples=102,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                )\n",
    "\n",
    "    # nfolds 번 cross validation Iteration 반복하면서 OOF 방식으로 학습 및 테스트 데이터 예측\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(ftr)):\n",
    "        print('##### iteration ', fold_idx, ' 시작')\n",
    "        # 학습용 데이터 세트의 인덱스와 검증용 데이터 세트의 인덱스 추출하여 이를 기반으로 학습/검증 데이터 추출\n",
    "        train_x = ftr.iloc[train_idx, :]\n",
    "        train_y = target.iloc[train_idx]\n",
    "        valid_x = ftr.iloc[valid_idx, :]\n",
    "        valid_y = target.iloc[valid_idx]\n",
    "        \n",
    "        # 추출된 학습/검증 데이터 세트로 모델 학습. early_stopping은 200으로 증가. \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'RMSE', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "        # 검증 데이터 세트로 예측된 확률 저장. 사용되지는 않음. \n",
    "        #oof_preds[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration_)       \n",
    "        # 학습된 모델로 테스트 데이터 세트에 예측 확률 계산. \n",
    "        # nfolds 번 반복 실행하므로 평균 확률을 구하기 위해 개별 수행시 마다 수행 횟수로 나눈 확률을 추후에 더해서 최종 평균 확률 계산. \n",
    "        test_preds += clf.predict(data_te2[:,1:], num_iteration=clf.best_iteration_)/folds.n_splits\n",
    "        \n",
    "        \n",
    "    return clf, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### iteration  0  시작\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 7.73901\ttraining's l2: 59.8923\tvalid_1's rmse: 8.32756\tvalid_1's l2: 69.3482\n",
      "[400]\ttraining's rmse: 7.03913\ttraining's l2: 49.5493\tvalid_1's rmse: 8.10946\tvalid_1's l2: 65.7633\n",
      "[600]\ttraining's rmse: 6.57495\ttraining's l2: 43.23\tvalid_1's rmse: 8.0605\tvalid_1's l2: 64.9716\n",
      "[800]\ttraining's rmse: 6.1837\ttraining's l2: 38.2381\tvalid_1's rmse: 8.03527\tvalid_1's l2: 64.5656\n",
      "[1000]\ttraining's rmse: 5.84044\ttraining's l2: 34.1107\tvalid_1's rmse: 8.0235\tvalid_1's l2: 64.3766\n",
      "[1200]\ttraining's rmse: 5.53363\ttraining's l2: 30.6211\tvalid_1's rmse: 8.0188\tvalid_1's l2: 64.3012\n",
      "[1400]\ttraining's rmse: 5.25153\ttraining's l2: 27.5785\tvalid_1's rmse: 8.01529\tvalid_1's l2: 64.2449\n",
      "[1600]\ttraining's rmse: 4.99024\ttraining's l2: 24.9025\tvalid_1's rmse: 8.01393\tvalid_1's l2: 64.223\n",
      "Early stopping, best iteration is:\n",
      "[1511]\ttraining's rmse: 5.10334\ttraining's l2: 26.0441\tvalid_1's rmse: 8.01274\tvalid_1's l2: 64.204\n",
      "##### iteration  1  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 7.78066\ttraining's l2: 60.5387\tvalid_1's rmse: 8.20698\tvalid_1's l2: 67.3545\n",
      "[400]\ttraining's rmse: 7.07466\ttraining's l2: 50.0508\tvalid_1's rmse: 7.96092\tvalid_1's l2: 63.3763\n",
      "[600]\ttraining's rmse: 6.60619\ttraining's l2: 43.6418\tvalid_1's rmse: 7.90675\tvalid_1's l2: 62.5166\n",
      "[800]\ttraining's rmse: 6.21095\ttraining's l2: 38.5759\tvalid_1's rmse: 7.87623\tvalid_1's l2: 62.0349\n",
      "[1000]\ttraining's rmse: 5.865\ttraining's l2: 34.3983\tvalid_1's rmse: 7.86064\tvalid_1's l2: 61.7897\n",
      "[1200]\ttraining's rmse: 5.55444\ttraining's l2: 30.8518\tvalid_1's rmse: 7.84835\tvalid_1's l2: 61.5966\n",
      "[1400]\ttraining's rmse: 5.26922\ttraining's l2: 27.7647\tvalid_1's rmse: 7.84202\tvalid_1's l2: 61.4972\n",
      "[1600]\ttraining's rmse: 5.00685\ttraining's l2: 25.0686\tvalid_1's rmse: 7.84062\tvalid_1's l2: 61.4754\n",
      "[1800]\ttraining's rmse: 4.76688\ttraining's l2: 22.7232\tvalid_1's rmse: 7.83959\tvalid_1's l2: 61.4592\n",
      "[2000]\ttraining's rmse: 4.54194\ttraining's l2: 20.6292\tvalid_1's rmse: 7.83828\tvalid_1's l2: 61.4386\n",
      "Early stopping, best iteration is:\n",
      "[1868]\ttraining's rmse: 4.68933\ttraining's l2: 21.9898\tvalid_1's rmse: 7.83766\tvalid_1's l2: 61.429\n",
      "##### iteration  2  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 7.75775\ttraining's l2: 60.1827\tvalid_1's rmse: 8.28468\tvalid_1's l2: 68.6359\n",
      "[400]\ttraining's rmse: 7.05182\ttraining's l2: 49.7282\tvalid_1's rmse: 8.06699\tvalid_1's l2: 65.0764\n",
      "[600]\ttraining's rmse: 6.58056\ttraining's l2: 43.3037\tvalid_1's rmse: 8.00781\tvalid_1's l2: 64.125\n",
      "[800]\ttraining's rmse: 6.18453\ttraining's l2: 38.2484\tvalid_1's rmse: 7.98171\tvalid_1's l2: 63.7077\n",
      "[1000]\ttraining's rmse: 5.83801\ttraining's l2: 34.0824\tvalid_1's rmse: 7.96801\tvalid_1's l2: 63.4893\n",
      "[1200]\ttraining's rmse: 5.52313\ttraining's l2: 30.505\tvalid_1's rmse: 7.96376\tvalid_1's l2: 63.4214\n",
      "[1400]\ttraining's rmse: 5.2366\ttraining's l2: 27.422\tvalid_1's rmse: 7.96423\tvalid_1's l2: 63.429\n",
      "Early stopping, best iteration is:\n",
      "[1224]\ttraining's rmse: 5.48703\ttraining's l2: 30.1074\tvalid_1's rmse: 7.96267\tvalid_1's l2: 63.4041\n",
      "##### iteration  3  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 7.71503\ttraining's l2: 59.5218\tvalid_1's rmse: 8.43854\tvalid_1's l2: 71.209\n",
      "[400]\ttraining's rmse: 7.00667\ttraining's l2: 49.0934\tvalid_1's rmse: 8.2099\tvalid_1's l2: 67.4025\n",
      "[600]\ttraining's rmse: 6.53803\ttraining's l2: 42.7458\tvalid_1's rmse: 8.14248\tvalid_1's l2: 66.2999\n",
      "[800]\ttraining's rmse: 6.14465\ttraining's l2: 37.7567\tvalid_1's rmse: 8.10882\tvalid_1's l2: 65.753\n",
      "[1000]\ttraining's rmse: 5.79647\ttraining's l2: 33.5991\tvalid_1's rmse: 8.09047\tvalid_1's l2: 65.4557\n",
      "[1200]\ttraining's rmse: 5.48653\ttraining's l2: 30.102\tvalid_1's rmse: 8.08163\tvalid_1's l2: 65.3127\n",
      "[1400]\ttraining's rmse: 5.20525\ttraining's l2: 27.0946\tvalid_1's rmse: 8.07899\tvalid_1's l2: 65.27\n",
      "Early stopping, best iteration is:\n",
      "[1314]\ttraining's rmse: 5.32365\ttraining's l2: 28.3412\tvalid_1's rmse: 8.07707\tvalid_1's l2: 65.239\n",
      "##### iteration  4  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 7.7647\ttraining's l2: 60.2906\tvalid_1's rmse: 8.29575\tvalid_1's l2: 68.8194\n",
      "[400]\ttraining's rmse: 7.06574\ttraining's l2: 49.9247\tvalid_1's rmse: 8.05066\tvalid_1's l2: 64.8131\n",
      "[600]\ttraining's rmse: 6.59225\ttraining's l2: 43.4578\tvalid_1's rmse: 7.98628\tvalid_1's l2: 63.7807\n",
      "[800]\ttraining's rmse: 6.19244\ttraining's l2: 38.3464\tvalid_1's rmse: 7.95856\tvalid_1's l2: 63.3386\n",
      "[1000]\ttraining's rmse: 5.84283\ttraining's l2: 34.1387\tvalid_1's rmse: 7.94496\tvalid_1's l2: 63.1224\n",
      "[1200]\ttraining's rmse: 5.53141\ttraining's l2: 30.5966\tvalid_1's rmse: 7.93519\tvalid_1's l2: 62.9672\n",
      "[1400]\ttraining's rmse: 5.24424\ttraining's l2: 27.5021\tvalid_1's rmse: 7.92955\tvalid_1's l2: 62.8778\n",
      "[1600]\ttraining's rmse: 4.98161\ttraining's l2: 24.8164\tvalid_1's rmse: 7.92801\tvalid_1's l2: 62.8533\n",
      "[1800]\ttraining's rmse: 4.73977\ttraining's l2: 22.4654\tvalid_1's rmse: 7.92709\tvalid_1's l2: 62.8387\n",
      "[2000]\ttraining's rmse: 4.51237\ttraining's l2: 20.3615\tvalid_1's rmse: 7.92689\tvalid_1's l2: 62.8356\n",
      "Early stopping, best iteration is:\n",
      "[1915]\ttraining's rmse: 4.60767\ttraining's l2: 21.2306\tvalid_1's rmse: 7.92524\tvalid_1's l2: 62.8094\n"
     ]
    }
   ],
   "source": [
    "clf, test_preds = train_apps_all_with_oof(ftr, target, nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42.10341618, 40.98521977, 26.00266241, ..., 36.57434369,\n",
       "       33.35405562, 29.04774064])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDtest['age'] = test_preds ; sub = IDtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub.to_csv('submissions_0615_zi_min_scaled_lgbm_tun.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = data2[:, 1:]\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').age\n",
    "target = y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ftr, target, test_size=0.2 ,stratify=target, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingRegressor 로그 변환된 RMSE: 7.987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.98715985836425]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rmse(model):\n",
    "    pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test , pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('{0} 로그 변환된 RMSE: {1}'.format(model.__class__.__name__,np.round(rmse, 3)))\n",
    "    return rmse\n",
    "\n",
    "def get_rmses(models):\n",
    "    rmses = [ ]\n",
    "    for model in models:\n",
    "        rmse = get_rmse(model)\n",
    "        rmses.append(rmse)\n",
    "    return rmses\n",
    "\n",
    "param_lgb = {'colsample_bytree': 0.612, 'max_bin': 56, \n",
    "             'max_depth': 13, 'min_child_samples': 86,\n",
    "             'min_child_weight': 2.53, 'num_leaves': 43, 'reg_alpha': 12.803, \n",
    "             'reg_lambda': 3.447, 'subsample': 0.524}\n",
    "\n",
    "lgbm = LGBMRegressor(random_state = 1000 , **param_lgb )\n",
    "cat = CatBoostRegressor(random_state=1000 )\n",
    "reg_ridge = Ridge(random_state = 1000)\n",
    "\n",
    "vr = VotingRegressor(estimators=[('lgbm', lgbm), ('cat', cat) , ('reg_ridge' , reg_ridge )],  n_jobs=-1)\n",
    "vr = vr.fit(X_train, y_train)\n",
    "\n",
    "models = [vr]\n",
    "get_rmses(models)\n",
    "\n",
    "\n",
    "# VotingRegressor 로그 변환된 RMSE: 7.968 -> lgb , cat ,ridge\n",
    "# [7.967520700609481]\n",
    "\n",
    "# VotingRegressor 로그 변환된 RMSE: 7.974- > lgb_tun , cat ,ridge\n",
    "# [7.9742317956902875]\n",
    "\n",
    "# VotingRegressor 로그 변환된 RMSE: 7.987\n",
    "# [7.98715985836425]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'submissions_0615_zi_min_select_vr_tun.csv' is ready to submit.\n"
     ]
    }
   ],
   "source": [
    "pred = vr.predict(data_te2[:,1:])\n",
    "fname = 'submissions_0615_zi_min_select_vr_tun.csv'\n",
    "submissions = pd.concat([pd.Series(IDtest['custid'], name=\"custid\"), pd.Series(pred, name=\"age\")] ,axis=1)\n",
    "submissions.to_csv(fname, index=False)\n",
    "print(\"'{}' is ready to submit.\" .format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30001</td>\n",
       "      <td>39.478306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30002</td>\n",
       "      <td>41.542168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30003</td>\n",
       "      <td>25.881382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30005</td>\n",
       "      <td>30.490629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30007</td>\n",
       "      <td>22.651624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>49988</td>\n",
       "      <td>36.513519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>49990</td>\n",
       "      <td>34.506005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>49992</td>\n",
       "      <td>37.429092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>49993</td>\n",
       "      <td>33.366580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>49994</td>\n",
       "      <td>29.225522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       custid        age\n",
       "0       30001  39.478306\n",
       "1       30002  41.542168\n",
       "2       30003  25.881382\n",
       "3       30005  30.490629\n",
       "4       30007  22.651624\n",
       "...       ...        ...\n",
       "14375   49988  36.513519\n",
       "14376   49990  34.506005\n",
       "14377   49992  37.429092\n",
       "14378   49993  33.366580\n",
       "14379   49994  29.225522\n",
       "\n",
       "[14380 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.read_csv('submissions_0615_zi_min_select_vr_tun.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
