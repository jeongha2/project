{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family=fm.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()) # for Windows OS user\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from tensorflow import keras\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sys, warnings\n",
    "if not sys.warnoptions: warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd7e3527fd56e5b5855c6846ca226f5f860f725b"
   },
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train_c = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "794123064b09797f51add356a676fb6a7aed015d"
   },
   "outputs": [],
   "source": [
    "df_x_train = pd.read_csv(os.path.abspath(\"../input\")+'/X_train.csv', encoding='cp949')\n",
    "df_x_test = pd.read_csv(os.path.abspath(\"../input\")+'/X_test.csv', encoding='cp949')\n",
    "df_y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv').age\n",
    "IDtrain = pd.DataFrame({'custid': df_x_train.custid.unique()})\n",
    "IDtest = pd.DataFrame({'custid': df_x_test.custid.unique()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.concat([df_x_train, df_x_test])\n",
    "tr['real_amt']= tr.tot_amt / tr.inst_mon\n",
    "tr['dist_rate'] = (tr['dis_amt']/tr['tot_amt'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_data = pd.DataFrame({'custid': tr.custid.unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['sales_hour'] = tr['sales_time']//100\n",
    "tr['sales_min'] = tr['sales_time']%100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[\"sales_date\"] = np.where(tr[\"sales_month\"] >9 , \n",
    "                            (tr[\"sales_month\"].astype(str)),(\"0\"+tr[\"sales_month\"].astype(str)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[\"sales_date\"] = np.where(tr[\"sales_day\"]>9,(tr[\"sales_date\"]+tr[\"sales_day\"].astype(str)),\n",
    "                            (tr[\"sales_date\"]+\"0\"+tr[\"sales_day\"].astype(str))\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[\"sales_month\"] = np.where(tr[\"sales_month\"]>12 , tr[\"sales_month\"]-12, tr[\"sales_month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[\"time\"] = pd.to_datetime(tr.sales_time, format = \"%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[\"refund\"] = np.where(tr[\"net_amt\"]<0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['sales_month_ver1'] = tr['sales_month']\n",
    "tr['sales_month'] = tr['sales_month'].apply(lambda x : x-12 if x > 12 else x )\n",
    "tr['sales_hour'] = tr['sales_time'].apply(lambda x : x//100 )\n",
    "tr['sales_sec'] = tr['sales_time'].apply(lambda x : x%100 )\n",
    "tr['total_sec'] = tr['sales_time'].apply(lambda x : x//100*60 + x%100 )\n",
    "tr['환불여부'] = tr['tot_amt'].apply(lambda x : 1 if x < 0 else 0 )\n",
    "tr['refund'] = tr['tot_amt'].apply(lambda x : abs(x) if x < 0 else 0 )\n",
    "tr['tot_amt'] = tr['tot_amt'] .apply(lambda x : 0 if x < 0 else x )\n",
    "tr['real_amt'] = ( tr['tot_amt'] / tr['inst_mon'] ).apply(lambda x : math.trunc(x)) \n",
    "tr['sales_date'] =tr['sales_month_ver1'].astype(str).apply(lambda x : \"0\"+x if len(x) == 1  else x ) +tr['sales_day'].astype(str).apply(lambda x : \"0\"+x if len(x) == 1 else  x )\n",
    "tr['sales_date'] = tr['sales_date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(tr, df_y_train_c, on = 'custid')\n",
    "tr['age_group'] = df['age'].apply(lambda x : 'twenty' if (x>=20) & (x<30)\n",
    "                                     else 'thirty' if (x>=30) & (x<40)\n",
    "                                     else 'forty' if (x>=40) & (x<50)\n",
    "                                     else 'fifty' if (x>=50) & (x<60)\n",
    "                                     else 'sixty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_prefer_brd = tr[tr['age_group'] == 'twenty'].brd_nm.value_counts().index[1:].to_list()\n",
    "thirty_prefer_brd = tr[tr['age_group'] == 'thirty'].brd_nm.value_counts().index[1:].to_list()\n",
    "forty_prefer_brd = tr[tr['age_group'] == 'forty'].brd_nm.value_counts().index[1:].to_list()\n",
    "fifty_prefer_brd = tr[tr['age_group'] == 'fifty'].brd_nm.value_counts().index[1:].to_list()\n",
    "sixty_prefer_brd = tr[tr['age_group'] == 'sixty'].brd_nm.value_counts().index[1:].to_list()\n",
    "\n",
    "def prefer_brd(x, list):\n",
    "    for i in range(len(list)):\n",
    "        if(x == list[i]):\n",
    "            return len(list)-i\n",
    "\n",
    "tr['20_weight'] = tr['brd_nm'].apply(lambda x: prefer_brd(x, twenty_prefer_brd)).fillna(0)\n",
    "tr['30_weight'] = tr['brd_nm'].apply(lambda x: prefer_brd(x, thirty_prefer_brd)).fillna(0)\n",
    "tr['40_weight'] = tr['brd_nm'].apply(lambda x: prefer_brd(x, forty_prefer_brd)).fillna(0)\n",
    "tr['50_weight'] = tr['brd_nm'].apply(lambda x: prefer_brd(x, fifty_prefer_brd)).fillna(0)\n",
    "tr['60_weight'] = tr['brd_nm'].apply(lambda x: prefer_brd(x, sixty_prefer_brd)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[\"age_weight_sum\"] = tr['20_weight']+tr['30_weight']+tr['40_weight']+tr['50_weight']+tr['60_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr[\"sales_season\"] = tr['sales_month'].apply(lambda x : 'SPRING' if (x>=3) and (x<=5)\n",
    "                                                  else 'SUMMER' if (x>=6) and (x<=8)\n",
    "                                                  else 'FALL' if (x>=9) and (x<=11)\n",
    "                                                  else 'WINTER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['tot_amt>=0'] = tr['tot_amt'].apply(lambda x : x if x>=0 else 0)\n",
    "tr['dis_amt>=0'] = tr['dis_amt'].apply(lambda x : x if x>=0 else 0)\n",
    "tr['net_amt>=0'] = tr['net_amt'].apply(lambda x : x if x>=0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(x, n):\n",
    "    lst = []\n",
    "    random.seed(100)\n",
    "    for i in x:\n",
    "        tmp = []\n",
    "        for j in range(n):\n",
    "            random.shuffle(i)\n",
    "            tmp += list(i)\n",
    "            lst.append(tmp)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V goodcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=tr.reset_index().drop('index',axis=1).copy().reset_index()\n",
    "df['goodcd']=df['goodcd'].astype('str')\n",
    "train_data=list(df.groupby('custid')['goodcd'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_input = oversample(train_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = word2vec.Word2Vec(sentences = w2v_input, vector_size = 100, window = 5,workers=6, min_count = 1, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 35967/35967 [00:02<00:00, 13983.21it/s]\n"
     ]
    }
   ],
   "source": [
    "train_mean_vector = []\n",
    "for words in tqdm(train_data):\n",
    "    tmp = np.zeros(100)\n",
    "    cnt = 0\n",
    "    for word in words:\n",
    "        tmp += w2v.wv[word]\n",
    "        cnt += 1\n",
    "    tmp /= cnt\n",
    "    train_mean_vector.append(tmp)\n",
    "train_mean_vector = np.array(train_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_good= pd.DataFrame(train_mean_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V brd_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=tr.reset_index().drop('index',axis=1).copy().reset_index()\n",
    "train_data=list(df.groupby('custid')['brd_nm'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_input = oversample(train_data, 5)\n",
    "w2v = word2vec.Word2Vec(sentences = w2v_input, vector_size = 100, window = 5,workers=6, min_count = 1, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 35967/35967 [00:02<00:00, 15418.24it/s]\n"
     ]
    }
   ],
   "source": [
    "train_mean_vector = []\n",
    "for words in tqdm(train_data):\n",
    "    tmp = np.zeros(100)\n",
    "    cnt = 0\n",
    "    for word in words:\n",
    "        tmp += w2v.wv[word]\n",
    "        cnt += 1\n",
    "    tmp /= cnt\n",
    "    train_mean_vector.append(tmp)\n",
    "train_mean_vector = np.array(train_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_brd = pd.DataFrame(train_mean_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V corner_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=tr.reset_index().drop('index',axis=1).copy().reset_index()\n",
    "train_data=list(df.groupby('custid')['corner_nm'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_input = oversample(train_data, 5)\n",
    "w2v = word2vec.Word2Vec(sentences = w2v_input, vector_size = 100, window = 5,workers=6, min_count = 1, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 35967/35967 [00:02<00:00, 16444.42it/s]\n"
     ]
    }
   ],
   "source": [
    "train_mean_vector = []\n",
    "for words in tqdm(train_data):\n",
    "    tmp = np.zeros(100)\n",
    "    cnt = 0\n",
    "    for word in words:\n",
    "        tmp += w2v.wv[word]\n",
    "        cnt += 1\n",
    "    tmp /= cnt\n",
    "    train_mean_vector.append(tmp)\n",
    "train_mean_vector = np.array(train_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_coner = pd.DataFrame(train_mean_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 환불데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tr.groupby(\"custid\")[\"refund\"].agg([(\"refund_count\",\"sum\")]).reset_index()\n",
    "t[\"refund_bool\"] = np.where(t[\"refund_count\"]>0,1,0)\n",
    "features.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cn  구매하는 나이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([id_data,df_y_train],axis = 1)\n",
    "data = data.iloc[:len(df_y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = pd.merge(tr,data,on=\"custid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_cor_mean = tr_data.groupby(\"corner_nm\")[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corner_nm\n",
       "DC캐주얼      37.875949\n",
       "GBR  지원    46.125000\n",
       "L/B침구      36.815166\n",
       "N/B침구      37.051136\n",
       "NB제화       36.269504\n",
       "             ...    \n",
       "홈데코        36.025105\n",
       "홈쇼핑        62.000000\n",
       "화장잡화       38.326142\n",
       "화장품        31.930435\n",
       "훼미닌부틱      48.281167\n",
       "Name: age, Length: 308, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_cor_mean # 주구매 코너를 이걸로 매핑해주자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- brd 구매 평균나이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_brd_mean = tr_data.groupby(\"brd_nm\")[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pc 구매 평균나이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pc_mean = tr_data.groupby(\"pc_nm\")[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주구매 요일 나이평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_day_mean = tr_data.groupby(\"sales_dayofweek\")[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refund_check(x):\n",
    "    if x<0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 환불 총액, 평균 , 최대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = tr.copy()\n",
    "copy_df[\"tot_amt_refund\"] = copy_df.net_amt.apply(refund_check)\n",
    "t = copy_df.groupby(\"custid\")[\"tot_amt_refund\"].agg([(\"amt_refund\",\"sum\"),\n",
    "                                                    (\"amt_refund_mean\",\"mean\"),\n",
    "                                                    (\"amt_refund_max\",\"min\")]).reset_index()\n",
    "features.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최애브랜드 사용수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    y = x.value_counts()\n",
    "    y = y.iloc[0]\n",
    "    return y\n",
    "\n",
    "f = tr.groupby('custid')['brd_nm'].agg([('love_brd_count', g)]).reset_index()\n",
    "f = f.fillna(0)\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 연령대별 브랜드 선호도에 따른 가중치 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tr.groupby('custid')['20_weight', '30_weight', '40_weight', '50_weight', '60_weight', 'age_weight_sum'].sum()\n",
    "\n",
    "f['20_weight_ratio'] = f['20_weight'] / f['age_weight_sum']\n",
    "f['30_weight_ratio'] = f['30_weight'] / f['age_weight_sum']\n",
    "f['40_weight_ratio'] = f['40_weight'] / f['age_weight_sum']\n",
    "f['50_weight_ratio'] = f['50_weight'] / f['age_weight_sum']\n",
    "f['60_weight_ratio'] = f['60_weight'] / f['age_weight_sum']\n",
    "\n",
    "f = f.fillna(0)\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시간대별 방문횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.pivot_table(tr, index='custid', columns='sales_hour', values='tot_amt', \n",
    "                   aggfunc=np.size).fillna(0).astype(int).reset_index()\n",
    "features.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시간대별 구매금액"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.pivot_table(tr, index='custid', columns='sales_hour', values='tot_amt', \n",
    "                   aggfunc=\"sum\").fillna(0).astype(int).reset_index().drop([0,1,8,9],axis = 1)\n",
    "features.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 날짜별 방문횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.pivot_table(tr, index='custid', columns='sales_day', values='tot_amt', \n",
    "                   aggfunc=np.size).fillna(0).astype(int).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = id_data.copy()\n",
    "f[\"month_start\"] = 0\n",
    "f[\"month_mid\"] = 0\n",
    "f[\"month_end\"] = 0 \n",
    "for i in [x for x in range(1,11)]:\n",
    "    f[\"month_start\"] += t[i]\n",
    "    f[\"month_mid\"] += t[i+10]\n",
    "    f[\"month_end\"] += t[i+20]\n",
    "f[\"month_end\"] += t[31]\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 날짜별 구매금액"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.pivot_table(tr, index='custid', columns='sales_day', values='tot_amt', \n",
    "                   aggfunc=\"sum\").fillna(0).astype(int).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = id_data.copy()\n",
    "f[\"month_start\"] = 0\n",
    "f[\"month_mid\"] = 0\n",
    "f[\"month_end\"] = 0 \n",
    "for i in [x for x in range(1,11)]:\n",
    "    f[\"month_start\"] += t[i]\n",
    "    f[\"month_mid\"] += t[i+10]\n",
    "    f[\"month_end\"] += t[i+20]\n",
    "f[\"month_end\"] += t[31]\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 월간별 날짜횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.pivot_table(tr, index='custid', columns='sales_month', values='tot_amt', \n",
    "                   aggfunc=np.size).fillna(0).astype(int).reset_index()\n",
    "features.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 월간 구매금액"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.pivot_table(tr, index='custid', columns='sales_month', values='tot_amt', \n",
    "                   aggfunc=\"sum\").fillna(0).astype(int).reset_index()\n",
    "features.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#쇼핑시간\n",
    "time_sum = tr.groupby(['sales_date','custid'])['time'].agg([('time', ['min','max'])]).reset_index()\n",
    "time_sum['shopping_time'] = (time_sum['time']['max'] - time_sum['time']['min']).dt.total_seconds()\n",
    "time_sum.drop(['sales_date','time'], axis=1, inplace=True,level=0)\n",
    "time_sum = time_sum.groupby(['custid'])['shopping_time'].agg([('shopping_time_mean','mean')]).reset_index()\n",
    "features.append(time_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균할인율\n",
    "f = tr.groupby('custid')['dist_rate'].agg([('dis_rate', 'mean')]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균시간\n",
    "f = tr.groupby(['custid'])['sales_time'].agg([('sales_time', 'mean')]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#남성파트\n",
    "df = tr.groupby(['custid','part_nm'])['tot_amt'].agg([('tot_amt_part', 'sum')]).reset_index()\n",
    "df['part_nm'] = np.where(df.part_nm.str.contains('남성'), '남성', '비남성')\n",
    "df = df.pivot_table(values='tot_amt_part', index=df.custid, columns='part_nm', aggfunc='first',fill_value=0).reset_index()\n",
    "df['남성part'] = (df['남성'] / (df['남성'] + df['비남성'])) * 100\n",
    "df = df.fillna(0)\n",
    "features.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#화장품구매비율\n",
    "df = tr.groupby(['custid','corner_nm'])['tot_amt'].agg([('tot_amt_corner', 'sum')]).reset_index()\n",
    "df['corner_nm'] = np.where(df.corner_nm.str.contains('화장품'), '화장품', '비화장품')\n",
    "df = df.pivot_table(values='tot_amt_corner', index=df.custid, columns='corner_nm', aggfunc='first',fill_value=0).reset_index()\n",
    "df['화장품비율'] = (df['화장품'] / (df['화장품'] + df['비화장품'])) * 100\n",
    "df = df.fillna(0)\n",
    "features.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#할부대비평균실구매\n",
    "f = tr.groupby('custid')['real_amt'].agg([('real_amt', 'mean')]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균구매상품종류\n",
    "df =tr.groupby(['custid','goodcd'])['tot_amt'].agg([('good_count', 'count')]).reset_index()\n",
    "f = df.groupby(['custid'])['good_count'].agg([('good_count_mean', 'mean')]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#지역\n",
    "df = tr.groupby(['custid','str_nm'])['tot_amt'].agg([('tot_amt_str', 'sum')]).reset_index()\n",
    "df =df.pivot_table(values='tot_amt_str', index=df.custid, columns='str_nm', aggfunc='first',fill_value=0).reset_index()\n",
    "features.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#팀별\n",
    "df = tr.groupby(['custid','team_nm'])['tot_amt'].agg([('tot_amt_team', 'sum')]).reset_index()\n",
    "df =df.pivot_table(values='tot_amt_team', index=df.custid, columns='team_nm', aggfunc='first',fill_value=0).reset_index()\n",
    "features.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#총구매수입상품\n",
    "df = tr.groupby(['custid'])['import_flg'].agg([('import_flg_sum', 'sum')]).reset_index()\n",
    "features.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파트\n",
    "df = tr.groupby(['custid','part_nm'])['tot_amt'].agg([('tot_amt_part', 'sum')]).reset_index()\n",
    "df =df.pivot_table(values='tot_amt_part', index=df.custid, columns='part_nm', aggfunc='first',fill_value=0).reset_index()\n",
    "features.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코너\n",
    "df = tr.groupby(['custid','corner_nm'])['tot_amt'].agg([('tot_amt_corner', 'sum')]).reset_index()\n",
    "df =df.pivot_table(values='tot_amt_corner', index=df.custid, columns='corner_nm', aggfunc='first',fill_value=0).reset_index()\n",
    "features.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pc\n",
    "df = tr.groupby(['custid','pc_nm'])['tot_amt'].agg([('tot_amt_pc', 'sum')]).reset_index()\n",
    "df =df.pivot_table(values='tot_amt_pc', index=df.custid, columns='pc_nm', aggfunc='first',fill_value=0).reset_index()\n",
    "features.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#총구매액\n",
    "f = tr.groupby('custid')['tot_amt'].agg([('총구매액', 'sum')]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#구매건수\n",
    "f = tr.groupby('custid')['tot_amt'].agg([('구매건수', 'size')]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균구매가격\n",
    "\n",
    "f = tr.groupby('custid')['tot_amt'].agg([('평균구매가격', \"mean\")]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균할부개월수\n",
    "f = tr.groupby('custid')['inst_mon'].agg([('평균할부개월수', 'mean')]).reset_index()\n",
    "f.iloc[:,1] = f.iloc[:,1].apply(round, args=(1,))\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#구매상품다양성\n",
    "n = tr.corner_nm.nunique()\n",
    "f = tr.groupby('custid')['brd_nm'].agg([('구매상품다양성', lambda x: len(x.unique()) / n)]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#수입상품_구매비율\n",
    "x = tr[tr['import_flg'] == 1].groupby('custid').size() / tr.groupby('custid').size()\n",
    "f = x.reset_index().rename(columns={0: '수입상품_구매비율'}).fillna(0)\n",
    "f.iloc[:,1] = (f.iloc[:,1]*100).apply(round, args=(1,))\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#일평균구매액\n",
    "test2 = tr.groupby(['sales_date','custid'])['tot_amt'].agg([('day_amt', 'sum')]).reset_index()\n",
    "test2 = test2.groupby(['custid'])['day_amt'].agg([('일평균구매액', 'mean')]).reset_index()\n",
    "features.append(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#내점일수 \n",
    "\n",
    "f = tr.groupby(by = 'custid')['sales_time'].agg([('내점일수','nunique')]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#일평균구매건\n",
    "df = tr.groupby(['sales_date','custid'])['custid'].agg([('day_visit', 'count')]).reset_index()\n",
    "f = df.groupby(['custid'])['day_visit'].agg([('일평균구매건', 'mean')]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#아동상품 구매건수\n",
    "f = tr[tr.tot_amt > 0].groupby('custid')['part_nm'].agg([('baby_sales', lambda x: list(x).count('아동')+list(x).count('케주얼,구두,아동')+list(x).count('아동문화')+list(x).count('아동,스포츠'))]).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상위 브랜드 40개의 구매빈도\n",
    "top_brd = tr[\"brd_nm\"].value_counts()[:40].index\n",
    "df = tr.groupby(['custid','brd_nm'])[\"custid\"].agg([('brd_count', 'count')]).reset_index()\n",
    "df =df.pivot_table(values='brd_count', index=df.custid, columns=\"brd_nm\", aggfunc='count',fill_value=0).reset_index()\n",
    "df = pd.concat([df[\"custid\"] ,df[top_brd]],axis= 1)\n",
    "features.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상위 브랜드 40개의 구매금액\n",
    "df = tr.groupby(['custid','brd_nm'])[\"tot_amt\"].agg([('tot_amt_brd', 'sum')]).reset_index()\n",
    "df =df.pivot_table(values='tot_amt_brd', index=df.custid, columns=\"brd_nm\", aggfunc='sum',fill_value=0).reset_index()\n",
    "df = pd.concat([df[\"custid\"] ,df[top_brd]],axis= 1)\n",
    "features.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#주말방문비율\n",
    "day = {'월' : 0 , '화' : 1 , '수' : 2 , '목' : 3 , '금' : 4 , '토': 5 , '일' : 6 }\n",
    "\n",
    "tr['sales_dayofweek_num'] = tr['sales_dayofweek'].apply(lambda x : day[x] )\n",
    "\n",
    "f = tr.groupby('custid')['sales_dayofweek_num'].agg([\n",
    "    ('주말방문비율', lambda x: np.mean(x >4))]).reset_index()\n",
    "\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#계절별 구매 건수\n",
    "def season(k):\n",
    "    if 3 <= k <= 5 :\n",
    "        return('봄')\n",
    "    elif 6 <= k <= 8 :\n",
    "        return('여름')\n",
    "    elif 9 <= k <= 11 :    \n",
    "        return('가을')\n",
    "    else :\n",
    "        return('겨울')\n",
    "df = tr.copy()\n",
    "df[\"season\"] = df.sales_month.apply(season)\n",
    "f = pd.pivot_table(df, index='custid', columns='season', values='tot_amt', \n",
    "                   aggfunc=np.size, fill_value=0).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#계절별 구매 금액\n",
    "df = tr.copy()\n",
    "df[\"season\"] = df.sales_month.apply(season)\n",
    "f = pd.pivot_table(df, index='custid', columns='season', values='tot_amt', \n",
    "                   aggfunc=\"sum\", fill_value=0).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#아침점심저녁별 구매건수\n",
    "def f2(x):\n",
    "    if 9 <= x <= 12 :\n",
    "        return('아침')\n",
    "    elif 13 <= x <= 16 :\n",
    "        return('점심')\n",
    "    else :\n",
    "        return('저녁')  # datatime 필드가 시간 형식에 맞지 않은 값을 갖는 경우 저녁시간으로 처리\n",
    "df = tr.copy()\n",
    "df[\"goodmea\"] = df.sales_hour.apply(f2)\n",
    "f = pd.pivot_table(df, index='custid', columns='goodmea', values='tot_amt', \n",
    "                   aggfunc=np.size).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#아침점심저녁별 구매금액\n",
    "df = tr.copy()\n",
    "df[\"goodmea\"] = df.sales_hour.apply(f2)\n",
    "f = pd.pivot_table(df, index='custid', columns='goodmea', values='tot_amt', \n",
    "                   aggfunc=\"sum\").reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#주방문요일\n",
    "f = tr.groupby('custid')['sales_dayofweek'].agg([('주방문요일', lambda x: x.value_counts().index[0])]).reset_index()\n",
    "f = pd.get_dummies(f, columns=['주방문요일'])\n",
    "\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균 쇼핑시간\n",
    "f = tr.groupby('custid')['total_sec'].agg([\n",
    "    ('평균쇼핑시간', lambda x: (x.max() - x.min()) / x.nunique())]).reset_index()\n",
    "\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#일별 구매건수\n",
    "f = pd.pivot_table(tr, index='custid', columns='sales_day', values='tot_amt', \n",
    "                   aggfunc=np.size).fillna(0).astype(int).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#일별 구매금액\n",
    "f = pd.pivot_table(tr, index='custid', columns='sales_day', values='tot_amt', \n",
    "                   aggfunc=\"sum\").fillna(0).astype(int).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#월별 구매건수\n",
    "f = pd.pivot_table(tr, index='custid', columns='sales_month', values='tot_amt', \n",
    "                   aggfunc=np.size).fillna(0).astype(int).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#월별 구매금액\n",
    "f = pd.pivot_table(tr, index='custid', columns='sales_month', values='tot_amt', \n",
    "                   aggfunc=\"sum\").fillna(0).astype(int).reset_index()\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([id_data,df_y_train],axis = 1)\n",
    "data = data.iloc[:len(df_y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = pd.merge(tr,data,on=\"custid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_cor_mean = dict(tr_data.groupby(\"corner_nm\")[\"age\"].mean())\n",
    "tr_brd_mean = dict(tr_data.groupby(\"brd_nm\")[\"age\"].mean())\n",
    "tr_pc_mean = dict(tr_data.groupby(\"pc_nm\")[\"age\"].mean())\n",
    "tr_day_mean = dict(tr_data.groupby(\"sales_dayofweek\")[\"age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "brd_data = tr.groupby(\"custid\")[\"pc_nm\"].agg([(\"pc\",\"first\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = brd_data[\"pc\"].apply(lambda x: tr_pc_mean[x])\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tr.groupby(\"custid\")[\"corner_nm\"].agg([(\"cor\",\"first\")])\n",
    "f = d[\"cor\"].apply(lambda x: tr_cor_mean[x])\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tr.groupby(\"custid\")[\"sales_dayofweek\"].agg([(\"day\",\"first\")])\n",
    "f = d[\"day\"].apply(lambda x: tr_day_mean[x])\n",
    "features.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21587, 715)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = pd.DataFrame({'custid': df_x_train.custid.unique()})\n",
    "for f in features :\n",
    "    X_train = pd.merge(X_train, f, how='left',on='custid')\n",
    "display(X_train.shape)\n",
    "\n",
    "X_test = pd.DataFrame({'custid': df_x_test.custid.unique()})\n",
    "for f in features :\n",
    "    X_test = pd.merge(X_test, f, how='left',on='custid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['평균내점구매액'] = X_train['총구매액']/X_train['내점일수']\n",
    "X_train['주중방문비율'] = (100 - X_train[\"주말방문비율\"])\n",
    "X_train['국내상품_구매비율'] = (100 - X_train['수입상품_구매비율'])\n",
    "X_train['할부구매가격'] = X_train['평균구매가격'] / X_train['평균할부개월수']\n",
    "X_train['구매상품다양성'] = X_train['총구매액'] / X_train['구매상품다양성']\n",
    "X_train['주말방문수'] = (X_train['주말방문비율'] * X_train['내점일수']) / 100\n",
    "X_train['주말방문수'] = X_train['주말방문수'].astype('int64')\n",
    "X_train['주중방문수'] = X_train['내점일수'] - X_train['주말방문수']\n",
    "X_train['주중방문수'] = X_train['주중방문수'].astype('int64')\n",
    "X_train['내점당편균구매건수'] = X_train['구매건수']/X_train['내점일수']\n",
    "X_train['주중구매액'] = X_train['총구매액']*(X_train['주중방문비율']/100)\n",
    "X_train['주말구매액'] = X_train['총구매액'] - X_train['주중구매액']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['평균내점구매액'] = X_test['총구매액']/X_test['내점일수']\n",
    "X_test['주중방문비율'] = (100 - X_test['주말방문비율'])\n",
    "X_test['국내상품_구매비율'] = (100 - X_test['수입상품_구매비율'])\n",
    "X_test['할부구매가격'] = X_test['평균구매가격'] / X_test['평균할부개월수']\n",
    "X_test['구매상품다양성'] = X_test['총구매액'] / X_test['구매상품다양성']\n",
    "X_test['주말방문수'] = (X_test['주말방문비율'] * X_test['내점일수']) / 100\n",
    "X_test['주말방문수'] = X_test['주말방문수'].astype('int64')\n",
    "X_test['주중방문수'] = X_test['내점일수'] - X_test['주말방문수']\n",
    "X_test['주중방문수'] = X_test['주중방문수'].astype('int64')\n",
    "X_test['내점당편균구매건수'] = X_test['구매건수']/X_test['내점일수']\n",
    "X_test['주중구매액'] = X_test['총구매액']*(X_test['주중방문비율']/100)\n",
    "X_test['주말구매액'] = X_test['총구매액'] - X_test['주중구매액']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmean 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "features__ = X_train.drop(columns='custid',axis=1).fillna(0)\n",
    "features_t__= X_test.drop(columns='custid',axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class KMeansFeaturizer:\n",
    "    \"\"\" 숫자 데이터를 k-평균 클러스터 멤버십으로 변환.\n",
    "\n",
    "    이 변환기는 입력 데이터에 k-평균을 수행해 각 데이터 포인트를 가장 가까운 클러스터의 id로 변환한다.\n",
    "    만약 목표 변수가 주어지면 유사한 데이터 포인트와 함께 grouping되고,\n",
    "    분류 경계에 따르는 클러스터를 생성하기 위해 스케일링되고, k-평균 입력에 포함된다.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k = 100, target_scale = 5.0, random_state = None):\n",
    "        self.k = k\n",
    "        self.target_scale = target_scale\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        \"\"\" 입력 데이터에 k-평균을 수행하고 중심점을 찾는다.\n",
    "        \"\"\"\n",
    "        if y is None: # 목표 변수가 없으면 단순한 k-평균 수행\n",
    "            km_model = KMeans(n_clusters = self.k, n_init = 20, random_state = self.random_state)\n",
    "            km_model.fit(X)\n",
    "            \n",
    "            self.inertia_ = km_model.inertia_\n",
    "            self.km_model = km_model\n",
    "            self.cluster_centers_ = km_model.cluster_centers_\n",
    "            return self\n",
    "\n",
    "        # 목표 변수가 있으면, 적절한 스케일링을 적용하고, 이를 k-평균에 대한 입력 데이터에 포함시킨다.\n",
    "        data_with_target = np.hstack((X, y[:, np.newaxis] * self.target_scale))\n",
    "        # 데이터와 타겟에 대해 사전 학습할 k-평균 모델 구축\n",
    "        km_model_pretrain = KMeans(n_clusters = self.k, n_init = 20, random_state = self.random_state)\n",
    "        km_model_pretrain.fit(data_with_target)\n",
    "\n",
    "        # k평균을 두번째로 실행해 목표 변수 없이 원시 공간에서 클러스터를 얻는다. 사전 학습을 통해 얻은 중심점을 활용해 초기화한다.\n",
    "        # 반복을 통해 클러스터 할당과 중심점 계산을 다시 수행한다.\n",
    "\n",
    "        km_model = KMeans(n_clusters = self.k, init = km_model_pretrain.cluster_centers_[:,:data_with_target.shape[1]-1], n_init = 1, max_iter = 1)\n",
    "\n",
    "        km_model.fit(X)\n",
    "        \n",
    "        self.inertia_ = km_model.inertia_\n",
    "        self.km_model = km_model\n",
    "        self.cluster_centers_ = km_model.cluster_centers_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        \"\"\" 각 입력 데이터 포인트에 대해 가장 가까운 클러스터 ID 산출\n",
    "        \"\"\"\n",
    "        clusters = self.km_model.predict(X)\n",
    "        return clusters[:, np.newaxis]\n",
    "\n",
    "    def fit_transform(self, X, y = None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "kme = KMeansFeaturizer(random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_k = kme.fit_transform(features__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_k_t = kme.transform(features_t__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_kmean = pd.concat([pd.DataFrame(features_k),pd.DataFrame(features_k_t)],axis = 0).reset_index().drop(\"index\",axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_kmean = features_kmean.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_k_dum = pd.get_dummies(features_kmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_col = features_k_dum.shape[1]\n",
    "pca = PCA(n_components=max_col, random_state=0).fit(features_k_dum)\n",
    "\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "num_col = np.argmax(cumsum >= 0.99) + 1\n",
    "\n",
    "\n",
    "if num_col == 1:\n",
    "    num_col = max_col\n",
    "\n",
    "pca = PCA(n_components = num_col, random_state=0).fit_transform(features_k_dum)\n",
    "features_k_dum = pd.DataFrame(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_k_train = features_k_dum[:len(features__)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_k_test = features_k_dum[len(features__):].reset_index().drop(\"index\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "features__ = pd.concat([features__,features_k_train],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_t__ = pd.concat([features_t__,features_k_test],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = features__.columns.to_series().groupby(level=0).transform('cumcount')\n",
    "features__.columns = identifier.astype('string')\n",
    "\n",
    "identifier_t = features_t__.columns.to_series().groupby(level=0).transform('cumcount')\n",
    "features_t__.columns = identifier_t.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = features__.columns.to_series().groupby(level=0).transform('cumcount')\n",
    "features__.columns = features__.columns.astype('string') + identifier.astype('string')\n",
    "\n",
    "identifier_t = features_t__.columns.to_series().groupby(level=0).transform('cumcount')\n",
    "features_t__.columns = features_t__.columns.astype('string') + identifier_t.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1등 피쳐 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ji = pd.read_csv(os.path.abspath(\"../input\")+\"/지평오빠feature.csv\")\n",
    "ji_t = pd.read_csv(os.path.abspath(\"../input\")+\"/지평오빠feature_te.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns1 = ji.dtypes[ji.dtypes != 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewlist1 = []\n",
    "numeric_columns_ns1 = []\n",
    "\n",
    "for i in numeric_columns1:\n",
    "    if 'SKEW' in i:\n",
    "        skewlist1.append(i)\n",
    "    else:\n",
    "        numeric_columns_ns1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "ji[numeric_columns1] = scaler.fit_transform(ji[numeric_columns1])\n",
    "ji_t[numeric_columns1] = scaler.transform(ji_t[numeric_columns1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마이피쳐 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns2 = features__.dtypes[features__.dtypes != 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewlist2 = []\n",
    "numeric_columns_ns2 = []\n",
    "\n",
    "for i in numeric_columns2:\n",
    "    if 'SKEW' in i:\n",
    "        skewlist2.append(i)\n",
    "    else:\n",
    "        numeric_columns_ns2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features__[numeric_columns2] = scaler.fit_transform(features__[numeric_columns2])\n",
    "features_t__[numeric_columns2] = scaler.transform(features_t__[numeric_columns2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마이피쳐 + 1st 피쳐 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([ji[numeric_columns_ns1],ji[skewlist1], features__[numeric_columns_ns2], features__[skewlist2] ], axis=1)\n",
    "\n",
    "features_t__.index = ji_t.index\n",
    "data_te = pd.concat([ji_t[numeric_columns_ns1],ji_t[skewlist1] , features_t__[numeric_columns_ns2], features_t__[skewlist2] ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 워드투벡 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_list = [w2v_good,w2v_coner,w2v_brd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.concat([data,data_te],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = data_all.reset_index().drop(\"index\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in w2v_list:\n",
    "    data_all = pd.concat([data_all,i],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.drop(\"custid\",axis =1 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all[:len(features__)]\n",
    "data_te = data_all[len(features__):].reset_index().drop(\"index\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.astype(str)\n",
    "data_te.columns = data_te.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.values\n",
    "data_te2 = data_te.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = data2[:, 1:]\n",
    "target = df_y_train\n",
    "target_log = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17269, 17125), (4318, 17125))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr, target, test_size=0.2 , stratify = target , random_state=1000)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 7.7676\ttraining's l2: 60.3357\tvalid_1's rmse: 8.30134\tvalid_1's l2: 68.9122\n",
      "[200]\ttraining's rmse: 7.02968\ttraining's l2: 49.4164\tvalid_1's rmse: 8.09159\tvalid_1's l2: 65.4738\n",
      "[300]\ttraining's rmse: 6.53169\ttraining's l2: 42.663\tvalid_1's rmse: 8.05721\tvalid_1's l2: 64.9186\n",
      "[400]\ttraining's rmse: 6.12835\ttraining's l2: 37.5567\tvalid_1's rmse: 8.05002\tvalid_1's l2: 64.8028\n",
      "Early stopping, best iteration is:\n",
      "[406]\ttraining's rmse: 6.10618\ttraining's l2: 37.2855\tvalid_1's rmse: 8.04892\tvalid_1's l2: 64.7852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.02, max_depth=12, n_estimators=1000,\n",
       "              num_leaves=32, silent=-1, subsample=0.8, verbose=-1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "clf = LGBMRegressor(\n",
    "        n_jobs=-1,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=32,\n",
    "        subsample=0.8,\n",
    "        max_depth=12,\n",
    "        silent=-1,\n",
    "        verbose=-1\n",
    "        )\n",
    "\n",
    "clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric = 'RMSE', \n",
    "        verbose=100, early_stopping_rounds= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "smf = SelectFromModel(clf, threshold='7.0*mean')\n",
    "smf.fit(ftr, target)\n",
    "X_new = smf.transform(ftr)\n",
    "X_te_new = smf.transform(data_te2[:, 1:])\n",
    "feature_idx = smf.get_support()\n",
    "#feature_name = ftr.columns[feature_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [-63.5007 -65.8621 -65.4368 -61.9738 -62.0358]\n",
      "평균 검증 정확도: -63.7618\n",
      "RMSE: 7.985101113600758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X_new, target, scoring='neg_mean_squared_error', cv=5)\n",
    "print('교차 검증별 정확도:', np.round(scores, 4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores), 4))\n",
    "print('RMSE:', np.sqrt(-np.mean(scores)))\n",
    "# mean - 7.0 : RMSE: 7.99449713498378\n",
    "# mean - 5.0 : RMSE: RMSE: 8.000763598952103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(X_new).to_csv(\"features__2rd_jinew.csv\")\n",
    "#pd.DataFrame(X_te_new).to_csv(\"features_t__2rd_jinew.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
